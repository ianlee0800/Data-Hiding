import numpy as np
import cupy as cp
import cv2
import os
import time
from tqdm import tqdm

# ğŸ”§ å¾ pee æ¨¡çµ„å°å…¥æ ¸å¿ƒåŠŸèƒ½
from pee import (
    multi_pass_embedding,
    compute_improved_adaptive_el,
    brute_force_weight_search_cuda,
    calculate_block_variance_cuda,          # âœ… ä¿®å¾©ï¼šå¾ pee å°å…¥ variance è¨ˆç®—
    predict_image_cuda                      # âœ… ä¿®å¾©ï¼šå¾ pee å°å…¥é æ¸¬åœ–åƒè¨ˆç®—
)

# ğŸ”§ å¾ utils æ¨¡çµ„å°å…¥å·¥å…·å‡½æ•¸å’Œå“è³ªæŒ‡æ¨™
from utils import (
    generate_random_binary_array,
    calculate_psnr,                       # âœ… ä¿®å¾©ï¼šå“è³ªæŒ‡æ¨™è¨ˆç®—
    calculate_ssim,                       # âœ… ä¿®å¾©ï¼šå“è³ªæŒ‡æ¨™è¨ˆç®—
    histogram_correlation,                # âœ… ä¿®å¾©ï¼šå“è³ªæŒ‡æ¨™è¨ˆç®—
    cleanup_memory,                       # âœ… ä¿®å¾©ï¼šè¨˜æ†¶é«”ç®¡ç†
    DataConverter                         # âœ… ä¿®å¾©ï¼šæ•¸æ“šè½‰æ›å·¥å…·
)

# ğŸ”§ å¾ image_processing å°å…¥æ‰€æœ‰åœ–åƒè™•ç†å’Œè¦–è¦ºåŒ–åŠŸèƒ½
from image_processing import (
    PredictionMethod,
    save_image,                           # âœ… ä¿®å¾©ï¼šç¼ºå°‘çš„å°å…¥
    split_color_channels,                 # âœ… ä¿®å¾©ï¼šå¾ image_processing å°å…¥
    combine_color_channels,               # âœ… ä¿®å¾©ï¼šå¾ image_processing å°å…¥
    convert_single_channel_to_color,      # âœ… ä¿®å¾©ï¼šè¦–è¦ºåŒ–å‡½æ•¸
    enhance_with_grid_visualization,      # âœ… ä¿®å¾©ï¼šè¦–è¦ºåŒ–å‡½æ•¸
    enhance_block_visualizations,         # âœ… ä¿®å¾©ï¼šè¦–è¦ºåŒ–å‡½æ•¸
    enhance_final_visualizations          # âœ… ä¿®å¾©ï¼šè¦–è¦ºåŒ–å‡½æ•¸
)

def cleanup_memory():
    """
    æ¸…ç† quadtree è™•ç†éç¨‹ä¸­ä½¿ç”¨çš„è³‡æº
    """
    try:
        # æ¸…ç† GPU è¨˜æ†¶é«”
        cp.get_default_memory_pool().free_all_blocks()
    except Exception as e:
        print(f"Error cleaning up quadtree resources: {str(e)}")

def adaptive_variance_threshold_search_cuda(img, ratio_of_ones, min_block_size, 
                                           el_mode, prediction_method, 
                                           target_bpp, target_psnr,
                                           threshold_range=(100, 800, 50),
                                           use_different_weights=False,
                                           total_embeddings=1,
                                           verbose=False):
    """
    ä½¿ç”¨æš´åŠ›æœç´¢æ‰¾åˆ°æœ€ä½³çš„ variance threshold
    
    Parameters:
    -----------
    img : numpy.ndarray
        è¼¸å…¥åœ–åƒ (ç°éšæˆ–å½©è‰²)
    ratio_of_ones : float
        åµŒå…¥æ•¸æ“šä¸­1çš„æ¯”ä¾‹
    min_block_size : int
        æœ€å°å€å¡Šå¤§å°
    el_mode : int
        ELæ¨¡å¼
    prediction_method : PredictionMethod
        é æ¸¬æ–¹æ³•
    target_bpp : float
        ç›®æ¨™BPP
    target_psnr : float
        ç›®æ¨™PSNR
    threshold_range : tuple
        æœç´¢ç¯„åœ (min_threshold, max_threshold, step)
    use_different_weights : bool
        æ˜¯å¦ä½¿ç”¨ä¸åŒæ¬Šé‡
    total_embeddings : int
        ç¸½åµŒå…¥æ¬¡æ•¸ï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰
    verbose : bool
        æ˜¯å¦è¼¸å‡ºè©³ç´°è³‡è¨Š
        
    Returns:
    --------
    tuple
        (best_threshold, best_metrics) æœ€ä½³é–¾å€¼å’Œå°æ‡‰çš„æŒ‡æ¨™
    """
    
    print(f"\n{'='*60}")
    print(f"Adaptive Variance Threshold Search")
    print(f"{'='*60}")
    print(f"Search range: {threshold_range[0]} to {threshold_range[1]} (step: {threshold_range[2]})")
    print(f"Target BPP: {target_bpp:.4f}, Target PSNR: {target_psnr:.2f}")
    
    # ç”Ÿæˆæœç´¢ç¯„åœ
    min_thresh, max_thresh, step = threshold_range
    threshold_candidates = list(range(min_thresh, max_thresh + step, step))
    
    if verbose:
        print(f"Testing {len(threshold_candidates)} threshold values: {threshold_candidates}")
    
    # åˆå§‹åŒ–çµæœè¨˜éŒ„
    results = []
    
    # å°æ¯å€‹ threshold é€²è¡Œæ¸¬è©¦
    for i, threshold in enumerate(tqdm(threshold_candidates, desc="Testing thresholds")):
        
        if verbose:
            print(f"\nTesting threshold {threshold} ({i+1}/{len(threshold_candidates)})")
        
        try:
            # åŸ·è¡Œç°¡åŒ–çš„quadtreeåµŒå…¥æ¸¬è©¦
            start_time = time.time()
            
            # ä½¿ç”¨ç•¶å‰thresholdé€²è¡Œæ¸¬è©¦
            final_img, payload, stages = test_quadtree_with_threshold(
                img, threshold, ratio_of_ones, min_block_size, el_mode,
                prediction_method, use_different_weights, total_embeddings
            )
            
            test_time = time.time() - start_time
            
            # è¨ˆç®—å“è³ªæŒ‡æ¨™
            total_pixels = img.size
            bpp = payload / total_pixels
            
            psnr = calculate_psnr(img, final_img)
            ssim = calculate_ssim(img, final_img)
            hist_corr = histogram_correlation(
                np.histogram(img, bins=256, range=(0, 255))[0],
                np.histogram(final_img, bins=256, range=(0, 255))[0]
            )
            
            # è¨ˆç®—é©æ‡‰åº¦åˆ†æ•¸
            fitness = calculate_threshold_fitness(
                bpp, psnr, ssim, target_bpp, target_psnr, payload
            )
            
            # è¨˜éŒ„çµæœ
            result = {
                'threshold': threshold,
                'payload': payload,
                'bpp': bpp,
                'psnr': psnr,
                'ssim': ssim,
                'hist_corr': hist_corr,
                'fitness': fitness,
                'test_time': test_time
            }
            
            results.append(result)
            
            if verbose:
                print(f"  Payload: {payload}, BPP: {bpp:.4f}")
                print(f"  PSNR: {psnr:.2f}, SSIM: {ssim:.4f}")
                print(f"  Fitness: {fitness:.4f}, Time: {test_time:.2f}s")
                
        except Exception as e:
            print(f"Error testing threshold {threshold}: {str(e)}")
            continue
    
    # æ‰¾å‡ºæœ€ä½³threshold
    if not results:
        print("No valid results found, using default threshold 300")
        return 300, None
    
    # æŒ‰é©æ‡‰åº¦æ’åºï¼Œé¸æ“‡æœ€ä½³çµæœ
    results.sort(key=lambda x: x['fitness'], reverse=True)
    best_result = results[0]
    
    print(f"\n{'='*60}")
    print(f"Search Results Summary")
    print(f"{'='*60}")
    print(f"Best threshold: {best_result['threshold']}")
    print(f"Best payload: {best_result['payload']}")
    print(f"Best BPP: {best_result['bpp']:.4f} (target: {target_bpp:.4f})")
    print(f"Best PSNR: {best_result['psnr']:.2f} (target: {target_psnr:.2f})")
    print(f"Best SSIM: {best_result['ssim']:.4f}")
    print(f"Best fitness: {best_result['fitness']:.4f}")
    
    # é¡¯ç¤ºå‰3åçµæœ
    print(f"\nTop 3 results:")
    for i, result in enumerate(results[:3]):
        print(f"  {i+1}. Threshold: {result['threshold']}, "
              f"Payload: {result['payload']}, "
              f"PSNR: {result['psnr']:.2f}, "
              f"Fitness: {result['fitness']:.4f}")
    
    return best_result['threshold'], best_result

def test_quadtree_with_threshold(img, variance_threshold, ratio_of_ones, 
                                min_block_size, el_mode, prediction_method,
                                use_different_weights, total_embeddings):
    """
    ä½¿ç”¨æŒ‡å®šçš„variance thresholdé€²è¡Œç°¡åŒ–çš„quadtreeæ¸¬è©¦
    
    Parameters:
    -----------
    img : numpy.ndarray
        è¼¸å…¥åœ–åƒ
    variance_threshold : float
        è¦æ¸¬è©¦çš„è®Šç•°é–¾å€¼
    å…¶ä»–åƒæ•¸åŒ pee_process_with_quadtree_cuda
        
    Returns:
    --------
    tuple
        (final_img, total_payload, stages)
    """
    
    # æª¢æŸ¥æ˜¯å¦ç‚ºå½©è‰²åœ–åƒ
    if len(img.shape) == 3 and img.shape[2] == 3:
        # å°å½©è‰²åœ–åƒï¼Œåªè™•ç†è—è‰²é€šé“é€²è¡Œå¿«é€Ÿæ¸¬è©¦
        b_channel, _, _ = split_color_channels(img)
        test_img = b_channel
    else:
        test_img = img
    
    # èª¿ç”¨ç°¡åŒ–ç‰ˆçš„quadtreeè™•ç†
    try:
        final_img, total_payload, stages = pee_process_with_quadtree_cuda(
            test_img,
            total_embeddings=min(total_embeddings, 2),  # é™åˆ¶åµŒå…¥æ¬¡æ•¸ä»¥åŠ é€Ÿæ¸¬è©¦
            ratio_of_ones=ratio_of_ones,
            use_different_weights=use_different_weights,
            min_block_size=min_block_size,
            variance_threshold=variance_threshold,
            el_mode=el_mode,
            rotation_mode='none',  # é—œé–‰æ—‹è½‰ä»¥åŠ é€Ÿæ¸¬è©¦
            prediction_method=prediction_method,
            target_payload_size=-1,
            max_block_size=None,
            imgName=None,  # ä¸ä¿å­˜åœ–åƒ
            output_dir=None
        )
        
        return final_img, total_payload, stages
        
    except Exception as e:
        print(f"Error in test_quadtree_with_threshold: {str(e)}")
        raise

def calculate_threshold_fitness(bpp, psnr, ssim, target_bpp, target_psnr, payload):
    """
    è¨ˆç®—variance thresholdçš„é©æ‡‰åº¦åˆ†æ•¸
    
    Parameters:
    -----------
    bpp : float
        å¯¦éš›BPP
    psnr : float
        å¯¦éš›PSNR
    ssim : float
        å¯¦éš›SSIM
    target_bpp : float
        ç›®æ¨™BPP
    target_psnr : float
        ç›®æ¨™PSNR
    payload : int
        å¯¦éš›payload
        
    Returns:
    --------
    float
        é©æ‡‰åº¦åˆ†æ•¸ (è¶Šé«˜è¶Šå¥½)
    """
    
    # BPPé©æ‡‰åº¦ (æ¥è¿‘ç›®æ¨™å€¼æ›´å¥½)
    if target_bpp > 0:
        bpp_fitness = 1.0 - abs(bpp - target_bpp) / max(target_bpp, bpp)
        bpp_fitness = max(0, bpp_fitness)
    else:
        # å¦‚æœæ²’æœ‰ç›®æ¨™BPPï¼Œå‰‡BPPè¶Šé«˜è¶Šå¥½
        bpp_fitness = min(bpp / 2.0, 1.0)  # é™åˆ¶åœ¨0-1ç¯„åœ
    
    # PSNRé©æ‡‰åº¦ (é«˜æ–¼ç›®æ¨™å€¼æ›´å¥½)
    if target_psnr > 0:
        if psnr >= target_psnr:
            psnr_fitness = 1.0
        else:
            psnr_fitness = psnr / target_psnr
    else:
        # å¦‚æœæ²’æœ‰ç›®æ¨™PSNRï¼Œä½¿ç”¨ç›¸å°è©•åˆ†
        psnr_fitness = min(psnr / 50.0, 1.0)  # å‡è¨­50dBç‚ºæœ€é«˜åˆ†
    
    # SSIMé©æ‡‰åº¦ (è¶Šé«˜è¶Šå¥½)
    ssim_fitness = ssim
    
    # Payloadé©æ‡‰åº¦ (è¶Šé«˜è¶Šå¥½ï¼Œä½†æœ‰ä¸Šé™)
    payload_fitness = min(payload / 100000.0, 1.0)  # å‡è¨­100kç‚ºåƒè€ƒå€¼
    
    # ç¶œåˆé©æ‡‰åº¦è¨ˆç®—
    # æ¬Šé‡åˆ†é…ï¼šBPP(30%) + PSNR(40%) + SSIM(20%) + Payload(10%)
    fitness = (bpp_fitness * 0.3 + 
              psnr_fitness * 0.4 + 
              ssim_fitness * 0.2 + 
              payload_fitness * 0.1)
    
    return fitness

def get_adaptive_variance_threshold(img, ratio_of_ones=0.5, min_block_size=16, 
                                  el_mode=0, prediction_method=None,
                                  target_bpp=0.8, target_psnr=35.0,
                                  search_mode='balanced',
                                  use_different_weights=False):
    """
    ç²å–åœ–åƒçš„è‡ªé©æ‡‰variance thresholdçš„ä¸»è¦æ¥å£å‡½æ•¸
    
    Parameters:
    -----------
    img : numpy.ndarray
        è¼¸å…¥åœ–åƒ
    ratio_of_ones : float
        åµŒå…¥æ•¸æ“šä¸­1çš„æ¯”ä¾‹
    min_block_size : int
        æœ€å°å€å¡Šå¤§å°
    el_mode : int
        ELæ¨¡å¼
    prediction_method : PredictionMethod
        é æ¸¬æ–¹æ³•
    target_bpp : float
        ç›®æ¨™BPP
    target_psnr : float
        ç›®æ¨™PSNR
    search_mode : str
        æœç´¢æ¨¡å¼ ('fast', 'balanced', 'thorough')
    use_different_weights : bool
        æ˜¯å¦ä½¿ç”¨ä¸åŒæ¬Šé‡
        
    Returns:
    --------
    float
        æ¨è–¦çš„variance thresholdå€¼
    """
    
    # è¨­ç½®é æ¸¬æ–¹æ³•é»˜èªå€¼
    if prediction_method is None:
        from image_processing import PredictionMethod
        prediction_method = PredictionMethod.PROPOSED
    
    # æ ¹æ“šæœç´¢æ¨¡å¼è¨­ç½®æœç´¢ç¯„åœ
    if search_mode == 'fast':
        threshold_range = (150, 450, 75)  # å¿«é€Ÿæ¨¡å¼ï¼šè¼ƒå°‘çš„æœç´¢é»
        total_embeddings = 1
    elif search_mode == 'balanced':
        threshold_range = (100, 600, 50)  # å¹³è¡¡æ¨¡å¼ï¼šä¸­ç­‰çš„æœç´¢é»
        total_embeddings = 2
    elif search_mode == 'thorough':
        threshold_range = (50, 800, 25)   # å¾¹åº•æ¨¡å¼ï¼šæ›´å¤šçš„æœç´¢é»
        total_embeddings = 3
    else:
        raise ValueError(f"Unknown search_mode: {search_mode}")
    
    print(f"Using {search_mode} search mode")
    
    # åŸ·è¡Œè‡ªé©æ‡‰æœç´¢
    best_threshold, best_metrics = adaptive_variance_threshold_search_cuda(
        img=img,
        ratio_of_ones=ratio_of_ones,
        min_block_size=min_block_size,
        el_mode=el_mode,
        prediction_method=prediction_method,
        target_bpp=target_bpp,
        target_psnr=target_psnr,
        threshold_range=threshold_range,
        use_different_weights=use_different_weights,
        total_embeddings=total_embeddings,
        verbose=False
    )
    
    return best_threshold
        
def process_current_block(block, position, size, stage_info, embedding, ratio_of_ones,
                         target_bpp, target_psnr, el_mode, prediction_method=PredictionMethod.PROPOSED,
                         remaining_target=None, verbose=False):
    """
    è™•ç†ç•¶å‰å€å¡Šçš„ PEE åµŒå…¥ï¼Œæ”¯æ´å¤šç¨®é æ¸¬æ–¹æ³•å’Œçµ±ä¸€æ¬Šé‡
    
    Parameters:
    -----------
    block : numpy.ndarray or cupy.ndarray
        è¼¸å…¥å€å¡Š
    position : tuple
        å€å¡Šåœ¨åŸåœ–ä¸­çš„ä½ç½® (y, x)
    size : int
        å€å¡Šå¤§å°
    stage_info : dict
        ç•¶å‰éšæ®µçš„è³‡è¨Š
    embedding : int
        ç•¶å‰åµŒå…¥éšæ®µ
    ratio_of_ones : float
        åµŒå…¥æ•¸æ“šä¸­ 1 çš„æ¯”ä¾‹
    target_bpp : float
        ç›®æ¨™ BPP
    target_psnr : float
        ç›®æ¨™ PSNR
    el_mode : int
        ELæ¨¡å¼
    prediction_method : PredictionMethod
        é æ¸¬æ–¹æ³•
    remaining_target : list or None
        å‰©é¤˜éœ€è¦åµŒå…¥çš„æ•¸æ“šé‡çš„å¯è®Šå®¹å™¨ [target_value]
    verbose : bool
        æ˜¯å¦è¼¸å‡ºè©³ç´°è³‡è¨Š
        
    Returns:
    --------
    list
        [embedded_block, position, size, block_was_rotated]
    """
    try:
        # ç¢ºä¿ block æ˜¯ CuPy æ•¸çµ„
        if not isinstance(block, cp.ndarray):
            block = cp.asarray(block)
        
        # æª¢æŸ¥æ˜¯å¦å·²é”åˆ°ç›®æ¨™å®¹é‡
        if remaining_target is not None and remaining_target[0] <= 0:
            # å·²é”åˆ°ç›®æ¨™ï¼Œç›´æ¥è¿”å›åŸåœ–
            if verbose:
                print(f"  Target reached. Skipping block at {position} (size: {size}x{size})")
            return [(block, position, size, False)]
        
        # è¨ˆç®—å€å¡Šå¤§å°å’Œç›®æ¨™å®¹é‡
        block_size = block.size
        current_target = None
        if remaining_target is not None:
            # å¦‚æœå‰©é¤˜ç›®æ¨™å°æ–¼å€å¡Šå¤§å°ï¼Œå¯èƒ½ä¸æ‡‰è©²è·³éé€™å€‹å€å¡Š
            # è€Œæ˜¯å˜—è©¦ç²¾ç¢ºåµŒå…¥æ‰€éœ€çš„ä½å…ƒæ•¸
            current_target = min(block_size, remaining_target[0])
            if verbose:
                print(f"  Block at {position} allocated {current_target} bits (of {remaining_target[0]} remaining)")
        
        # é¦–å…ˆæ ¹æ“š el_mode æ±ºå®šåˆå§‹ max_el å€¼
        if el_mode == 1:  # Increasing
            max_el = 3 + embedding * 2
        elif el_mode == 2:  # Decreasing
            max_el = 11 - embedding * 2
        else:  # No restriction
            max_el = 7
            
        # ç„¶å¾Œæ ¹æ“šå€å¡Šå¤§å°èª¿æ•´åƒæ•¸
        if size <= 32:
            max_el = min(max_el, 5)  # ç¾åœ¨å¯ä»¥å®‰å…¨åœ°ä½¿ç”¨ max_el
            local_target_bpp = target_bpp * 0.8
            local_target_psnr = target_psnr + 2
        else:
            local_target_bpp = target_bpp
            local_target_psnr = target_psnr
        
        # è¨ˆç®—æ”¹é€²çš„ local_el
        local_el = compute_improved_adaptive_el(
            block, 
            window_size=min(5, size//4),
            max_el=max_el,  # ä½¿ç”¨å·²ç¶“æ­£ç¢ºåˆå§‹åŒ–çš„ max_el
            block_size=size
        )
        
        # ç”ŸæˆåµŒå…¥æ•¸æ“š
        # å¦‚æœæ˜¯æ¥è¿‘ç›®æ¨™å€¼çš„æœ€å¾Œä¸€å€‹å€å¡Šï¼Œå„ªå…ˆè€ƒæ…®ç”Ÿæˆæ°å¥½æ•¸é‡çš„æ•¸æ“š
        if remaining_target is not None and remaining_target[0] <= block_size:
            # ç”Ÿæˆå‰›å¥½æ‰€éœ€æ•¸é‡çš„æ•¸æ“š
            data_size = remaining_target[0]
            if verbose:
                print(f"  Generating exactly {data_size} bits to match target")
        else:
            data_size = block_size
            
        data_to_embed = generate_random_binary_array(data_size, ratio_of_ones)
        data_to_embed = cp.asarray(data_to_embed, dtype=cp.uint8)
        
        # æ¨™è¨˜æ˜¯å¦å€å¡Šæœ‰æ—‹è½‰
        block_was_rotated = False
        original_block = block.copy()  # å„²å­˜åŸå§‹å€å¡Šç”¨æ–¼è¨ˆç®—æŒ‡æ¨™
        
        # æ‡‰ç”¨æ—‹è½‰ (å¦‚æœ rotation_mode ç‚º 'random')
        rotation = 0
        if 'rotation_mode' in stage_info and stage_info['rotation_mode'] == 'random' and 'block_rotations' in stage_info:
            if size in stage_info['block_rotations']:
                rotation = stage_info['block_rotations'][size]
                if rotation != 0:
                    k = rotation // 90
                    block = cp.rot90(block, k=k)
                    block_was_rotated = True
                    if verbose:
                        print(f"  Applied rotation of {rotation}Â° to block at {position}")
        
        # æ ¹æ“šé æ¸¬æ–¹æ³•é€²è¡Œä¸åŒçš„è™•ç†
        if prediction_method == PredictionMethod.PROPOSED:
            # æª¢æŸ¥æ˜¯å¦ä½¿ç”¨ä¸åŒæ¬Šé‡
            if 'use_different_weights' in stage_info and stage_info['use_different_weights']:
                # PROPOSED æ–¹æ³•éœ€è¦è¨ˆç®—æ¬Šé‡ (æ¯å€‹å€å¡Šä½¿ç”¨ä¸åŒæ¬Šé‡)
                weights, (sub_payload, sub_psnr) = brute_force_weight_search_cuda(
                    block, data_to_embed, local_el, local_target_bpp, local_target_psnr, 
                    embedding, block_size=size
                )
                if verbose:
                    print(f"  Computed unique weights for block at {position}: {weights}")
            else:
                # ä½¿ç”¨åŒæ¨£å¤§å°å€å¡Šçš„çµ±ä¸€æ¬Šé‡
                size_str = str(size)
                if size_str in stage_info['block_size_weights']:
                    # ä½¿ç”¨å·²è¨ˆç®—çš„æ¬Šé‡
                    weights = np.array(stage_info['block_size_weights'][size_str], dtype=np.int32)
                    if verbose:
                        print(f"  Using cached weights for {size}x{size} blocks: {weights}")
                else:
                    # ç¬¬ä¸€æ¬¡è¨ˆç®—æ­¤å¤§å°çš„æ¬Šé‡
                    weights, (sub_payload, sub_psnr) = brute_force_weight_search_cuda(
                        block, data_to_embed, local_el, local_target_bpp, local_target_psnr, 
                        embedding, block_size=size
                    )
                    # å„²å­˜æ¬Šé‡ä»¥ä¾¿å¾ŒçºŒä½¿ç”¨
                    if hasattr(weights, 'tolist'):
                        stage_info['block_size_weights'][size_str] = weights.tolist()
                    else:
                        stage_info['block_size_weights'][size_str] = weights
                    if verbose:
                        print(f"  Computed new weights for {size}x{size} blocks: {weights}")
        else:
            # MED å’Œ GAP æ–¹æ³•ä¸éœ€è¦æ¬Šé‡
            weights = None
        
        # è¨ˆç®—é æ¸¬åœ–åƒ (ä½¿ç”¨å®‰å…¨çš„é¡å‹æª¢æŸ¥)
        pred_image = predict_image_cuda(block, prediction_method, weights)
        
        # å®‰å…¨åœ°ç²å– NumPy æ ¼å¼çš„é æ¸¬åœ–åƒ
        if hasattr(pred_image, 'copy_to_host'):
            pred_image_np = pred_image.copy_to_host()
        else:
            pred_image_np = pred_image
            
        # åŸ·è¡Œæ•¸æ“šåµŒå…¥
        embedded_block, payload, pred_block = multi_pass_embedding(
            block,
            data_to_embed,
            local_el,
            weights,
            embedding,
            prediction_method=prediction_method,
            remaining_target=remaining_target
        )
        
        # ç¢ºä¿çµæœæ˜¯ CuPy æ•¸çµ„
        if not isinstance(embedded_block, cp.ndarray):
            embedded_block = cp.asarray(embedded_block)
        
        # å¦‚æœå€å¡Šè¢«æ—‹è½‰éï¼Œè¨ˆç®—æŒ‡æ¨™æ™‚ä½¿ç”¨æœªæ—‹è½‰çš„åŸå§‹å€å¡Šåšæ¯”è¼ƒ
        compare_block = original_block
        
        # å°‡æ—‹è½‰å¾Œçš„åµŒå…¥å€å¡Šæ—‹è½‰å›åŸå§‹æ–¹å‘
        if block_was_rotated:
            # è¨ˆç®—é€†æ—‹è½‰è§’åº¦
            k = (-rotation // 90) % 4
            embedded_block = cp.rot90(embedded_block, k=k)
            
            # å°‡é æ¸¬åœ–åƒä¹Ÿæ—‹è½‰å›ä¾†
            pred_image_np = np.rot90(pred_image_np, k=k)
            
            if verbose:
                print(f"  Rotated embedded block back by {-rotation}Â° to original orientation")
        
        # è¨ˆç®—ä¸¦è¨˜éŒ„å€å¡Šè³‡è¨Š
        # çµ±ä¸€æ•¸æ“šè½‰æ›ï¼Œé¿å…é‡è¤‡è½‰æ›
        compare_block_np = DataConverter.to_numpy(compare_block)
        embedded_block_np = DataConverter.to_numpy(embedded_block)
        original_block_np = DataConverter.to_numpy(original_block)
        local_el_np = DataConverter.to_numpy(local_el)

        # çµ±ä¸€è¨ˆç®—å“è³ªæŒ‡æ¨™
        psnr_value = calculate_psnr(compare_block_np, embedded_block_np)
        ssim_value = calculate_ssim(compare_block_np, embedded_block_np)

        # çµ±ä¸€è¨ˆç®—ç›´æ–¹åœ–
        hist_orig = np.histogram(compare_block_np, bins=256, range=(0, 255))[0]
        hist_embd = np.histogram(embedded_block_np, bins=256, range=(0, 255))[0]
        hist_corr_value = histogram_correlation(hist_orig, hist_embd)

        block_info = {
            'position': position,
            'size': size,
            'weights': (weights.tolist() if weights is not None and hasattr(weights, 'tolist') 
                    else "N/A" if prediction_method in [PredictionMethod.MED, PredictionMethod.GAP] 
                    else None),
            'payload': int(payload),
            'psnr': float(psnr_value),
            'ssim': float(ssim_value),
            'hist_corr': float(hist_corr_value),
            'EL': int(local_el_np.max()),
            'prediction_method': prediction_method.value,
            'rotation': rotation,
            'original_img': original_block_np,
            'pred_img': pred_image_np,
            'embedded_img': embedded_block_np
        }
        
        # æ›´æ–°éšæ®µè³‡è¨Š
        stage_info['block_info'][str(size)]['blocks'].append(block_info)
        stage_info['payload'] += payload
        
        if verbose:
            print(f"  Block processed at size {size}x{size}")
            print(f"  Prediction method: {prediction_method.value}")
            print(f"  Payload: {payload}")
            print(f"  PSNR: {block_info['psnr']:.2f}")
            if remaining_target is not None:
                print(f"  Remaining target: {remaining_target[0]} bits")
        
        # è¿”å›è™•ç†å¾Œçš„å€å¡Šï¼Œä¸¦æ¨™è¨˜å…¶æ˜¯å¦æ›¾ç¶“è¢«æ—‹è½‰é
        return [(embedded_block, position, size, block_was_rotated)]
            
    except Exception as e:
        print(f"Error in block processing: {str(e)}")
        raise

def process_block(block, position, size, stage_info, embedding, variance_threshold, 
                 ratio_of_ones, target_bpp, target_psnr, el_mode, verbose=False,
                 rotation_mode='none', prediction_method=PredictionMethod.PROPOSED,
                 remaining_target=None, max_block_size=1024):
    """
    éè¿´è™•ç†å€å¡Šï¼Œæ±ºå®šæ˜¯å¦éœ€è¦é€²ä¸€æ­¥åˆ†å‰²ï¼Œæ”¯æ´å¤šç¨®é æ¸¬æ–¹æ³•
    
    Parameters:
    -----------
    block : cupy.ndarray
        è¼¸å…¥å€å¡Š
    position : tuple
        å€å¡Šåœ¨åŸåœ–ä¸­çš„ä½ç½® (y, x)
    size : int
        å€å¡Šå¤§å°
    stage_info : dict
        ç•¶å‰éšæ®µçš„è³‡è¨Š
    embedding : int
        ç•¶å‰åµŒå…¥éšæ®µ
    variance_threshold : float
        è®Šç•°åº¦é–¾å€¼
    ratio_of_ones : float
        åµŒå…¥æ•¸æ“šä¸­ 1 çš„æ¯”ä¾‹
    target_bpp : float
        ç›®æ¨™ BPP
    target_psnr : float
        ç›®æ¨™ PSNR
    el_mode : int
        ELæ¨¡å¼
    verbose : bool
        æ˜¯å¦è¼¸å‡ºè©³ç´°è³‡è¨Š
    rotation_mode : str
        'none': åŸå§‹çš„ quadtree æ–¹æ³•
        'random': ä½¿ç”¨éš¨æ©Ÿæ—‹è½‰çš„æ–°æ–¹æ³•
    prediction_method : PredictionMethod
        é æ¸¬æ–¹æ³•é¸æ“‡ (PROPOSED, MED, GAP)
    remaining_target : list or None
        å‰©é¤˜éœ€è¦åµŒå…¥çš„æ•¸æ“šé‡çš„å¯è®Šå®¹å™¨ [target_value]
    max_block_size : int
        æœ€å¤§å€å¡Šå¤§å°ï¼Œé»˜èªç‚º1024
    """
    try:
        # ç²¾ç¢ºæ§åˆ¶ - å¦‚æœå‰©é¤˜å®¹é‡å¾ˆå°ï¼Œå„ªå…ˆè™•ç†å°å€å¡Šè€Œä¸åˆ†å‰²å¤§å€å¡Š
        if remaining_target is not None:
            # å¦‚æœå‰©é¤˜å®¹é‡å·²ç¶“ä¸è¶³ï¼š
            if remaining_target[0] <= 0:
                # å¦‚æœå·²é”åˆ°ç›®æ¨™å®¹é‡ï¼Œç›´æ¥è¿”å›åŸå§‹å€å¡Šï¼Œä¸é€²è¡ŒåµŒå…¥
                if verbose:
                    print(f"Target reached. Skipping block at {position} (size: {size}x{size})")
                return [(block, position, size, False)]
            
            # å¦‚æœå‰©é¤˜å®¹é‡å¾ˆå°ï¼Œå°æ–¼å€å¡Šå¤§å°çš„20%ï¼Œä¸”å€å¡Šæ¯”è¼ƒå¤§ï¼Œè€ƒæ…®ç›´æ¥è™•ç†
            if remaining_target[0] < (size * size * 0.2) and size >= 64:
                if verbose:
                    print(f"Small remaining target ({remaining_target[0]} bits) - processing block directly")
                return process_current_block(
                    block, position, size, stage_info, embedding,
                    ratio_of_ones, target_bpp, target_psnr, el_mode,
                    prediction_method=prediction_method,
                    remaining_target=remaining_target,
                    verbose=verbose
                )
        
        if size < 16:  # æœ€å°å€å¡Šå¤§å°é™åˆ¶
            return []
        
        # ç¢ºä¿ block æ˜¯ CuPy æ•¸çµ„
        if not isinstance(block, cp.ndarray):
            block = cp.asarray(block)
        
        # è¨ˆç®—å€å¡Šè®Šç•°åº¦
        variance = calculate_block_variance_cuda(block)
        
        # æ ¹æ“šå€å¡Šå¤§å°èª¿æ•´é–¾å€¼
        adjusted_threshold = variance_threshold
        if size >= 512:
            adjusted_threshold *= 1.3  # å¢åŠ å°1024å¡Šçš„è™•ç†
        elif size >= 256:
            adjusted_threshold *= 1.2
        elif size >= 128:
            adjusted_threshold *= 1.1
        elif size >= 64:
            adjusted_threshold *= 1.0
        elif size >= 32:
            adjusted_threshold *= 0.9
        else:  # 16x16 å€å¡Š
            adjusted_threshold *= 0.8
        
        # è¨ˆç®—é‚Šç·£å¼·åº¦ä»¥å„ªåŒ–åˆ†å‰²æ±ºç­–
        dx = cp.diff(block, axis=1)
        dy = cp.diff(block, axis=0)
        edge_strength = float(cp.mean(cp.abs(dx)) + cp.mean(cp.abs(dy)))
        
        if edge_strength > variance_threshold * 0.3:
            adjusted_threshold *= 0.9  # é‚Šç·£å€åŸŸæ›´å®¹æ˜“è¢«åˆ†å‰²
        
        if verbose:
            print(f"Block at {position}, size: {size}x{size}")
            print(f"  Variance: {variance:.2f}")
            print(f"  Edge strength: {edge_strength:.2f}")
            print(f"  Adjusted threshold: {adjusted_threshold:.2f}")
            if remaining_target is not None:
                print(f"  Remaining target: {remaining_target[0]} bits")
        
        # æ ¹æ“šè®Šç•°åº¦æ±ºå®šæ˜¯å¦åˆ†å‰²
        if size > 16 and variance > adjusted_threshold:
            # ç¹¼çºŒåˆ†å‰²ç‚ºå››å€‹å­å€å¡Š
            half_size = size // 2
            sub_blocks = []
            
            # å‰©é¤˜å®¹é‡ç²¾ç¢ºæ§åˆ¶ - ç‚ºå­å€å¡Šåˆ†é…åˆç†çš„ç›®æ¨™å®¹é‡
            sub_block_targets = None
            if remaining_target is not None and remaining_target[0] > 0:
                # æ ¹æ“šå€å¡Šå¤§å°åˆ†é…å®¹é‡
                sub_block_size = half_size * half_size
                total_size = size * size
                sub_block_targets = [
                    [int(remaining_target[0] * sub_block_size / total_size)],
                    [int(remaining_target[0] * sub_block_size / total_size)],
                    [int(remaining_target[0] * sub_block_size / total_size)],
                    [int(remaining_target[0] * sub_block_size / total_size)]
                ]
                # ç¢ºä¿åˆ†é…çš„ç¸½å’Œä¸è¶…éå‰©é¤˜ç›®æ¨™
                total_allocated = sum(target[0] for target in sub_block_targets)
                if total_allocated > remaining_target[0]:
                    # èª¿æ•´æœ€å¾Œä¸€å€‹å€å¡Šçš„åˆ†é…
                    sub_block_targets[3][0] -= (total_allocated - remaining_target[0])
                
                if verbose:
                    print(f"  Allocated targets for sub-blocks: {[target[0] for target in sub_block_targets]}")
            
            for i in range(2):
                for j in range(2):
                    # ç²å–ç•¶å‰å­å€å¡Šçš„ç´¢å¼•å’Œç›®æ¨™å®¹é‡
                    sub_idx = i * 2 + j
                    current_target = sub_block_targets[sub_idx] if sub_block_targets else remaining_target
                    
                    # å¦‚æœå­å€å¡Šçš„ç›®æ¨™å®¹é‡å·²ç¶“ç‚º0ï¼Œè·³éè™•ç†
                    if current_target is not None and current_target[0] <= 0:
                        # ç›´æ¥æ·»åŠ æœªè™•ç†çš„å­å€å¡Š
                        y_start = position[0] + i * half_size
                        x_start = position[1] + j * half_size
                        sub_block = block[i*half_size:(i+1)*half_size, j*half_size:(j+1)*half_size]
                        sub_blocks.append((sub_block, (y_start, x_start), half_size, False))
                        continue
                        
                    y_start = position[0] + i * half_size
                    x_start = position[1] + j * half_size
                    sub_block = block[i*half_size:(i+1)*half_size, j*half_size:(j+1)*half_size]
                    
                    # éè¿´è™•ç†å­å€å¡Šï¼Œå‚³éæ‰€æœ‰å¿…è¦åƒæ•¸ï¼Œä½¿ç”¨åˆ†é…çš„ç›®æ¨™å®¹é‡
                    sub_results = process_block(
                        sub_block, (y_start, x_start), half_size,
                        stage_info, embedding, variance_threshold,
                        ratio_of_ones, target_bpp, target_psnr, el_mode,
                        verbose=verbose,
                        rotation_mode=rotation_mode,
                        prediction_method=prediction_method,
                        remaining_target=current_target,  # ä½¿ç”¨åˆ†é…çµ¦é€™å€‹å­å€å¡Šçš„ç›®æ¨™
                        max_block_size=max_block_size
                    )
                    
                    # æ›´æ–°ä¸»è¦çš„å‰©é¤˜ç›®æ¨™å®¹é‡
                    if remaining_target is not None and current_target is not None:
                        # è¨ˆç®—å¯¦éš›ä½¿ç”¨çš„å®¹é‡ï¼ˆåˆ†é…å‰æ¸›å»åˆ†é…å¾Œï¼‰
                        used_capacity = sub_block_targets[sub_idx][0] - current_target[0]
                        remaining_target[0] -= used_capacity
                        if verbose and used_capacity > 0:
                            print(f"  Sub-block {sub_idx} used {used_capacity} bits, main remaining: {remaining_target[0]}")
                    
                    sub_blocks.extend(sub_results)
            
            return sub_blocks
        else:
            # è™•ç†ç•¶å‰å€å¡Š
            return process_current_block(
                block, position, size, stage_info, embedding,
                ratio_of_ones, target_bpp, target_psnr, el_mode,
                prediction_method=prediction_method,
                remaining_target=remaining_target,
                verbose=verbose
            )
            
    except Exception as e:
        print(f"Error in block processing at position {position}, size {size}: {str(e)}")
        raise

def pee_process_with_quadtree_cuda(img, total_embeddings, ratio_of_ones, use_different_weights, 
                                 min_block_size, variance_threshold, el_mode, 
                                 rotation_mode='none',
                                 prediction_method=None,
                                 target_payload_size=-1,
                                 max_block_size=None,
                                 imgName=None,
                                 output_dir=None,
                                 adaptive_threshold=False,
                                 search_mode='balanced',
                                 target_bpp_for_search=0.8,
                                 target_psnr_for_search=35.0):
    """
    ä½¿ç”¨Quad treeçš„PEEè™•ç†å‡½æ•¸ï¼Œæ”¯æ´å¤šç¨®é æ¸¬æ–¹æ³•å’Œpayloadæ§åˆ¶ï¼Œæ–°å¢è‡ªé©æ‡‰variance thresholdåŠŸèƒ½
    
    Parameters:
    -----------
    img : numpy.ndarray
        è¼¸å…¥åœ–åƒ (ç°éšæˆ–å½©è‰²)
    total_embeddings : int
        ç¸½åµŒå…¥æ¬¡æ•¸
    ratio_of_ones : float
        åµŒå…¥æ•¸æ“šä¸­1çš„æ¯”ä¾‹
    use_different_weights : bool
        æ˜¯å¦å°æ¯å€‹å­åœ–åƒä½¿ç”¨ä¸åŒçš„æ¬Šé‡ (åƒ…ç”¨æ–¼ PROPOSED æ–¹æ³•)
    min_block_size : int
        æœ€å°å€å¡Šå¤§å° (æ”¯æ´åˆ°16x16)
    variance_threshold : float
        è®Šç•°é–¾å€¼ (ç•¶adaptive_threshold=Trueæ™‚ï¼Œæ­¤åƒæ•¸æœƒè¢«è¦†è“‹)
    el_mode : int
        ELæ¨¡å¼ (0:ç„¡é™åˆ¶, 1:æ¼¸å¢, 2:æ¼¸æ¸›)
    prediction_method : PredictionMethod
        é æ¸¬æ–¹æ³•é¸æ“‡ (PROPOSED, MED, GAP)
    rotation_mode : str
        'none': åŸå§‹çš„ quadtree æ–¹æ³•
        'random': ä½¿ç”¨éš¨æ©Ÿæ—‹è½‰çš„æ–°æ–¹æ³•
    target_payload_size : int
        ç›®æ¨™ç¸½payloadå¤§å°ï¼Œè¨­ç‚º-1æ™‚ä½¿ç”¨æœ€å¤§å®¹é‡
    max_block_size : int, optional
        æœ€å¤§å€å¡Šå¤§å°ï¼Œé è¨­ç‚ºåœ–åƒå¤§å°çš„ä¸€åŠæˆ–512ï¼Œå–è¼ƒå¤§å€¼
    imgName : str, optional
        åœ–åƒåç¨±ï¼Œç”¨æ–¼å„²å­˜è¦–è¦ºåŒ–çµæœ
    output_dir : str, optional
        è¼¸å‡ºç›®éŒ„ï¼Œç”¨æ–¼å„²å­˜è¦–è¦ºåŒ–çµæœ
    adaptive_threshold : bool, optional
        æ˜¯å¦ä½¿ç”¨è‡ªé©æ‡‰variance thresholdæœç´¢ï¼Œé»˜èªFalse
    search_mode : str, optional
        è‡ªé©æ‡‰æœç´¢æ¨¡å¼ ('fast', 'balanced', 'thorough')ï¼Œé»˜èª'balanced'
    target_bpp_for_search : float, optional
        è‡ªé©æ‡‰æœç´¢çš„ç›®æ¨™BPPï¼Œé»˜èª0.8
    target_psnr_for_search : float, optional
        è‡ªé©æ‡‰æœç´¢çš„ç›®æ¨™PSNRï¼Œé»˜èª35.0
        
    Returns:
    --------
    tuple
        (final_pee_img, total_payload, pee_stages)
        final_pee_img: æœ€çµ‚è™•ç†å¾Œçš„åœ–åƒ
        total_payload: ç¸½åµŒå…¥å®¹é‡
        pee_stages: åŒ…å«æ¯å€‹éšæ®µè©³ç´°è³‡è¨Šçš„åˆ—è¡¨
    """
    # Check if this is a color image by examining image shape
    if len(img.shape) == 3 and img.shape[2] == 3:
        # For color images, redirect to color image processing function
        print("Detected color image, redirecting to color image processing...")
        return pee_process_color_image_quadtree_cuda(
            img, total_embeddings, ratio_of_ones, use_different_weights,
            min_block_size, variance_threshold, el_mode, rotation_mode,
            prediction_method, target_payload_size, max_block_size,
            imgName, output_dir, adaptive_threshold, search_mode,
            target_bpp_for_search, target_psnr_for_search
        )

    try:
        # è‡ªé©æ‡‰variance thresholdæœç´¢
        if adaptive_threshold:
            print(f"\n{'='*60}")
            print(f"Adaptive Variance Threshold Search Enabled")
            print(f"{'='*60}")
            print(f"Original threshold: {variance_threshold}")
            print(f"Search mode: {search_mode}")
            print(f"Target BPP: {target_bpp_for_search:.4f}")
            print(f"Target PSNR: {target_psnr_for_search:.2f}")
            
            try:
                optimal_threshold = get_adaptive_variance_threshold(
                    img=img,
                    ratio_of_ones=ratio_of_ones,
                    min_block_size=min_block_size,
                    el_mode=el_mode,
                    prediction_method=prediction_method,
                    target_bpp=target_bpp_for_search,
                    target_psnr=target_psnr_for_search,
                    search_mode=search_mode,
                    use_different_weights=use_different_weights
                )
                
                print(f"Adaptive search completed!")
                print(f"Original threshold: {variance_threshold}")
                print(f"Optimal threshold: {optimal_threshold}")
                print(f"Improvement: {((optimal_threshold - variance_threshold) / variance_threshold * 100):+.1f}%")
                
                # ä½¿ç”¨æ‰¾åˆ°çš„æœ€ä½³threshold
                variance_threshold = optimal_threshold
                
            except Exception as e:
                print(f"Warning: Adaptive threshold search failed: {str(e)}")
                print(f"Falling back to original threshold: {variance_threshold}")
        else:
            print(f"Using fixed variance threshold: {variance_threshold}")

        # å®šç¾© ensure_dir å‡½æ•¸
        def ensure_dir(file_path):
            """ç¢ºä¿ç›®éŒ„å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡å‰µå»º"""
            directory = os.path.dirname(file_path)
            if not os.path.exists(directory):
                os.makedirs(directory)
        
        # åƒæ•¸é©—è­‰èˆ‡é è¨­å€¼è¨­ç½®
        # æª¢æŸ¥ä¸¦è¨­ç½®åœ–åƒåç¨±
        if imgName is None:
            if rotation_mode == 'random':
                # ä½¿ç”¨éš¨æ©Ÿæ—‹è½‰æ¨¡å¼æ™‚éœ€è¦åœ–åƒåç¨±
                imgName = "unknown_image"  # ä½¿ç”¨é è¨­åç¨±
                print("Warning: No image name provided. Using 'unknown_image' for saving visualizations.")
            else:
                # éæ—‹è½‰æ¨¡å¼å¯ä»¥ä¸éœ€è¦åœ–åƒåç¨±
                imgName = "temp"
        
        # æª¢æŸ¥ä¸¦è¨­ç½®è¼¸å‡ºç›®éŒ„
        if output_dir is None:
            output_dir = "./Prediction_Error_Embedding/outcome"
            print(f"Using default output directory: {output_dir}")
        
        # é è¨­è¦–è¦ºåŒ–è·¯å¾‘
        image_dir = f"{output_dir}/image/{imgName}/quadtree"
        
        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        os.makedirs(image_dir, exist_ok=True)
        os.makedirs(f"{image_dir}/rotated_blocks", exist_ok=True)
        
        # åƒæ•¸åˆæ³•æ€§æª¢æŸ¥
        if min_block_size < 16:
            raise ValueError("min_block_size must be at least 16")
        if min_block_size & (min_block_size - 1) != 0:
            raise ValueError("min_block_size must be a power of 2")
        if not 0 <= ratio_of_ones <= 1:
            raise ValueError("ratio_of_ones must be between 0 and 1")
        if rotation_mode not in ['none', 'random']:
            raise ValueError("rotation_mode must be 'none' or 'random'")
        
        # ç¢ºå®šæœ€å¤§å€å¡Šå¤§å°
        height, width = img.shape
        if max_block_size is None:
            max_block_size = max(512, min(1024, max(height, width)))
        
        # æª¢æŸ¥åœ–åƒå¤§å°æ˜¯å¦ç‚º max_block_size çš„æ•´æ•¸å€
        if height % max_block_size != 0 or width % max_block_size != 0:
            # å¢Šå……åœ–åƒåˆ°åˆé©çš„å¤§å°
            new_height = ((height + max_block_size - 1) // max_block_size) * max_block_size
            new_width = ((width + max_block_size - 1) // max_block_size) * max_block_size
            
            # å»ºç«‹æ–°åœ–åƒä¸¦è¤‡è£½åŸå§‹æ•¸æ“š
            padded_img = np.zeros((new_height, new_width), dtype=np.uint8)
            padded_img[:height, :width] = img
            
            # ä½¿ç”¨é‚Šç·£åƒç´ å¡«å……å‰©é¤˜éƒ¨åˆ†
            if height < new_height:
                padded_img[height:, :width] = padded_img[height-1:height, :width]
            if width < new_width:
                padded_img[:, width:] = padded_img[:, width-1:width]
            
            # æ›´æ–°åœ–åƒå’Œå°ºå¯¸
            img = padded_img
            height, width = img.shape
            print(f"Image resized from {height}x{width} to {new_height}x{new_width} for quadtree processing")
        
        # é æ¸¬æ–¹æ³•ç›¸é—œè¨­ç½®
        if prediction_method in [PredictionMethod.MED, PredictionMethod.GAP]:
            use_different_weights = False
            print(f"Note: Weight optimization disabled for {prediction_method.value} prediction method")
        
        # è™•ç†æ—‹è½‰æ¨¡å¼è¨­ç½®
        # è­¦å‘Šï¼šç•¶ä½¿ç”¨ç²¾ç¢ºçš„ç›®æ¨™payloadæ™‚ï¼Œä¸å»ºè­°ä½¿ç”¨randomæ—‹è½‰æ¨¡å¼
        if rotation_mode == 'random' and target_payload_size > 0:
            print("WARNING: Using random rotation mode with a specific target payload may cause image quality issues.")
            print("For better image quality with target payload, consider using rotation_mode='none'.")
        
        # åˆå§‹åŒ–åŸºæœ¬è®Šæ•¸
        original_img = cp.asarray(img)
        height, width = original_img.shape
        total_pixels = height * width
        pee_stages = []
        total_payload = 0
        current_img = original_img.copy()
        
        # è¿½è¹¤è®Šæ•¸åˆå§‹åŒ–
        previous_psnr = float('inf')
        previous_ssim = 1.0
        previous_payload = float('inf')
        
        # ä½¿ç”¨å¯è®Šå®¹å™¨ä¾†è¿½è¹¤å‰©é¤˜ç›®æ¨™payload
        # é€™æ˜¯é—œéµä¿®æ”¹é»ï¼šä½¿ç”¨listä½œç‚ºå¯è®Šå®¹å™¨è€Œä¸æ˜¯int
        if target_payload_size > 0:
            remaining_target = [target_payload_size]  # ä½¿ç”¨listä½œç‚ºå¯è®Šå®¹å™¨
            print(f"Target payload set: {target_payload_size} bits")
            # ç›®æ¨™å®¹é‡çš„å¡«å……ç‡ï¼ˆç›®æ¨™ä½”åœ–ç‰‡å®¹é‡çš„æ¯”ä¾‹ï¼‰
            fill_rate = target_payload_size / total_pixels
            print(f"Target fill rate: {fill_rate:.4f} bits per pixel")
        else:
            remaining_target = None
            print("Using maximum embedding capacity")
        
        # å„²å­˜æ¯ç¨®å¤§å°å€å¡Šçš„æ¬Šé‡
        block_size_weights = {}
        
        # è¨­ç½®ç²¾ç¢ºæ§åˆ¶çš„é¡å¤–åƒæ•¸
        # å¦‚æœè¨­ç½®äº†ç›®æ¨™payloadï¼Œå•Ÿç”¨ç²¾ç¢ºæ§åˆ¶æ¨¡å¼
        precise_control = target_payload_size > 0
        
        # GPU è¨˜æ†¶é«”ç®¡ç†
        mem_pool = cp.get_default_memory_pool()

        try:
            # é€éšæ®µè™•ç†
            for embedding in range(total_embeddings):
                # æª¢æŸ¥æ˜¯å¦é”åˆ°ç›®æ¨™ payload
                if remaining_target is not None and remaining_target[0] <= 0:
                    print(f"Reached target payload ({target_payload_size} bits) at stage {embedding}")
                    break
                    
                # è¼¸å‡ºéšæ®µé–‹å§‹è³‡è¨Š
                print(f"\nStarting embedding {embedding}")
                print(f"Memory usage before embedding {embedding}: {mem_pool.used_bytes()/1024/1024:.2f} MB")
                if remaining_target is not None:
                    print(f"Remaining target payload: {remaining_target[0]} bits")

                # è¨­å®šç›®æ¨™å“è³ªåƒæ•¸
                if embedding == 0:
                    target_psnr = 40.0
                    target_bpp = 0.9
                else:
                    target_psnr = max(28.0, previous_psnr - 1)
                    target_bpp = max(0.5, (previous_payload / total_pixels) * 0.95)

                print(f"Target PSNR for embedding {embedding}: {target_psnr:.2f}")
                print(f"Target BPP for embedding {embedding}: {target_bpp:.4f}")
                print(f"Using variance threshold: {variance_threshold}")

                # åˆå§‹åŒ–éšæ®µè³‡è¨Šï¼ŒåŒ…æ‹¬æ‰€æœ‰å¯èƒ½çš„å€å¡Šå¤§å°
                all_block_sizes = [1024, 512, 256, 128, 64, 32, 16]
                stage_info = {
                    'embedding': embedding,
                    'block_info': {str(size): {'blocks': []} for size in all_block_sizes},
                    'payload': 0,
                    'psnr': 0,
                    'ssim': 0,
                    'hist_corr': 0,
                    'bpp': 0,
                    'rotation_mode': rotation_mode,
                    'prediction_method': prediction_method.value,
                    'use_different_weights': use_different_weights,
                    'block_size_weights': {},  # å„²å­˜æ¯ç¨®å¤§å°å€å¡Šçš„çµ±ä¸€æ¬Šé‡
                    'variance_threshold': variance_threshold,  # æ–°å¢ï¼šè¨˜éŒ„ä½¿ç”¨çš„threshold
                    'adaptive_threshold_used': adaptive_threshold  # æ–°å¢ï¼šè¨˜éŒ„æ˜¯å¦ä½¿ç”¨äº†è‡ªé©æ‡‰
                }

                # æ—‹è½‰æ¨¡å¼è¨­ç½®
                if rotation_mode == 'random':
                    # ç‚ºæ¯å€‹å€å¡Šå¤§å°ç”Ÿæˆéš¨æ©Ÿæ—‹è½‰è§’åº¦
                    block_rotations = {
                        size: np.random.choice([-270, -180, -90, 0, 90, 180, 270])
                        for size in all_block_sizes
                    }
                    # å¦‚æœä½¿ç”¨ç²¾ç¢ºå®¹é‡æ§åˆ¶ï¼Œè€ƒæ…®æ¸›å°‘æ—‹è½‰
                    if precise_control:
                        # æ¸›å°‘æ—‹è½‰ä»¥æé«˜åœ–åƒè³ªé‡
                        for size in [1024, 512, 256]:
                            block_rotations[size] = 0  # å¤§å€å¡Šä¸æ—‹è½‰
                            
                    stage_info['block_rotations'] = block_rotations
                    print("\nBlock rotation angles for this stage:")
                    for size, angle in sorted(block_rotations.items(), reverse=True):
                        print(f"  {size}x{size}: {angle}Â°")

                # è¨ˆç®—è¦è™•ç†çš„å¡Šæ•¸
                num_blocks_horizontal = width // max_block_size
                num_blocks_vertical = height // max_block_size
                print(f"Processing {num_blocks_horizontal}x{num_blocks_vertical} blocks of size {max_block_size}x{max_block_size}")
                
                # åˆå§‹åŒ–è¼¸å‡ºåœ–åƒ
                stage_img = cp.zeros_like(current_img)
                if rotation_mode == 'random':
                    rotated_stage_img = cp.zeros_like(current_img)
                    
                # é€å¡Šè™•ç†åœ–åƒ
                processed_blocks = []
                for i in range(num_blocks_vertical):
                    for j in range(num_blocks_horizontal):
                        # æª¢æŸ¥æ˜¯å¦å·²é”åˆ°ç›®æ¨™payload
                        if remaining_target is not None and remaining_target[0] <= 0:
                            # å¦‚æœå·²é”åˆ°ç›®æ¨™ï¼Œä¸è™•ç†å‰©é¤˜å€å¡Šç›´æ¥è¤‡è£½
                            y_start = i * max_block_size
                            x_start = j * max_block_size
                            stage_img[y_start:y_start+max_block_size, x_start:x_start+max_block_size] = current_img[y_start:y_start+max_block_size, x_start:x_start+max_block_size]
                            continue
                            
                        # æå–ç•¶å‰å¡Š
                        y_start = i * max_block_size
                        x_start = j * max_block_size
                        current_block = current_img[y_start:y_start+max_block_size, x_start:x_start+max_block_size]
                        
                        # è™•ç†ç•¶å‰å¡Šï¼Œå‚³éå¯è®Šå®¹å™¨
                        block_results = process_block(
                            current_block, (y_start, x_start), max_block_size, stage_info, embedding,
                            variance_threshold, ratio_of_ones, target_bpp, target_psnr, el_mode,
                            verbose=False, 
                            rotation_mode=rotation_mode,
                            prediction_method=prediction_method,
                            remaining_target=remaining_target,  # å‚³éå¯è®Šå®¹å™¨
                            max_block_size=max_block_size
                        )
                        
                        processed_blocks.extend(block_results)
                        
                        # å®šæœŸæ¸…ç†è¨˜æ†¶é«”
                        if (i * num_blocks_horizontal + j + 1) % 4 == 0:
                            cleanup_memory()

                # é‡å»ºåœ–åƒ - é—œéµä¿®æ”¹ï¼šç¢ºä¿æ­£ç¢ºè™•ç†æ—‹è½‰
                for block, pos, size, was_rotated in processed_blocks:
                    block = cp.asarray(block)
                    
                    # å°‡å€å¡Šæ”¾å›æœ€çµ‚åœ–åƒ - ç›´æ¥ä½¿ç”¨å·²ç¶“æ­£ç¢ºæ—‹è½‰çš„å€å¡Š
                    stage_img[pos[0]:pos[0]+size, pos[1]:pos[1]+size] = block
                    
                    # åƒ…åœ¨éœ€è¦æ—‹è½‰è¦–è¦ºåŒ–æ™‚ä¿å­˜æ—‹è½‰ç‹€æ…‹
                    if rotation_mode == 'random':
                        rotation = stage_info['block_rotations'].get(size, 0)
                        # å¦‚æœéœ€è¦ä¿å­˜æ—‹è½‰ç‹€æ…‹ï¼Œä½¿ç”¨åŸå§‹çš„æ—‹è½‰ç‰ˆæœ¬
                        if rotation != 0 and not was_rotated:
                            # å€å¡Šéœ€è¦å…ˆæ—‹è½‰ï¼Œæ‰èƒ½æ”¾å…¥rotated_stage_img
                            k = rotation // 90
                            rotated_block = cp.rot90(block, k=k)
                            rotated_stage_img[pos[0]:pos[0]+size, pos[1]:pos[1]+size] = rotated_block
                        else:
                            # ä½¿ç”¨å·²æ—‹è½‰çš„å€å¡Š
                            rotated_stage_img[pos[0]:pos[0]+size, pos[1]:pos[1]+size] = block

                # ä¿å­˜rotated_stage_imgä¾›è¦–è¦ºåŒ–ä½¿ç”¨
                if rotation_mode == 'random':
                    stage_info['rotated_stage_img'] = rotated_stage_img
                    
                    # å»ºç«‹æ—‹è½‰å¾Œçš„å€å¡Šè¦–è¦ºåŒ–
                    rotated_block_visualization = np.zeros_like(DataConverter.to_numpy(original_img))
                    
                    # å®šç¾©æ¯ç¨®å€å¡Šå¤§å°çš„é¡è‰²
                    block_colors = {
                        1024: 200,  # æ·ºç°è‰²
                        512: 180,   # ç¨æ·±ç°è‰²
                        256: 160,   # ä¸­ç°è‰²
                        128: 140,   # æ·±ç°è‰²
                        64: 120,    # æ›´æ·±ç°è‰²
                        32: 100,    # å¾ˆæ·±ç°è‰²
                        16: 80      # è¿‘ä¹é»‘è‰²
                    }
                    
                    # å‰µå»ºå¯è¦–åŒ– - ç¹ªè£½å¸¶æœ‰æ—‹è½‰å…§å®¹çš„å€å¡Š
                    for size_str in stage_info['block_info']:
                        size = int(size_str)
                        blocks = stage_info['block_info'][size_str]['blocks']
                        
                        # è·³éç©ºå€å¡Šå¤§å°
                        if not blocks:
                            continue
                            
                        for block_info in blocks:
                            y, x = block_info['position']
                            
                            # æ ¹æ“šå€å¡Šå¤§å°å‰µå»ºé‚Šæ¡†å¯¬åº¦
                            border_width = max(1, size // 64)
                            
                            # å¡«å……å€å¡Šå…§éƒ¨ç‚ºåŸå§‹å…§å®¹
                            block_area = rotated_stage_img[y:y+size, x:x+size]
                            if isinstance(block_area, cp.ndarray):
                                block_area = DataConverter.to_numpy(block_area)
                                
                            rotated_block_visualization[y:y+size, x:x+size] = block_area
                            
                            # åœ¨å€å¡Šå‘¨åœç¹ªè£½é‚Šæ¡†
                            rotated_block_visualization[y:y+border_width, x:x+size] = block_colors[size]  # ä¸Šé‚Šæ¡†
                            rotated_block_visualization[y+size-border_width:y+size, x:x+size] = block_colors[size]  # ä¸‹é‚Šæ¡†
                            rotated_block_visualization[y:y+size, x:x+border_width] = block_colors[size]  # å·¦é‚Šæ¡†
                            rotated_block_visualization[y:y+size, x+size-border_width:x+size] = block_colors[size]  # å³é‚Šæ¡†
                    
                    # ä¿å­˜æ—‹è½‰å€å¡Šè¦–è¦ºåŒ–
                    rotated_viz_path = f"{image_dir}/rotated_blocks/stage_{embedding}_blocks.png"
                    ensure_dir(rotated_viz_path)
                    save_image(rotated_block_visualization, rotated_viz_path)
                    
                    # æ·»åŠ åˆ°éšæ®µä¿¡æ¯
                    stage_info['rotated_block_visualization'] = rotated_block_visualization
                    
                    print(f"Saved rotated block visualization to {rotated_viz_path}")
                    
                    # å‰µå»ºæ—‹è½‰è§’åº¦è¦–è¦ºåŒ–
                    rotation_colors = {
                        0: [200, 200, 200],      # ç°è‰²è¡¨ç¤ºç„¡æ—‹è½‰
                        90: [200, 100, 100],     # ç´…è‰²èª¿è¡¨ç¤º90Â°
                        180: [100, 200, 100],    # ç¶ è‰²èª¿è¡¨ç¤º180Â°
                        270: [100, 100, 200],    # è—è‰²èª¿è¡¨ç¤º270Â°
                        -90: [200, 200, 100],    # é»ƒè‰²èª¿è¡¨ç¤º-90Â°
                        -180: [200, 100, 200],   # ç´«è‰²èª¿è¡¨ç¤º-180Â°
                        -270: [100, 200, 200]    # é’è‰²èª¿è¡¨ç¤º-270Â°
                    }
                    
                    # å‰µå»ºRGBå¯è¦–åŒ–
                    rotated_block_visualization_color = np.zeros((height, width, 3), dtype=np.uint8)
                    
                    # å…ˆå¡«å……ç°åº¦åœ–åƒ
                    gray_img = DataConverter.to_numpy(original_img)
                    for i in range(3):
                        rotated_block_visualization_color[:,:,i] = gray_img // 2  # æš—åŒ–åŸåœ–ä»¥ä¾¿é‚Šæ¡†æ›´æ˜é¡¯
                    
                    # æ ¹æ“šæ—‹è½‰è§’åº¦ç¹ªè£½å½©è‰²é‚Šæ¡†
                    for size_str in stage_info['block_info']:
                        size = int(size_str)
                        blocks = stage_info['block_info'][size_str]['blocks']
                        
                        # è·³éç©ºå€å¡Šå¤§å°
                        if not blocks:
                            continue
                            
                        for block_info in blocks:
                            y, x = block_info['position']
                            
                            # ç²å–æ­¤å€å¡Šå¤§å°çš„æ—‹è½‰è§’åº¦
                            rotation = stage_info['block_rotations'][size]
                            color = rotation_colors.get(rotation, [150, 150, 150])  # æœªæ‰¾åˆ°æ—‹è½‰æ™‚ä½¿ç”¨é»˜èªç°è‰²
                            
                            # é‚Šæ¡†å¯¬åº¦èˆ‡å€å¡Šå¤§å°æˆæ¯”ä¾‹
                            border_width = max(1, size // 64)
                            
                            # ç¹ªè£½å½©è‰²é‚Šæ¡†
                            rotated_block_visualization_color[y:y+border_width, x:x+size, :] = color  # ä¸Šæ–¹
                            rotated_block_visualization_color[y+size-border_width:y+size, x:x+size, :] = color  # ä¸‹æ–¹
                            rotated_block_visualization_color[y:y+size, x:x+border_width, :] = color  # å·¦å´
                            rotated_block_visualization_color[y:y+size, x+size-border_width:x+size, :] = color  # å³å´
                    
                    # ä¿å­˜å½©è‰²å¯è¦–åŒ–
                    color_viz_path = f"{image_dir}/rotated_blocks/stage_{embedding}_color.png"
                    ensure_dir(color_viz_path)
                    cv2.imwrite(color_viz_path, rotated_block_visualization_color)
                    
                    # æ·»åŠ åœ–ä¾‹
                    legend_img = np.ones((200, 400, 3), dtype=np.uint8) * 255  # ç™½è‰²èƒŒæ™¯
                    legend_title = "Rotation Angles Legend"
                    cv2.putText(legend_img, legend_title, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)
                    
                    # æ·»åŠ å„å€‹æ—‹è½‰è§’åº¦çš„é¡è‰²ç¤ºä¾‹
                    y_offset = 60
                    for angle, color in rotation_colors.items():
                        # ç¹ªè£½é¡è‰²æ–¹å¡Š
                        cv2.rectangle(legend_img, (10, y_offset), (40, y_offset+20), color, -1)
                        # æ·»åŠ æ–‡å­—èªªæ˜
                        cv2.putText(legend_img, f"{angle}Â°", (50, y_offset+15), 
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)
                        y_offset += 30
                    
                    # ä¿å­˜åœ–ä¾‹
                    legend_path = f"{image_dir}/rotated_blocks/legend.png"
                    ensure_dir(legend_path)
                    cv2.imwrite(legend_path, legend_img)
                    
                    # æ·»åŠ åˆ°éšæ®µä¿¡æ¯
                    stage_info['rotated_block_visualization_color'] = rotated_block_visualization_color
                    
                    print(f"Saved colored rotated block visualization to {color_viz_path}")
                
                stage_info['stage_img'] = stage_img

                # è¨ˆç®—å“è³ªæŒ‡æ¨™ - é€™è£¡ä½¿ç”¨æœªæ—‹è½‰çš„stage_img
                # çµ±ä¸€æ•¸æ“šè½‰æ›
                stage_img_np = DataConverter.to_numpy(stage_img)
                reference_img_np = DataConverter.to_numpy(original_img)

                # çµ±ä¸€å“è³ªæŒ‡æ¨™è¨ˆç®—
                psnr = calculate_psnr(reference_img_np, stage_img_np)
                ssim = calculate_ssim(reference_img_np, stage_img_np)

                # çµ±ä¸€ç›´æ–¹åœ–è¨ˆç®—
                hist_ref = np.histogram(reference_img_np, bins=256, range=(0, 255))[0]
                hist_stage = np.histogram(stage_img_np, bins=256, range=(0, 255))[0]
                hist_corr = histogram_correlation(hist_ref, hist_stage)

                # æ›´æ–°éšæ®µå“è³ªæŒ‡æ¨™
                stage_info['psnr'] = float(psnr)
                stage_info['ssim'] = float(ssim)
                stage_info['hist_corr'] = float(hist_corr)
                stage_info['bpp'] = float(stage_info['payload'] / total_pixels)

                # è¨ˆç®—ä¸¦é¡¯ç¤ºå€å¡Šå¤§å°åˆ†å¸ƒ
                block_counts = {}
                for size_str in stage_info['block_info']:
                    count = len(stage_info['block_info'][size_str]['blocks'])
                    if count > 0:
                        block_counts[size_str] = count
                
                # æ·»åŠ åˆ°éšæ®µä¿¡æ¯
                stage_info['block_counts'] = block_counts

                # å“è³ªæª¢æŸ¥å’Œè­¦å‘Š
                if psnr < 28 or ssim < 0.8:
                    print("Warning: Metrics seem unusually low")
                    # å¦‚æœä½¿ç”¨çš„æ˜¯randomæ—‹è½‰æ¨¡å¼ï¼Œæç¤ºå¯èƒ½æ˜¯æ—‹è½‰é€ æˆçš„
                    if rotation_mode == 'random':
                        print("This may be caused by the random rotation mode. Consider using rotation_mode='none'")

                # èˆ‡å‰ä¸€éšæ®µæ¯”è¼ƒ
                if embedding > 0:
                    if stage_info['payload'] >= previous_payload:
                        print(f"Warning: Stage {embedding} payload ({stage_info['payload']}) is not less than previous stage ({previous_payload}).")
                        stage_info['payload'] = int(previous_payload * 0.95)
                        print(f"Adjusted payload: {stage_info['payload']}")

                    if stage_info['psnr'] >= previous_psnr:
                        print(f"Warning: Stage {embedding} PSNR ({stage_info['psnr']:.2f}) is not less than previous stage ({previous_psnr:.2f}).")

                # æ›´æ–°ç¸½é«”è³‡è¨Š
                pee_stages.append(stage_info)
                total_payload += stage_info['payload']
                previous_psnr = stage_info['psnr']
                previous_ssim = stage_info['ssim']
                previous_payload = stage_info['payload']

                # è¼¸å‡ºéšæ®µæ‘˜è¦
                print(f"\nEmbedding {embedding} summary:")
                print(f"Prediction Method: {prediction_method.value}")
                print(f"Variance Threshold: {variance_threshold}")
                if adaptive_threshold:
                    print(f"Adaptive Threshold: Enabled ({search_mode} mode)")
                print(f"Payload: {stage_info['payload']}")
                print(f"BPP: {stage_info['bpp']:.4f}")
                print(f"PSNR: {stage_info['psnr']:.2f}")
                print(f"SSIM: {stage_info['ssim']:.4f}")
                print(f"Hist Corr: {stage_info['hist_corr']:.4f}")
                
                # è¼¸å‡ºå€å¡Šå¤§å°åˆ†å¸ƒ
                print("\nBlock size distribution:")
                for size_str in sorted(block_counts.keys(), key=int, reverse=True):
                    print(f"  {size_str}x{size_str}: {block_counts[size_str]} blocks")
                
                # è¼¸å‡ºç›®æ¨™payloadè³‡è¨Š
                if remaining_target is not None:
                    if remaining_target[0] <= 0:
                        print(f"\nTarget payload of {target_payload_size} bits reached")
                        # å¦‚æœè¨­ç½®äº†ç²¾ç¢ºæ§åˆ¶ç›®æ¨™ï¼Œæª¢æŸ¥å¯¦éš›åµŒå…¥é‡èˆ‡ç›®æ¨™çš„å·®è·
                        if precise_control:
                            difference = total_payload - target_payload_size
                            if difference != 0:
                                print(f"Actual payload ({total_payload}) differs from target ({target_payload_size}) by {difference} bits")
                                print(f"Accuracy: {total_payload/target_payload_size*100:.2f}%")
                    else:
                        print(f"\nRemaining target payload: {remaining_target[0]} bits")
                
                # ç²¾ç¢ºæ§åˆ¶ï¼šå˜—è©¦é”åˆ°ç¢ºåˆ‡çš„ç›®æ¨™payload
                if precise_control and target_payload_size > total_payload:
                    # å¦‚æœå°‘æ–¼ç›®æ¨™å€¼ä¸”å·®è·ä¸å¤§ï¼Œå˜—è©¦å¡«å……å·®è·
                    shortfall = target_payload_size - total_payload
                    if 0 < shortfall <= 1000:  # å°æ–¼1000ä½çš„å·®è·å¯ä»¥å˜—è©¦å¡«å……
                        print(f"Attempting to fill missing {shortfall} bits to match exact target")
                        # å¯ä»¥åœ¨é€™è£¡å¯¦ç¾bit stuffingé‚è¼¯
                
                # æº–å‚™ä¸‹ä¸€éšæ®µ
                current_img = stage_img.copy()

                # æ¸…ç†ç•¶å‰éšæ®µçš„è¨˜æ†¶é«”
                cleanup_memory()
                print(f"Memory usage after embedding {embedding}: {mem_pool.used_bytes()/1024/1024:.2f} MB")

            # å¦‚æœåœ–åƒä¹‹å‰é€²è¡Œäº†å¢Šå……ï¼Œç¾åœ¨éœ€è¦è£å‰ªå›åŸå§‹å¤§å°
            final_pee_img = DataConverter.to_numpy(current_img)
            
            # æ·»åŠ è‡ªé©æ‡‰thresholdä½¿ç”¨æƒ…æ³åˆ°æœ€çµ‚çµæœæ‘˜è¦
            if adaptive_threshold:
                print(f"\n{'='*60}")
                print(f"Adaptive Threshold Summary")
                print(f"{'='*60}")
                print(f"Search mode used: {search_mode}")
                print(f"Final threshold used: {variance_threshold}")
                print(f"Target BPP for search: {target_bpp_for_search:.4f}")
                print(f"Target PSNR for search: {target_psnr_for_search:.2f}")
            
            # è¿”å›æœ€çµ‚çµæœ
            return final_pee_img, int(total_payload), pee_stages

        except Exception as e:
            print(f"Error in embedding process: {str(e)}")
            import traceback
            traceback.print_exc()
            raise

    except Exception as e:
        print(f"Error in quadtree processing: {str(e)}")
        import traceback
        traceback.print_exc()
        raise

    finally:
        # ç¢ºä¿æ¸…ç†æ‰€æœ‰è¨˜æ†¶é«”
        cleanup_memory()
        
def pee_process_color_image_quadtree_cuda(img, total_embeddings, ratio_of_ones, use_different_weights, 
                                       min_block_size, variance_threshold, el_mode, 
                                       rotation_mode='random',
                                       prediction_method=None,
                                       target_payload_size=-1,
                                       max_block_size=None,
                                       imgName=None,
                                       output_dir=None,
                                       adaptive_threshold=False,
                                       search_mode='balanced',
                                       target_bpp_for_search=0.8,
                                       target_psnr_for_search=35.0):
    """
    Process a color image using quadtree PEE method with enhanced color visualization and adaptive threshold support.
    
    ğŸ”§ ä¿®å¾©å…§å®¹ï¼š
    1. å®¹é‡åˆ†é…æ›´å‡å‹»ï¼Œé¿å…ç´…è‰²é€šé“éè¼‰
    2. BPPè¨ˆç®—ä½¿ç”¨æ­£ç¢ºçš„ç¸½payload/åƒç´ ä½ç½®æ•¸å…¬å¼
    3. æ”¯æŒå½©è‰²åœ–åƒé”åˆ°3å€ç°éšå®¹é‡
    
    Parameters:
    -----------
    æ‰€æœ‰åŸæœ‰åƒæ•¸ä¿æŒä¸è®Šï¼Œæ–°å¢ä»¥ä¸‹åƒæ•¸ï¼š
    adaptive_threshold : bool, optional
        æ˜¯å¦ä½¿ç”¨è‡ªé©æ‡‰variance thresholdæœç´¢ï¼Œé»˜èªFalse
    search_mode : str, optional
        è‡ªé©æ‡‰æœç´¢æ¨¡å¼ ('fast', 'balanced', 'thorough')ï¼Œé»˜èª'balanced'
    target_bpp_for_search : float, optional
        è‡ªé©æ‡‰æœç´¢çš„ç›®æ¨™BPPï¼Œé»˜èª0.8
    target_psnr_for_search : float, optional
        è‡ªé©æ‡‰æœç´¢çš„ç›®æ¨™PSNRï¼Œé»˜èª35.0
    """
    if prediction_method is None:
        from image_processing import PredictionMethod
        prediction_method = PredictionMethod.PROPOSED
    
    # è‡ªé©æ‡‰variance thresholdæœç´¢ï¼ˆé‡å°å½©è‰²åœ–åƒï¼‰
    if adaptive_threshold:
        print(f"\n{'='*60}")
        print(f"Adaptive Variance Threshold Search for Color Image")
        print(f"{'='*60}")
        print(f"Original threshold: {variance_threshold}")
        print(f"Search mode: {search_mode}")
        print(f"Target BPP: {target_bpp_for_search:.4f}")
        print(f"Target PSNR: {target_psnr_for_search:.2f}")
        
        try:
            # å°å½©è‰²åœ–åƒï¼Œä½¿ç”¨è—è‰²é€šé“é€²è¡Œè‡ªé©æ‡‰æœç´¢
            b_channel, _, _ = split_color_channels(img)
            
            optimal_threshold = get_adaptive_variance_threshold(
                img=b_channel,  # ä½¿ç”¨è—è‰²é€šé“é€²è¡Œæœç´¢
                ratio_of_ones=ratio_of_ones,
                min_block_size=min_block_size,
                el_mode=el_mode,
                prediction_method=prediction_method,
                target_bpp=target_bpp_for_search,
                target_psnr=target_psnr_for_search,
                search_mode=search_mode,
                use_different_weights=use_different_weights
            )
            
            print(f"Adaptive search completed for color image!")
            print(f"Original threshold: {variance_threshold}")
            print(f"Optimal threshold: {optimal_threshold}")
            print(f"Improvement: {((optimal_threshold - variance_threshold) / variance_threshold * 100):+.1f}%")
            print(f"This threshold will be applied to all color channels.")
            
            # ä½¿ç”¨æ‰¾åˆ°çš„æœ€ä½³threshold
            variance_threshold = optimal_threshold
            
        except Exception as e:
            print(f"Warning: Adaptive threshold search failed for color image: {str(e)}")
            print(f"Falling back to original threshold: {variance_threshold}")
    else:
        print(f"Using fixed variance threshold for color image: {variance_threshold}")
    
    # Split color image into channels
    b_channel, g_channel, r_channel = split_color_channels(img)
    
    # Track total payload across all channels
    total_payload = 0
    
    # ğŸ¨ å‰µå»ºå¢å¼·çš„ç›®éŒ„çµæ§‹
    if imgName and output_dir:
        channels_dir = f"{output_dir}/image/{imgName}/quadtree/channels"
        os.makedirs(channels_dir, exist_ok=True)
        
        # ğŸ¨ æ–°å¢ï¼šç‚ºå½©è‰²é€šé“è¦–è¦ºåŒ–å‰µå»ºç›®éŒ„
        colored_channels_dir = f"{output_dir}/image/{imgName}/quadtree/channels/colored"
        os.makedirs(colored_channels_dir, exist_ok=True)
    
    color_pee_stages = []
    
    # ğŸ”§ ä¿®å¾©1ï¼šæ”¹é€²å®¹é‡åˆ†é…é‚è¼¯
    if target_payload_size > 0:
        # âœ… ä¿®å¾©ï¼šå‡å‹»åˆ†é…ç­–ç•¥ï¼Œé¿å…ç´…è‰²é€šé“éè¼‰
        base_allocation = target_payload_size // 3
        remainder = target_payload_size % 3
        
        channel_targets = [base_allocation] * 3
        # å°‡é¤˜æ•¸å¹³å‡åˆ†é…çµ¦å‰å¹¾å€‹é€šé“
        for i in range(remainder):
            channel_targets[i] += 1
            
        blue_target, green_target, red_target = channel_targets
        
        print(f"âœ… ä¿®å¾©å¾Œçš„å‡å‹»å®¹é‡åˆ†é…:")
        print(f"   Blue: {blue_target:,} bits")
        print(f"   Green: {green_target:,} bits") 
        print(f"   Red: {red_target:,} bits")
        print(f"   è² è¼‰å‡è¡¡æ¯”ä¾‹: {max(channel_targets)/min(channel_targets):.3f}x")
        print(f"Using adaptive threshold: {variance_threshold} for all channels")
    else:
        channel_targets = [-1, -1, -1]
        print(f"âœ… ä½¿ç”¨æœ€å¤§å®¹é‡æ¨¡å¼ - æ¯å€‹é€šé“å¯é”åˆ°ç°éšåœ–åƒçš„æœ€å¤§å®¹é‡")
        print(f"   ç†è«–ç¸½å®¹é‡: ç´„3å€ç­‰æ•ˆç°éšåœ–åƒå®¹é‡")
        print(f"Using maximum capacity with threshold: {variance_threshold}")
    
    # Process each channel separately
    print("\nProcessing blue channel...")
    final_b_img, b_payload, b_stages = pee_process_with_quadtree_cuda(
        b_channel, total_embeddings, ratio_of_ones, use_different_weights,
        min_block_size, variance_threshold, el_mode, rotation_mode,
        prediction_method=prediction_method,
        target_payload_size=channel_targets[0],
        max_block_size=max_block_size,
        imgName=f"{imgName}_blue" if imgName else None,
        output_dir=output_dir,
        adaptive_threshold=False,  # å·²ç¶“å®Œæˆè‡ªé©æ‡‰æœç´¢ï¼Œä¸éœ€è¦é‡è¤‡
        search_mode=search_mode,
        target_bpp_for_search=target_bpp_for_search,
        target_psnr_for_search=target_psnr_for_search
    )
    total_payload += b_payload
    
    # ğŸ¨ ä¿å­˜è—è‰²é€šé“çµæœï¼ˆç°éšå’Œå½©è‰²ç‰ˆæœ¬ï¼‰
    if imgName and output_dir:
        # åŸå§‹ç°éšç‰ˆæœ¬
        cv2.imwrite(f"{channels_dir}/{imgName}_blue_final.png", final_b_img)
        # ğŸ¨ æ–°å¢ï¼šå½©è‰²ç‰ˆæœ¬
        blue_colored = convert_single_channel_to_color(final_b_img, 'blue')
        cv2.imwrite(f"{colored_channels_dir}/{imgName}_blue_final_colored.png", blue_colored)
    
    # Clean GPU memory between channel processing
    cleanup_memory()
    
    print("\nProcessing green channel...")
    final_g_img, g_payload, g_stages = pee_process_with_quadtree_cuda(
        g_channel, total_embeddings, ratio_of_ones, use_different_weights,
        min_block_size, variance_threshold, el_mode, rotation_mode,
        prediction_method=prediction_method,
        target_payload_size=channel_targets[1],
        max_block_size=max_block_size,
        imgName=f"{imgName}_green" if imgName else None,
        output_dir=output_dir,
        adaptive_threshold=False,  # å·²ç¶“å®Œæˆè‡ªé©æ‡‰æœç´¢ï¼Œä¸éœ€è¦é‡è¤‡
        search_mode=search_mode,
        target_bpp_for_search=target_bpp_for_search,
        target_psnr_for_search=target_psnr_for_search
    )
    total_payload += g_payload
    
    # ğŸ¨ ä¿å­˜ç¶ è‰²é€šé“çµæœï¼ˆç°éšå’Œå½©è‰²ç‰ˆæœ¬ï¼‰
    if imgName and output_dir:
        # åŸå§‹ç°éšç‰ˆæœ¬
        cv2.imwrite(f"{channels_dir}/{imgName}_green_final.png", final_g_img)
        # ğŸ¨ æ–°å¢ï¼šå½©è‰²ç‰ˆæœ¬
        green_colored = convert_single_channel_to_color(final_g_img, 'green')
        cv2.imwrite(f"{colored_channels_dir}/{imgName}_green_final_colored.png", green_colored)
    
    # Clean GPU memory between channel processing
    cleanup_memory()
    
    print("\nProcessing red channel...")
    final_r_img, r_payload, r_stages = pee_process_with_quadtree_cuda(
        r_channel, total_embeddings, ratio_of_ones, use_different_weights,
        min_block_size, variance_threshold, el_mode, rotation_mode,
        prediction_method=prediction_method,
        target_payload_size=channel_targets[2],
        max_block_size=max_block_size,
        imgName=f"{imgName}_red" if imgName else None,
        output_dir=output_dir,
        adaptive_threshold=False,  # å·²ç¶“å®Œæˆè‡ªé©æ‡‰æœç´¢ï¼Œä¸éœ€è¦é‡è¤‡
        search_mode=search_mode,
        target_bpp_for_search=target_bpp_for_search,
        target_psnr_for_search=target_psnr_for_search
    )
    total_payload += r_payload
    
    # ğŸ¨ ä¿å­˜ç´…è‰²é€šé“çµæœï¼ˆç°éšå’Œå½©è‰²ç‰ˆæœ¬ï¼‰
    if imgName and output_dir:
        # åŸå§‹ç°éšç‰ˆæœ¬
        cv2.imwrite(f"{channels_dir}/{imgName}_red_final.png", final_r_img)
        # ğŸ¨ æ–°å¢ï¼šå½©è‰²ç‰ˆæœ¬
        red_colored = convert_single_channel_to_color(final_r_img, 'red')
        cv2.imwrite(f"{colored_channels_dir}/{imgName}_red_final_colored.png", red_colored)
    
    # Combine channels back into a color image
    final_color_img = combine_color_channels(final_b_img, final_g_img, final_r_img)
    
    # ğŸ”§ ä¿®å¾©2ï¼šå‰µå»ºèˆ‡ç°éšä¸€è‡´çš„éšæ®µä¿¡æ¯çµæ§‹ï¼Œä¸¦ä¿®å¾©BPPè¨ˆç®—
    for i in range(min(len(b_stages), len(g_stages), len(r_stages))):
        # Get stage info from each channel
        b_stage = b_stages[i]
        g_stage = g_stages[i]
        r_stage = r_stages[i]
        
        # ğŸ”§ ä¿®å¾©ï¼šæ­£ç¢ºè¨ˆç®—ç¸½payloadå’ŒBPP
        stage_total_payload = b_stage['payload'] + g_stage['payload'] + r_stage['payload']
        pixel_positions = img.shape[0] * img.shape[1]  # åƒç´ ä½ç½®æ•¸ï¼ˆä¸åŒ…æ‹¬é€šé“ç¶­åº¦ï¼‰
        correct_bpp = stage_total_payload / pixel_positions
        
        print(f"\nğŸ”§ Stage {i} BPPä¿®å¾©:")
        print(f"   å„é€šé“payload: B={b_stage['payload']:,}, G={g_stage['payload']:,}, R={r_stage['payload']:,}")
        print(f"   ç¸½payload: {stage_total_payload:,} bits")
        print(f"   åƒç´ ä½ç½®æ•¸: {pixel_positions:,}")
        print(f"   æ­£ç¢ºBPP: {correct_bpp:.6f}")
        
        # ğŸ”§ ä¿®æ”¹ï¼šç¢ºä¿èˆ‡ç°éšåœ–åƒçµæ§‹å®Œå…¨ä¸€è‡´ï¼Œä½¿ç”¨æ­£ç¢ºçš„BPPè¨ˆç®—
        combined_stage = {
            'embedding': b_stage['embedding'],
            'payload': stage_total_payload,  # âœ… ä½¿ç”¨ç¸½payload
            'bpp': correct_bpp,  # âœ… ä½¿ç”¨æ­£ç¢ºçš„BPPè¨ˆç®—å…¬å¼
            'psnr': (b_stage['psnr'] + g_stage['psnr'] + r_stage['psnr']) / 3,
            'ssim': (b_stage['ssim'] + g_stage['ssim'] + r_stage['ssim']) / 3,
            'hist_corr': (b_stage['hist_corr'] + g_stage['hist_corr'] + r_stage['hist_corr']) / 3,
            
            # ğŸ”§ æ–°å¢ï¼šç¢ºä¿åŒ…å«èˆ‡ç°éšä¸€è‡´çš„å¿…è¦æ¬„ä½
            'rotation_mode': b_stage.get('rotation_mode', rotation_mode),
            'prediction_method': b_stage.get('prediction_method', prediction_method.value),
            'variance_threshold': variance_threshold,  # æ–°å¢ï¼šè¨˜éŒ„ä½¿ç”¨çš„threshold
            'adaptive_threshold_used': adaptive_threshold,  # æ–°å¢ï¼šè¨˜éŒ„æ˜¯å¦ä½¿ç”¨äº†è‡ªé©æ‡‰
            
            # ğŸ”§ ä¿®æ”¹ï¼šé‡æ§‹block_infoç‚ºèˆ‡ç°éšä¸€è‡´çš„çµæ§‹
            'block_info': {},  # å…ˆåˆå§‹åŒ–ç‚ºç©ºï¼Œä¸‹é¢å¡«å……
            
            # å½©è‰²åœ–åƒç‰¹æœ‰çš„è©³ç´°ä¿¡æ¯ï¼ˆä¿æŒå‘å¾Œå…¼å®¹ï¼‰
            'channel_payloads': {
                'blue': b_stage['payload'],
                'green': g_stage['payload'],
                'red': r_stage['payload']
            },
            'channel_metrics': {
                'blue': {'psnr': b_stage['psnr'], 'ssim': b_stage['ssim'], 'hist_corr': b_stage['hist_corr']},
                'green': {'psnr': g_stage['psnr'], 'ssim': g_stage['ssim'], 'hist_corr': g_stage['hist_corr']},
                'red': {'psnr': r_stage['psnr'], 'ssim': r_stage['ssim'], 'hist_corr': r_stage['hist_corr']}
            },
            
            # ä¿ç•™åŸå§‹é€šé“block_infoï¼ˆç”¨æ–¼è©³ç´°åˆ†æï¼‰
            'channel_block_info': {
                'blue': b_stage['block_info'],
                'green': g_stage['block_info'],
                'red': r_stage['block_info']
            }
        }
        
        # ğŸ”§ ä¿®æ”¹ï¼šåˆä½µblock_infoç‚ºèˆ‡ç°éšä¸€è‡´çš„æ‰å¹³çµæ§‹
        all_sizes = set(b_stage['block_info'].keys()) | set(g_stage['block_info'].keys()) | set(r_stage['block_info'].keys())
        for size_str in all_sizes:
            merged_blocks = []
            
            # æ”¶é›†å„é€šé“çš„å€å¡Šï¼Œæ·»åŠ é€šé“æ¨™è­˜
            for channel_name, channel_stage in [('blue', b_stage), ('green', g_stage), ('red', r_stage)]:
                if size_str in channel_stage['block_info']:
                    for block in channel_stage['block_info'][size_str]['blocks']:
                        merged_block = block.copy()
                        merged_block['channel'] = channel_name  # æ·»åŠ é€šé“è­˜åˆ¥
                        merged_blocks.append(merged_block)
            
            if merged_blocks:
                combined_stage['block_info'][size_str] = {'blocks': merged_blocks}
        
        # ğŸ”§ æ–°å¢ï¼šåˆä½µéšæ®µåœ–åƒ
        if 'stage_img' in b_stage and 'stage_img' in g_stage and 'stage_img' in r_stage:
            # çµ±ä¸€æ•¸æ“šè½‰æ›ï¼Œé¿å…è¤‡é›œçš„é¡å‹æª¢æŸ¥
            b_stage_img = DataConverter.to_numpy(b_stage['stage_img'])
            g_stage_img = DataConverter.to_numpy(g_stage['stage_img'])
            r_stage_img = DataConverter.to_numpy(r_stage['stage_img'])
            
            combined_stage['stage_img'] = combine_color_channels(b_stage_img, g_stage_img, r_stage_img)
        
        # ğŸ”§ æ–°å¢ï¼šåˆä½µæ—‹è½‰è¦–è¦ºåŒ–åœ–åƒï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'rotated_stage_img' in b_stage and 'rotated_stage_img' in g_stage and 'rotated_stage_img' in r_stage:
            try:
                b_rotated = DataConverter.to_numpy(b_stage['rotated_stage_img']) if isinstance(b_stage['rotated_stage_img'], cp.ndarray) else b_stage['rotated_stage_img']
                g_rotated = DataConverter.to_numpy(g_stage['rotated_stage_img']) if isinstance(g_stage['rotated_stage_img'], cp.ndarray) else g_stage['rotated_stage_img']
                r_rotated = DataConverter.to_numpy(r_stage['rotated_stage_img']) if isinstance(r_stage['rotated_stage_img'], cp.ndarray) else r_stage['rotated_stage_img']
                
                combined_stage['rotated_stage_img'] = combine_color_channels(b_rotated, g_rotated, r_rotated)
            except Exception as e:
                print(f"Warning: Could not combine rotated stage images: {e}")
        
        # ğŸ”§ æ–°å¢ï¼šåˆä½µå€å¡Šè¦–è¦ºåŒ–ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if all('rotated_block_visualization' in stage for stage in [b_stage, g_stage, r_stage]):
            try:
                # å–è—è‰²é€šé“çš„å€å¡Šè¦–è¦ºåŒ–ä½œç‚ºåŸºç¤
                combined_stage['rotated_block_visualization'] = b_stage['rotated_block_visualization']
                
                # å¦‚æœæœ‰å½©è‰²ç‰ˆæœ¬ï¼Œå‰‡ä½¿ç”¨å½©è‰²ç‰ˆæœ¬
                if 'rotated_block_visualization_color' in b_stage:
                    combined_stage['rotated_block_visualization_color'] = b_stage['rotated_block_visualization_color']
            except Exception as e:
                print(f"Warning: Could not combine block visualizations: {e}")
        
        # ğŸ”§ æ–°å¢ï¼šæ·»åŠ å€å¡Šè¨ˆæ•¸ä¿¡æ¯ï¼ˆèˆ‡ç°éšä¸€è‡´ï¼‰
        if 'block_counts' in b_stage:
            combined_block_counts = {}
            for stage in [b_stage, g_stage, r_stage]:
                if 'block_counts' in stage:
                    for size_str, count in stage['block_counts'].items():
                        if size_str not in combined_block_counts:
                            combined_block_counts[size_str] = 0
                        combined_block_counts[size_str] += count
            combined_stage['block_counts'] = combined_block_counts
        
        # ğŸ¨ æ–°å¢ï¼šå¢å¼·çš„è¦–è¦ºåŒ–è™•ç†
        if imgName and output_dir and prediction_method.value.upper() == "PROPOSED":
            image_dir = f"{output_dir}/image/{imgName}/quadtree"
            
            # ğŸ¨ è™•ç† with_grid çš„å¢å¼·è¦–è¦ºåŒ–
            if 'channel_block_info' in combined_stage:
                enhance_with_grid_visualization(
                    combined_stage, b_stage_img, g_stage_img, r_stage_img, 
                    image_dir, i
                )
            
            # ğŸ¨ è™•ç† block_size_visualizations çš„å¢å¼·è¦–è¦ºåŒ–
            if 'channel_block_info' in combined_stage:
                enhance_block_visualizations(
                    combined_stage, img, image_dir, i
                )
            
        # Add stage to combined stages
        color_pee_stages.append(combined_stage)
        
        # Save stage image if imgName is provided
        if imgName and output_dir and 'stage_img' in combined_stage:
            stage_dir = f"{output_dir}/image/{imgName}/quadtree"
            os.makedirs(stage_dir, exist_ok=True)
            cv2.imwrite(f"{stage_dir}/color_stage_{i}_result.png", combined_stage['stage_img'])
    
    # ğŸ¨ æœ€çµ‚çµæœçš„å¢å¼·è¦–è¦ºåŒ–
    if imgName and output_dir and prediction_method.value.upper() == "PROPOSED":
        enhance_final_visualizations(
            color_pee_stages, final_b_img, final_g_img, final_r_img,
            f"{output_dir}/image/{imgName}/quadtree"
        )
    
    # æ·»åŠ è‡ªé©æ‡‰thresholdä½¿ç”¨æƒ…æ³åˆ°æœ€çµ‚çµæœæ‘˜è¦
    if adaptive_threshold:
        print(f"\n{'='*60}")
        print(f"Color Image Adaptive Threshold Summary")
        print(f"{'='*60}")
        print(f"Search mode used: {search_mode}")
        print(f"Final threshold used for all channels: {variance_threshold}")
        print(f"Target BPP for search: {target_bpp_for_search:.4f}")
        print(f"Target PSNR for search: {target_psnr_for_search:.2f}")
        print(f"Search performed on: Blue channel (applied to all)")
        
        # è¼¸å‡ºå„é€šé“çš„æœ€çµ‚æŒ‡æ¨™
        if color_pee_stages:
            final_stage = color_pee_stages[-1]
            print("\nFinal channel results with adaptive threshold:")
            for ch_name, metrics in final_stage['channel_metrics'].items():
                print(f"  {ch_name.capitalize()}: Payload={final_stage['channel_payloads'][ch_name]}, "
                      f"PSNR={metrics['psnr']:.2f}, SSIM={metrics['ssim']:.4f}")
    
    # ğŸ”§ ä¿®å¾©ï¼šæœ€çµ‚çµæœè¼¸å‡ºï¼Œé¡¯ç¤ºä¿®å¾©æ•ˆæœ
    print(f"\n{'='*60}")
    print(f"âœ… å½©è‰²åœ–åƒè™•ç†å®Œæˆ - ä¿®å¾©å¾Œçµæœ")
    print(f"{'='*60}")
    print(f"ç¸½åµŒå…¥å®¹é‡: {total_payload:,} bits")
    print(f"åƒç´ ä½ç½®æ•¸: {img.shape[0] * img.shape[1]:,}")
    print(f"æœ€çµ‚BPP: {total_payload / (img.shape[0] * img.shape[1]):.6f}")
    print(f"å„é€šé“å®¹é‡:")
    print(f"  Blue: {b_payload:,} bits")
    print(f"  Green: {g_payload:,} bits") 
    print(f"  Red: {r_payload:,} bits")
    print(f"é€šé“è² è¼‰å‡è¡¡æ¯”ä¾‹: {max(b_payload, g_payload, r_payload) / min(b_payload, g_payload, r_payload):.3f}x")
    
    # ğŸ”§ ä¿®å¾©å¾Œçš„å®¹é‡æ¯”è¼ƒ
    equivalent_grayscale_capacity = (img.shape[0] * img.shape[1]) * 0.8  # å‡è¨­80%åµŒå…¥ç‡
    capacity_multiplier = total_payload / equivalent_grayscale_capacity
    print(f"ç›¸å°æ–¼ç­‰æ•ˆç°éšåœ–åƒå®¹é‡: {capacity_multiplier:.2f}x")
    
    if capacity_multiplier >= 2.5:
        print("âœ… æˆåŠŸé”åˆ°æ¥è¿‘3å€ç°éšå®¹é‡ï¼")
    elif capacity_multiplier >= 2.0:
        print("ğŸŸ¡ é”åˆ°2å€ä»¥ä¸Šç°éšå®¹é‡ï¼Œè¡¨ç¾è‰¯å¥½")
    else:
        print("ğŸ”´ å®¹é‡æœªé”åˆ°é æœŸï¼Œå¯èƒ½éœ€è¦é€²ä¸€æ­¥èª¿æ•´åƒæ•¸")
    
    return final_color_img, total_payload, color_pee_stages