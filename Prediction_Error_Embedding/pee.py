import numpy as np
import cupy as cp
from numba import cuda
import itertools
import math
from image_processing import PredictionMethod, predict_image_cuda

# =============================================================================
# EL (Embedding Level) è¨ˆç®—ç›¸é—œå‡½æ•¸
# =============================================================================

@cuda.jit
def compute_improved_adaptive_el_kernel(img, local_el, window_size, max_el, block_size):
    """
    è¨ˆç®—æ”¹é€²çš„è‡ªé©æ‡‰ELå€¼çš„CUDA kernelï¼Œå„ªåŒ–ç‰ˆæœ¬
    ä¿®æ”¹ï¼šELå€¼ç¯„åœæ”¹ç‚º1~15ï¼Œä¸å†é™åˆ¶ç‚ºå¥‡æ•¸
    """
    x, y = cuda.grid(2)
    if x < img.shape[1] and y < img.shape[0]:
        # æ ¹æ“šå€å¡Šå¤§å°èª¿æ•´window_size
        actual_window_size = window_size
        if block_size > 0:  # ä½¿ç”¨æ­£æ•¸ä¾†åˆ¤æ–·æ˜¯å¦æœ‰æŒ‡å®šblock_size
            if block_size >= 512:
                actual_window_size = min(window_size + 3, 9)  # æ›´å¤§çš„è¦–çª—é©åˆ1024å¤§å°çš„åœ–åƒ
            elif block_size >= 256:
                actual_window_size = min(window_size + 2, 7)
            elif block_size <= 64:
                actual_window_size = max(window_size - 1, 3)
        
        half_window = actual_window_size // 2
        
        # è¨ˆç®—å±€éƒ¨çµ±è¨ˆé‡
        local_sum = 0
        local_sum_sq = 0
        count = 0
        
        for i in range(max(0, y - half_window), min(img.shape[0], y + half_window + 1)):
            for j in range(max(0, x - half_window), min(img.shape[1], x + half_window + 1)):
                pixel_value = img[i, j]
                local_sum += pixel_value
                local_sum_sq += pixel_value * pixel_value
                count += 1
        
        local_mean = local_sum / count
        local_variance = (local_sum_sq / count) - (local_mean * local_mean)
        
        # ä¿®æ”¹ï¼šèª¿æ•´varianceæ­£è¦åŒ–ç­–ç•¥ï¼Œæ˜ å°„åˆ°1~15ç¯„åœ
        max_variance = 6400  # é è¨­å€¼
        if block_size > 0:
            if block_size >= 512:
                max_variance = 10000  # é‡å°æ›´å¤§çš„åœ–åƒèª¿æ•´æ­¤å€¼
            elif block_size >= 256:
                max_variance = 8100
            elif block_size <= 64:
                max_variance = 4900
        
        # æ­£è¦åŒ–varianceåˆ°0~1ç¯„åœ
        normalized_variance = min(local_variance / max_variance, 1)
        
        # ä¿®æ”¹ï¼šæ˜ å°„åˆ°1~15ç¯„åœï¼Œä¸å†é™åˆ¶ç‚ºå¥‡æ•¸
        # ä½¿ç”¨åæ¯”é—œä¿‚ï¼švarianceè¶Šé«˜ï¼ŒELè¶Šå°ï¼ˆæ›´ä¿å®ˆï¼‰
        el_value = int(15 - normalized_variance * 14)  # 15 - (0~14) = 15~1
        
        # ç¢ºä¿ELå€¼åœ¨1~15ç¯„åœå…§ï¼ˆç§»é™¤å¥‡æ•¸é™åˆ¶ï¼‰
        el_value = max(1, min(el_value, max_el))
        
        local_el[y, x] = el_value

def compute_improved_adaptive_el(img, window_size=5, max_el=15, block_size=None):
    """
    è¨ˆç®—æ”¹é€²çš„è‡ªé©æ‡‰ELå€¼
    ä¿®æ”¹ï¼šmax_elé è¨­æ”¹ç‚º15ï¼Œæ”¯æ´1~15ç¯„åœ
    """
    if isinstance(img, cp.ndarray):
        img = cp.asnumpy(img)
    
    local_el = cuda.device_array(img.shape, dtype=cp.int32)
    
    threads_per_block = (16, 16)
    blocks_per_grid_x = (img.shape[1] + threads_per_block[0] - 1) // threads_per_block[0]
    blocks_per_grid_y = (img.shape[0] + threads_per_block[1] - 1) // threads_per_block[1]
    blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)
    
    # å°‡Noneè½‰æ›ç‚º-1ï¼Œé€™æ¨£åœ¨kernelä¸­å¯ä»¥æ­£ç¢ºè™•ç†
    block_size_value = -1 if block_size is None else block_size
    
    compute_improved_adaptive_el_kernel[blocks_per_grid, threads_per_block](
        img, local_el, window_size, max_el, block_size_value
    )
    
    return local_el

# =============================================================================
# Variance è¨ˆç®—ç›¸é—œå‡½æ•¸
# =============================================================================

@cuda.jit
def calculate_variance_kernel(block, variance_result):
    """
    CUDA kernel for calculating variance of image blocks
    """
    x, y = cuda.grid(2)
    if x < block.shape[1] and y < block.shape[0]:
        # ä½¿ç”¨shared memoryä¾†å„ªåŒ–æ€§èƒ½
        tid = cuda.threadIdx.x + cuda.threadIdx.y * cuda.blockDim.x
        block_size = block.shape[0] * block.shape[1]
        
        # è¨ˆç®—å€åŸŸå¹³å‡å€¼
        local_sum = 0
        local_sum_sq = 0
        for i in range(block.shape[0]):
            for j in range(block.shape[1]):
                pixel_value = block[i, j]
                local_sum += pixel_value
                local_sum_sq += pixel_value * pixel_value
        
        mean = local_sum / block_size
        variance = (local_sum_sq / block_size) - (mean * mean)
        
        # åªéœ€è¦ä¸€å€‹ç·šç¨‹å¯«å…¥çµæœ
        if x == 0 and y == 0:
            variance_result[0] = variance

def calculate_block_variance_cuda(block):
    """
    Calculate variance of a block using CUDA
    """
    threads_per_block = (16, 16)
    blocks_per_grid_x = (block.shape[1] + threads_per_block[0] - 1) // threads_per_block[0]
    blocks_per_grid_y = (block.shape[0] + threads_per_block[1] - 1) // threads_per_block[1]
    blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)
    
    variance_result = cuda.device_array(1, dtype=np.float32)
    
    calculate_variance_kernel[blocks_per_grid, threads_per_block](block, variance_result)
    
    return variance_result[0]

# =============================================================================
# æ¬Šé‡æœç´¢ç›¸é—œå‡½æ•¸
# =============================================================================

def brute_force_weight_search_cuda(img, data, local_el, target_bpp, target_psnr, stage, block_size=None):
    """
    ä½¿ç”¨æš´åŠ›æœç´¢æ‰¾åˆ°æœ€ä½³çš„æ¬Šé‡çµ„åˆ
    
    Parameters:
    -----------
    img : numpy.ndarray or cupy.ndarray
        è¼¸å…¥åœ–åƒ
    data : numpy.ndarray or cupy.ndarray
        è¦åµŒå…¥çš„æ•¸æ“š
    local_el : numpy.ndarray or cupy.ndarray
        å±€éƒ¨ELå€¼
    target_bpp : float
        ç›®æ¨™BPP
    target_psnr : float
        ç›®æ¨™PSNR
    stage : int
        ç•¶å‰åµŒå…¥éšæ®µ
    block_size : int, optional
        å€å¡Šå¤§å°ï¼ˆç”¨æ–¼èª¿æ•´æ¬Šé‡æœç´¢ç¯„åœï¼‰
    
    Returns:
    --------
    tuple
        (æœ€ä½³æ¬Šé‡, (payload, psnr))
    """
    img = cp.asarray(img)
    data = cp.asarray(data)
    
    # æ ¹æ“šå€å¡Šå¤§å°èª¿æ•´æ¬Šé‡ç¯„åœ
    if block_size is not None:
        if block_size >= 256:
            # å¤§å€å¡Šä½¿ç”¨æ›´å¤§çš„æ¬Šé‡ç¯„åœ
            weight_combinations = cp.array(list(itertools.product(range(1, 20), repeat=4)), dtype=cp.int32)
        elif block_size <= 32:
            # å°å€å¡Šä½¿ç”¨è¼ƒå°çš„æ¬Šé‡ç¯„åœä»¥æé«˜æ•ˆèƒ½
            weight_combinations = cp.array(list(itertools.product(range(1, 8), repeat=4)), dtype=cp.int32)
        elif block_size <= 64:
            # ä¸­å°å€å¡Šä½¿ç”¨ä¸­ç­‰æ¬Šé‡ç¯„åœ
            weight_combinations = cp.array(list(itertools.product(range(1, 12), repeat=4)), dtype=cp.int32)
        else:
            # ä¸­ç­‰å€å¡Šä½¿ç”¨æ¨™æº–æ¬Šé‡ç¯„åœ
            weight_combinations = cp.array(list(itertools.product(range(1, 16), repeat=4)), dtype=cp.int32)
    else:
        # é»˜èªä½¿ç”¨æ¨™æº–æ¬Šé‡ç¯„åœ
        weight_combinations = cp.array(list(itertools.product(range(1, 16), repeat=4)), dtype=cp.int32)
    
    # åˆå§‹åŒ–çµæœæ•¸çµ„
    results = cp.zeros((len(weight_combinations), 3), dtype=cp.float32)
    
    # é…ç½®CUDAé‹è¡Œåƒæ•¸
    threads_per_block = 256
    blocks_per_grid = (len(weight_combinations) + threads_per_block - 1) // threads_per_block
    
    # èª¿ç”¨è©•ä¼°kernel
    evaluate_weights_kernel[blocks_per_grid, threads_per_block](
        img, data, local_el, weight_combinations, results, 
        target_bpp, target_psnr, stage
    )
    
    # æ ¹æ“šå€å¡Šå¤§å°èª¿æ•´é©æ‡‰åº¦è¨ˆç®—
    if block_size is not None:
        if block_size >= 256:
            # å¤§å€å¡Šæ›´é‡è¦–PSNR
            results[:, 2] = results[:, 2] * 0.4 + (results[:, 1] / target_psnr) * 0.6
        elif block_size <= 32:
            # å°å€å¡Šæ›´é‡è¦–payload
            results[:, 2] = results[:, 2] * 0.7 + (results[:, 1] / target_psnr) * 0.3
        elif block_size <= 64:
            # ä¸­å°å€å¡Šå¹³è¡¡PSNRå’Œpayload
            results[:, 2] = results[:, 2] * 0.6 + (results[:, 1] / target_psnr) * 0.4
    
    # æ‰¾å‡ºæœ€ä½³æ¬Šé‡çµ„åˆ
    best_idx = cp.argmax(results[:, 2])
    best_weights = weight_combinations[best_idx]
    best_payload, best_psnr, best_fitness = results[best_idx]
    
    return cp.asnumpy(best_weights), (float(best_payload), float(best_psnr))

@cuda.jit
def evaluate_weights_kernel(img, data, EL, weight_combinations, results, target_bpp, target_psnr, stage):
    """æ¬Šé‡è©•ä¼°æ ¸å¿ƒ"""
    idx = cuda.grid(1)
    if idx < weight_combinations.shape[0]:
        w1, w2, w3, w4 = weight_combinations[idx]
        
        height, width = img.shape
        payload = 0
        mse = 0.0
        
        for y in range(1, height - 1):
            for x in range(1, width - 1):
                # Prediction
                ul = img[y-1, x-1]
                up = img[y-1, x]
                ur = img[y-1, x+1]
                left = img[y, x-1]
                p = (w1*up + w2*ul + w3*ur + w4*left) / (w1 + w2 + w3 + w4)
                pred_val = round(p)
                
                # Embedding
                diff = int(img[y, x]) - int(pred_val)
                if abs(diff) < EL[y, x] and payload < data.shape[0]:  # Use EL[y, x] instead of just EL
                    bit = data[payload]
                    payload += 1
                    if stage == 0:
                        # More aggressive embedding for stage 0
                        embedding_strength = min(3, EL[y, x] - abs(diff))
                    else:
                        embedding_strength = 1
                    
                    if diff >= 0:
                        embedded_val = min(255, int(img[y, x]) + bit * embedding_strength)
                    else:
                        embedded_val = max(0, int(img[y, x]) - (1 - bit) * embedding_strength)
                    mse += (embedded_val - img[y, x]) ** 2
                else:
                    mse += 0  # No change to pixel
        
        if mse > 0:
            psnr = 10 * math.log10((255 * 255) / (mse / (height * width)))
        else:
            psnr = 100.0  # High value for perfect embedding
        
        bpp = payload / (height * width)
        
        # Adaptive fitness criteria
        bpp_fitness = min(1.0, bpp / target_bpp)
        psnr_fitness = max(0, 1 - abs(psnr - target_psnr) / target_psnr)
        
        if stage == 0:
            fitness = bpp_fitness * 0.7 + psnr_fitness * 0.3
        else:
            fitness = bpp_fitness * 0.5 + psnr_fitness * 0.5
        
        results[idx, 0] = payload
        results[idx, 1] = psnr
        results[idx, 2] = fitness

# =============================================================================
# é æ¸¬å™¨é¡åˆ¥
# =============================================================================

class Predictors:
    @cuda.jit
    def predict_proposed_kernel(img, pred_img, weights, height, width):
        """PROPOSED æ–¹æ³•çš„ CUDA é æ¸¬æ ¸å¿ƒ"""
        x, y = cuda.grid(2)
        if 1 <= x < width - 1 and 1 <= y < height - 1:
            w1, w2, w3, w4 = weights[0], weights[1], weights[2], weights[3]
            
            ul = img[y-1, x-1]  # å·¦ä¸Š
            up = img[y-1, x]    # ä¸Š
            ur = img[y-1, x+1]  # å³ä¸Š
            left = img[y, x-1]  # å·¦
            
            # åŠ æ¬Šé æ¸¬
            pred_val = (w1*up + w2*ul + w3*ur + w4*left) / (w1 + w2 + w3 + w4)
            pred_img[y, x] = max(0, min(255, round(pred_val)))

    @cuda.jit  
    def predict_med_kernel(img, pred_img, height, width):
        """MED (Median Edge Detection) æ–¹æ³•çš„ CUDA é æ¸¬æ ¸å¿ƒ"""
        x, y = cuda.grid(2)
        if 1 <= x < width - 1 and 1 <= y < height - 1:
            up = img[y-1, x]      # N
            left = img[y, x-1]    # W  
            up_left = img[y-1, x-1]  # NW
            
            # MED é æ¸¬é‚è¼¯
            if up_left >= max(up, left):
                pred_val = min(up, left)
            elif up_left <= min(up, left):
                pred_val = max(up, left)
            else:
                pred_val = up + left - up_left
                
            pred_img[y, x] = max(0, min(255, int(pred_val)))

    @cuda.jit
    def predict_gap_kernel(img, pred_img, height, width):
        """GAP (Gradient Adjusted Prediction) æ–¹æ³•çš„ CUDA é æ¸¬æ ¸å¿ƒ"""
        x, y = cuda.grid(2)
        if 1 <= x < width - 1 and 1 <= y < height - 1:
            up = img[y-1, x]      # N
            left = img[y, x-1]    # W
            up_left = img[y-1, x-1]  # NW
            
            # è¨ˆç®—æ¢¯åº¦
            grad_h = abs(left - up_left)
            grad_v = abs(up - up_left)
            
            # GAP é æ¸¬é‚è¼¯
            if grad_h < grad_v:
                pred_val = left
            elif grad_v < grad_h:
                pred_val = up
            else:
                pred_val = (left + up) / 2
                
            pred_img[y, x] = max(0, min(255, int(pred_val)))

    @cuda.jit
    def predict_rhombus_kernel(img, pred_img, height, width):
        """RHOMBUS æ–¹æ³•çš„ CUDA é æ¸¬æ ¸å¿ƒ"""
        x, y = cuda.grid(2)
        if 2 <= x < width - 2 and 2 <= y < height - 2:
            # Rhombus æ¨¡å¼çš„åƒç´ 
            n = img[y-1, x]      # åŒ—
            s = img[y+1, x]      # å—  
            e = img[y, x+1]      # æ±
            w = img[y, x-1]      # è¥¿
            ne = img[y-1, x+1]   # æ±åŒ—
            nw = img[y-1, x-1]   # è¥¿åŒ—
            se = img[y+1, x+1]   # æ±å—
            sw = img[y+1, x-1]   # è¥¿å—
            
            # Rhombus é æ¸¬ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰
            pred_val = (n + s + e + w + ne + nw + se + sw) / 8
            pred_img[y, x] = max(0, min(255, int(pred_val)))

def predict_image_cuda(img, prediction_method, weights=None):
    """
    ä½¿ç”¨ CUDA é€²è¡Œåœ–åƒé æ¸¬ï¼ˆé©é… Predictors é¡ç‰ˆæœ¬ï¼‰
    
    Parameters:
    -----------
    img : cupy.ndarray or numpy.ndarray
        è¼¸å…¥åœ–åƒ
    prediction_method : PredictionMethod
        é æ¸¬æ–¹æ³•
    weights : numpy.ndarray, optional
        æ¬Šé‡ï¼ˆåƒ…ç”¨æ–¼ PROPOSED æ–¹æ³•ï¼‰
        
    Returns:
    --------
    cupy.ndarray : é æ¸¬åœ–åƒ
    """
    # ç¢ºä¿è¼¸å…¥æ˜¯ CuPy é™£åˆ—
    if not isinstance(img, cp.ndarray):
        img = cp.asarray(img)
    
    height, width = img.shape
    pred_img = cp.zeros_like(img)
    
    # è¨­ç½® CUDA åŸ·è¡Œåƒæ•¸
    threads_per_block = (16, 16)
    blocks_per_grid_x = (width + threads_per_block[0] - 1) // threads_per_block[0]
    blocks_per_grid_y = (height + threads_per_block[1] - 1) // threads_per_block[1]
    blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)
    
    # ğŸ”§ é—œéµä¿®æ”¹ï¼šé€šé Predictors é¡èª¿ç”¨ kernels
    if prediction_method == PredictionMethod.PROPOSED:
        if weights is None:
            # ä½¿ç”¨é»˜èªæ¬Šé‡
            weights = cp.array([1, 1, 1, 1], dtype=cp.int32)
        else:
            weights = cp.asarray(weights, dtype=cp.int32)
            
        # ğŸ”§ ä¿®æ”¹ï¼šé€šéé¡èª¿ç”¨
        Predictors.predict_proposed_kernel[blocks_per_grid, threads_per_block](
            img, pred_img, weights, height, width
        )
        
    elif prediction_method == PredictionMethod.MED:
        # ğŸ”§ ä¿®æ”¹ï¼šé€šéé¡èª¿ç”¨
        Predictors.predict_med_kernel[blocks_per_grid, threads_per_block](
            img, pred_img, height, width
        )
        
    elif prediction_method == PredictionMethod.GAP:
        # ğŸ”§ ä¿®æ”¹ï¼šé€šéé¡èª¿ç”¨
        Predictors.predict_gap_kernel[blocks_per_grid, threads_per_block](
            img, pred_img, height, width
        )
        
    elif prediction_method == PredictionMethod.RHOMBUS:
        # ğŸ”§ ä¿®æ”¹ï¼šé€šéé¡èª¿ç”¨
        Predictors.predict_rhombus_kernel[blocks_per_grid, threads_per_block](
            img, pred_img, height, width
        )
        
    else:
        raise ValueError(f"Unknown prediction method: {prediction_method}")
    
    return pred_img
    
# =============================================================================
# åµŒå…¥æ ¸å¿ƒé‚è¼¯
# =============================================================================

@cuda.jit
def simple_single_embedding_kernel(img, pred_img, data, embedded, payload, height, width, pass_idx):
    """
    ç°¡åŒ–ç‰ˆçš„å¢å¼·åµŒå…¥æ ¸å¿ƒï¼Œç”¨æ–¼éPROPOSEDé æ¸¬å™¨
    """
    x, y = cuda.grid(2)
    if x < width and y < height:
        diff = int(img[y, x]) - int(pred_img[y, x])
        pixel_val = int(img[y, x])
        
        if payload[0] < data.size:
            # åŸºæ–¼é€šéæ¬¡æ•¸èª¿æ•´åµŒå…¥ç­–ç•¥
            if pass_idx == 0:  # ç¬¬ä¸€æ¬¡é€šé - è¼ƒå¯¬é¬†æ¨™æº–
                embed_threshold = 3  # è¼ƒå¤§é–¾å€¼ï¼ŒåµŒå…¥æ›´å¤šæ•¸æ“š
            elif pass_idx == 1:  # ç¬¬äºŒæ¬¡é€šé - ä¸­ç­‰æ¨™æº–
                embed_threshold = 2
            else:  # ç¬¬ä¸‰æ¬¡é€šé - æœ€åš´æ ¼æ¨™æº–
                embed_threshold = 1
                
            if abs(diff) <= embed_threshold:
                bit = data[payload[0]]
                cuda.atomic.add(payload, 0, 1)
                
                # ç°¡å–®åµŒå…¥ç­–ç•¥
                if diff == 0:
                    if bit == 1:
                        embedded[y, x] = min(255, pixel_val + 1)
                    else:
                        embedded[y, x] = pixel_val
                elif diff > 0:  # æ­£å·®å€¼
                    if bit == 1:
                        embedded[y, x] = pixel_val
                    else:
                        embedded[y, x] = max(0, pixel_val - 1)
                else:  # è² å·®å€¼
                    if bit == 1:
                        embedded[y, x] = min(255, pixel_val + 1)
                    else:
                        embedded[y, x] = pixel_val
            else:
                embedded[y, x] = pixel_val
        else:
            embedded[y, x] = pixel_val
    else:
        embedded[y, x] = img[y, x]  # é‚Šç•Œåƒç´ ä¿æŒä¸è®Š

@cuda.jit
def pee_embedding_kernel(img, pred_img, data, embedded, payload, local_el, height, width, pass_idx):
    """
    å°ˆç‚º Stage 0 å„ªåŒ–çš„åŠ å¼·å‹åµŒå…¥æ ¸å¿ƒï¼Œæé«˜åµŒå…¥å®¹é‡
    """
    x, y = cuda.grid(2)
    if x < width and y < height:
        diff = int(img[y, x]) - int(pred_img[y, x])
        pixel_val = int(img[y, x])
        el = local_el[y, x]
        
        # å¢å¼·å‹åµŒå…¥ç­–ç•¥ - æ ¹æ“šé€šéæ¬¡æ•¸èª¿æ•´ç­–ç•¥
        if payload[0] < data.size:
            if pass_idx == 0:  # ç¬¬ä¸€æ¬¡é€šé - æœ€å¯¬é¬†çš„åµŒå…¥
                effective_el = min(el + 3, 9)  # å¤§å¹…æ“´å¤§åµŒå…¥å±¤ç´š
                if abs(diff) <= effective_el:
                    bit = data[payload[0]]
                    cuda.atomic.add(payload, 0, 1)
                    
                    # å°é›¶å·®å€¼ç‰¹æ®Šè™•ç†
                    if diff == 0:
                        if bit == 1:
                            embedded[y, x] = min(255, pixel_val + 1)
                        else:
                            embedded[y, x] = pixel_val
                    # å°éé›¶å·®å€¼ä½¿ç”¨æ›´ç©æ¥µçš„åµŒå…¥ç­–ç•¥
                    elif abs(diff) <= 2:
                        if bit == 1:
                            if diff > 0:
                                embedded[y, x] = pixel_val
                            else:
                                embedded[y, x] = min(255, pixel_val + 1)
                        else:
                            if diff > 0:
                                embedded[y, x] = max(0, pixel_val - 1)
                            else:
                                embedded[y, x] = pixel_val
                    else:
                        # æ›´å¤§çš„å·®å€¼ä½¿ç”¨æ¨™æº–ç­–ç•¥
                        if bit == 1:
                            if diff > 0:
                                embedded[y, x] = pixel_val
                            else:
                                embedded[y, x] = min(255, pixel_val + 1)
                        else:
                            if diff > 0:
                                embedded[y, x] = max(0, pixel_val - 1)
                            else:
                                embedded[y, x] = pixel_val
                else:
                    embedded[y, x] = pixel_val
            elif pass_idx == 1:  # ç¬¬äºŒæ¬¡é€šé - ä¸­ç­‰åµŒå…¥å¼·åº¦
                if abs(diff) <= 1:
                    bit = data[payload[0]]
                    cuda.atomic.add(payload, 0, 1)
                    
                    if diff == 0:
                        if bit == 1:
                            embedded[y, x] = min(255, pixel_val + 1)
                        else:
                            embedded[y, x] = pixel_val
                    else:  # diff == 1 or diff == -1
                        if bit == 1:
                            if diff > 0:
                                embedded[y, x] = pixel_val
                            else:
                                embedded[y, x] = min(255, pixel_val + 1)
                        else:
                            if diff > 0:
                                embedded[y, x] = max(0, pixel_val - 1)
                            else:
                                embedded[y, x] = pixel_val
                else:
                    embedded[y, x] = pixel_val
            else:  # ç¬¬ä¸‰æ¬¡é€šé - åƒ…åµŒå…¥æœ€å®‰å…¨çš„ä½ç½®
                if diff == 0:
                    bit = data[payload[0]]
                    cuda.atomic.add(payload, 0, 1)
                    
                    if bit == 1:
                        embedded[y, x] = min(255, pixel_val + 1)
                    else:
                        embedded[y, x] = pixel_val
                else:
                    embedded[y, x] = pixel_val
        else:
            embedded[y, x] = pixel_val
    else:
        embedded[y, x] = img[y, x]  # é‚Šç•Œåƒç´ ä¿æŒä¸è®Š

@cuda.jit
def rhombus_embedding_kernel(img, pred_img, data, embedded, payload, height, width, stage):
    """
    ç‚º Rhombus é æ¸¬å™¨è¨­è¨ˆçš„ç©©å®šåµŒå…¥ kernel
    ç°¡åŒ–å¯¦ç¾ä¸¦ç¢ºä¿çµæœç©©å®šæ€§
    """
    x, y = cuda.grid(2)
    if 1 < x < width - 1 and 1 < y < height - 1:
        diff = int(img[y, x]) - int(pred_img[y, x])
        pixel_val = int(img[y, x])
        
        if payload[0] < data.size:
            # ç°¡å–®ç©©å®šçš„åµŒå…¥é‚è¼¯
            # åªåœ¨å·®å€¼ç‚º 0 æ™‚åµŒå…¥ï¼Œç¢ºä¿æœ€å¤§ç©©å®šæ€§
            if diff == 0:
                bit = data[payload[0]]
                cuda.atomic.add(payload, 0, 1)
                
                if bit == 1:
                    embedded[y, x] = min(255, pixel_val + 1)
                else:
                    embedded[y, x] = pixel_val
            else:
                # ç¶­æŒåŸå§‹åƒç´ å€¼
                embedded[y, x] = pixel_val
        else:
            embedded[y, x] = pixel_val
    else:
        embedded[y, x] = img[y, x]

def multi_pass_embedding(img, data, local_el, weights, stage, 
                        prediction_method=PredictionMethod.PROPOSED,
                        remaining_target=None):
    """
    å¤šç¨®é æ¸¬æ–¹æ³•çš„åµŒå…¥å‡½æ•¸ï¼Œä½¿ç”¨çµ„åˆç­–ç•¥
    
    ğŸ”§ çµ„åˆç­–ç•¥ï¼ˆç­–ç•¥1 + ç­–ç•¥2ï¼‰ï¼š
    - PROPOSEDé æ¸¬å™¨ï¼š
      * Stage 0: ä½¿ç”¨ 3æ¬¡é€šéï¼ˆæœ€å¤§åµŒå…¥å®¹é‡ï¼‰
      * Stage 1+: ä½¿ç”¨ 2æ¬¡é€šéï¼ˆå¹³è¡¡å®¹é‡èˆ‡å“è³ªï¼‰
    - MED/GAP/RHOMBUSé æ¸¬å™¨ï¼š
      * æ‰€æœ‰Stage: ä½¿ç”¨ 1æ¬¡é€šéï¼ˆæœ€å¿«è™•ç†é€Ÿåº¦ï¼‰
    
    é€™ç¨®ç­–ç•¥çš„å„ªå‹¢ï¼š
    1. PROPOSEDä¿æŒæœ€é«˜æ€§èƒ½ï¼ŒåŒæ™‚å¾ŒçºŒStageæ›´æ³¨é‡å“è³ª
    2. å…¶ä»–é æ¸¬å™¨ç²å¾—æœ€å¤§é€Ÿåº¦æå‡
    3. æ˜ç¢ºçš„æ€§èƒ½åˆ†å±¤ï¼šé«˜æ€§èƒ½ã€å¹³è¡¡ã€é«˜é€Ÿåº¦
    4. æœ€ä½³çš„è³‡æºåˆ©ç”¨æ•ˆç‡
    
    Parameters:
    -----------
    img : numpy.ndarray or cupy.ndarray
        è¼¸å…¥åœ–åƒ
    data : numpy.ndarray or cupy.ndarray
        è¦åµŒå…¥çš„æ•¸æ“š
    local_el : numpy.ndarray
        å±€éƒ¨åµŒå…¥å±¤ç´š
    weights : numpy.ndarray or None
        æ¬Šé‡å‘é‡ (å¦‚æœé©ç”¨)
    stage : int
        ç•¶å‰åµŒå…¥éšæ®µ
    prediction_method : PredictionMethod
        é æ¸¬æ–¹æ³•
    remaining_target : list or None
        å‰©é¤˜éœ€è¦åµŒå…¥çš„æ•¸æ“šé‡çš„å¯è®Šå®¹å™¨ [target_value]
        
    Returns:
    --------
    tuple
        (embedded_img, payload, pred_img)
    """
    # æ•¸æ“šé¡å‹è½‰æ›
    if isinstance(img, cp.ndarray):
        img = cp.asnumpy(img)
    if isinstance(data, cp.ndarray):
        data = cp.asnumpy(data)
    
    if remaining_target is not None and not isinstance(remaining_target, list):
        remaining_target = [remaining_target]
    
    # ç²¾ç¢ºå®¹é‡æ§åˆ¶ - å¦‚æœå‰©é¤˜ç›®æ¨™å®¹é‡å°æ–¼æ•¸æ“šé‡çš„10%ï¼Œä½¿ç”¨ç²¾ç¢ºåµŒå…¥
    precise_embedding = False
    if remaining_target is not None:
        # å¦‚æœå‰©é¤˜å®¹é‡éå¸¸å°
        if remaining_target[0] <= len(data) * 0.1 and remaining_target[0] > 0:
            precise_embedding = True
    
    # é™åˆ¶æ•¸æ“šé‡ - ä½¿ç”¨å¯è®Šå®¹å™¨ä¸­çš„å€¼
    current_target = None
    if remaining_target is not None:
        # æª¢æŸ¥æ˜¯å¦é‚„æœ‰å‰©é¤˜å®¹é‡
        if remaining_target[0] <= 0:
            # å·²é”åˆ°ç›®æ¨™ï¼Œç›´æ¥è¿”å›åŸåœ–ä¸¦ä¸”payloadç‚º0
            return img, 0, img  # æ³¨æ„ï¼šåœ¨é€™è£¡é æ¸¬åœ–åƒå°±æ˜¯åŸåœ–
            
        # æ ¹æ“šç²¾ç¢ºæ¨¡å¼çš„ä¸åŒç­–ç•¥è¨­ç½®ç›®æ¨™
        if precise_embedding:
            # ç²¾ç¢ºæ¨¡å¼ï¼šå˜—è©¦åµŒå…¥æ°å¥½æ‰€éœ€çš„ä½å…ƒ
            current_target = remaining_target[0]
        else:
            # æ™®é€šæ¨¡å¼ï¼šå–è¼ƒå°å€¼
            current_target = min(len(data), remaining_target[0])
            
        # é™åˆ¶æ•¸æ“šé•·åº¦
        if current_target < len(data):
            data = data[:current_target]
    
    # è½‰æ›ç‚º CUDA è¨­å‚™æ•¸çµ„
    d_img = cuda.to_device(img)
    d_data = cuda.to_device(data)
    
    # ä½¿ç”¨çµ±ä¸€çš„é æ¸¬å‡½æ•¸æ¥å£
    pred_img = predict_image_cuda(d_img, prediction_method, weights)
    
    # ä¿å­˜é æ¸¬åœ–åƒçš„å‰¯æœ¬
    if hasattr(pred_img, 'copy_to_host'):
        pred_img_copy = pred_img.copy_to_host()
    else:
        pred_img_copy = pred_img
    
    height, width = d_img.shape
    threads_per_block = (16, 16)
    blocks_per_grid_x = (width + threads_per_block[0] - 1) // threads_per_block[0]
    blocks_per_grid_y = (height + threads_per_block[1] - 1) // threads_per_block[1]
    blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)
    
    d_embedded = cuda.device_array_like(d_img)
    d_payload = cuda.to_device(np.array([0], dtype=np.int32))
    
    # ç²¾ç¢ºåµŒå…¥æ¨¡å¼ç‰¹æ®Šè™•ç†
    if precise_embedding:
        # é‡å°ç²¾ç¢ºåµŒå…¥çš„å„ªåŒ–ç­–ç•¥
        # 1. æ¸›å°‘åµŒå…¥é€šé“ï¼Œåªä½¿ç”¨ä¸€æ¬¡é€šéï¼Œé¿å…éåº¦åµŒå…¥
        # 2. å„ªå…ˆä½¿ç”¨å·®å€¼å°çš„åƒç´ é€²è¡ŒåµŒå…¥
        pass_idx = 0  # åªä½¿ç”¨å–®æ¬¡é€šé
        
        if prediction_method == PredictionMethod.PROPOSED:
            if hasattr(local_el, 'copy_to_host'):
                local_el_np = local_el.copy_to_host()
            elif isinstance(local_el, cp.ndarray):
                local_el_np = cp.asnumpy(local_el)
            else:
                local_el_np = local_el
                
            d_local_el = cuda.to_device(local_el_np)
            
            # ä½¿ç”¨ç‰¹æ®Šåƒæ•¸çš„åµŒå…¥æ ¸å¿ƒ
            pee_embedding_kernel[blocks_per_grid, threads_per_block](
                d_img, pred_img, d_data, d_embedded, d_payload, d_local_el,
                height, width, pass_idx
            )
        else:
            # å°æ–¼å…¶ä»–é æ¸¬å™¨ï¼ŒåŒæ¨£ä½¿ç”¨å–®æ¬¡é€šé
            simple_single_embedding_kernel[blocks_per_grid, threads_per_block](
                d_img, pred_img, d_data, d_embedded, d_payload,
                height, width, pass_idx
            )
        
        # ç²å–çµæœ
        embedded = d_embedded.copy_to_host()
        payload = d_payload.copy_to_host()[0]
        
        # æ›´æ–°å‰©é¤˜ç›®æ¨™å®¹é‡
        if remaining_target is not None:
            actual_payload = min(payload, remaining_target[0])
            remaining_target[0] -= actual_payload
            payload = actual_payload
            
        return embedded, payload, pred_img_copy
    
    # ğŸ”§ çµ„åˆç­–ç•¥æ ¸å¿ƒï¼šæ ¹æ“šé æ¸¬æ–¹æ³•å’Œéšæ®µæ±ºå®šé€šéæ¬¡æ•¸
    if prediction_method == PredictionMethod.PROPOSED:
        # ğŸ¯ ç­–ç•¥1ï¼šPROPOSEDé æ¸¬å™¨ä½¿ç”¨å‹•æ…‹é€šéæ¬¡æ•¸
        if stage == 0:
            passes = 3  # Stage 0: æœ€å¤§å®¹é‡
            strategy_name = "PROPOSED Stage 0 (Maximum Capacity)"
        else:
            passes = 2  # Stage 1+: å¹³è¡¡å®¹é‡èˆ‡å“è³ª
            strategy_name = f"PROPOSED Stage {stage} (Balanced)"
        use_multi_pass = True
    else:
        # ğŸ¯ ç­–ç•¥2ï¼šå…¶ä»–é æ¸¬å™¨çµ±ä¸€ä½¿ç”¨1æ¬¡é€šé
        passes = 1
        strategy_name = f"{prediction_method.value} Stage {stage} (High Speed)"
        use_multi_pass = False
    
    # ğŸ”§ æ ¹æ“šæ˜¯å¦ä½¿ç”¨å¤šæ¬¡é€šéä¾†é¸æ“‡è™•ç†é‚è¼¯
    if use_multi_pass:
        # å¤šæ¬¡é€šéé‚è¼¯ï¼ˆé©ç”¨æ–¼PROPOSEDé æ¸¬å™¨ï¼‰
        total_payload = 0
        
        for pass_idx in range(passes):
            # æª¢æŸ¥æ˜¯å¦å·²é”åˆ°ç›®æ¨™
            if remaining_target is not None and remaining_target[0] <= 0:
                break
                
            # PROPOSEDé æ¸¬å™¨ä½¿ç”¨è¤‡é›œçš„åµŒå…¥æ ¸å¿ƒ
            if hasattr(local_el, 'copy_to_host'):
                local_el_np = local_el.copy_to_host()
            elif isinstance(local_el, cp.ndarray):
                local_el_np = cp.asnumpy(local_el)
            else:
                local_el_np = local_el
                
            d_local_el = cuda.to_device(local_el_np)
            
            # ğŸ”§ æ ¹æ“šstageå’Œpass_idxèª¿æ•´åµŒå…¥å¼·åº¦
            if stage == 0:
                # Stage 0 ä½¿ç”¨æ¿€é€²ç­–ç•¥ï¼ˆåŸæœ‰é‚è¼¯ï¼‰
                pee_embedding_kernel[blocks_per_grid, threads_per_block](
                    d_img, pred_img, d_data[total_payload:], d_embedded, d_payload, d_local_el,
                    height, width, pass_idx
                )
            else:
                # Stage 1+ ä½¿ç”¨è¼ƒä¿å®ˆçš„ç­–ç•¥
                # å¯ä»¥åœ¨é€™è£¡èª¿æ•´ pass_idx æˆ–ä½¿ç”¨ä¸åŒçš„åƒæ•¸
                # ä¾‹å¦‚ï¼šå°‡ pass_idx æ˜ å°„åˆ°æ›´ä¿å®ˆçš„å€¼
                conservative_pass_idx = min(pass_idx + 1, 2)  # è®“å¾ŒçºŒstageæ›´ä¿å®ˆ
                pee_embedding_kernel[blocks_per_grid, threads_per_block](
                    d_img, pred_img, d_data[total_payload:], d_embedded, d_payload, d_local_el,
                    height, width, conservative_pass_idx
                )
            
            # æ›´æ–°åµŒå…¥çµæœå’Œç¸½å®¹é‡
            current_payload = d_payload.copy_to_host()[0]
            if current_payload == 0:
                break  # å¦‚æœæ²’æœ‰åµŒå…¥ä»»ä½•æ•¸æ“šï¼Œå‰‡åœæ­¢
                
            total_payload += current_payload
            
            # æ›´æ–°å‰©é¤˜ç›®æ¨™å®¹é‡
            if remaining_target is not None:
                # ç¢ºä¿ä¸æœƒè¶…éç›®æ¨™
                actual_payload = min(current_payload, remaining_target[0])
                remaining_target[0] -= actual_payload
                
                # å¦‚æœå·²é”åˆ°ç›®æ¨™ï¼Œåœæ­¢è™•ç†
                if remaining_target[0] <= 0:
                    break
            
            d_payload = cuda.to_device(np.array([0], dtype=np.int32))
            
            # ä¿å­˜ç•¶å‰çµæœä¾›ä¸‹æ¬¡åµŒå…¥ä½¿ç”¨
            temp_img = d_embedded.copy_to_host()
            d_img = cuda.to_device(temp_img)
            
            # æ›´æ–°é æ¸¬åœ–åƒ
            pred_img = predict_image_cuda(d_img, prediction_method, weights)
            
            # æ›´æ–°é æ¸¬åœ–åƒå‰¯æœ¬
            if hasattr(pred_img, 'copy_to_host'):
                pred_img_copy = pred_img.copy_to_host()
            else:
                pred_img_copy = pred_img
        
        embedded = d_embedded.copy_to_host()
        payload = total_payload
        
        # ç¢ºä¿ä¸æœƒè¶…éç›®æ¨™
        if remaining_target is not None:
            payload = min(payload, current_target)
            
    else:
        # ğŸ”§ å–®æ¬¡é€šéé‚è¼¯ï¼ˆé©ç”¨æ–¼å…¶ä»–é æ¸¬å™¨çš„æ‰€æœ‰Stageï¼‰
        # å…¶ä»–é æ¸¬å™¨ä½¿ç”¨ç°¡åŒ–çš„å–®æ¬¡åµŒå…¥æ–¹å¼
        simple_single_embedding_kernel[blocks_per_grid, threads_per_block](
            d_img, pred_img, d_data, d_embedded, d_payload,
            height, width, 0  # pass_idx å›ºå®šç‚º 0ï¼Œå› ç‚ºåªæœ‰1æ¬¡é€šé
        )
        
        # ç²å–çµæœ
        embedded = d_embedded.copy_to_host()
        payload = d_payload.copy_to_host()[0]
        
        # æ›´æ–°å‰©é¤˜ç›®æ¨™å®¹é‡
        if remaining_target is not None:
            # ç¢ºä¿ä¸æœƒè¶…éç›®æ¨™
            actual_payload = min(payload, remaining_target[0])
            remaining_target[0] -= actual_payload
            payload = actual_payload  # æ›´æ–°å¯¦éš›åµŒå…¥çš„é‡
    
    # ç¢ºä¿ä¸æœƒè¿”å›è¶…éç›®æ¨™çš„payloadå€¼
    if current_target is not None:
        payload = min(payload, current_target)
    
    return embedded, payload, pred_img_copy

# =============================================================================
# è¼”åŠ©åµŒå…¥åŠŸèƒ½
# =============================================================================

def pee_embedding_adaptive(img, data, pred_img, EL):
    """è‡ªé©æ‡‰ PEE åµŒå…¥ï¼ˆCPUç‰ˆæœ¬ï¼‰"""
    height, width = img.shape
    embedded = np.zeros_like(img)
    payload = 0
    
    for x in range(height):
        for y in range(width):
            local_std = np.std(img[max(0, x-1):min(height, x+2), max(0, y-1):min(width, y+2)])
            adaptive_EL = min(EL, max(3, int(EL * (1 - local_std / 255))))
            
            diff = int(img[x, y]) - int(pred_img[x, y])
            if abs(diff) < adaptive_EL and payload < len(data):
                bit = int(data[payload])
                payload += 1
                if diff >= 0:
                    embedded[x, y] = min(255, max(0, int(img[x, y]) + bit))
                else:
                    embedded[x, y] = min(255, max(0, int(img[x, y]) - bit))
            else:
                embedded[x, y] = img[x, y]
    
    embedded_data = data[:payload].tolist()
    return embedded, payload, embedded_data

def pee_embedding_adaptive_cuda(img, data, pred_img, local_el, stage=0):
    """è‡ªé©æ‡‰ PEE åµŒå…¥ï¼ˆCUDAç‰ˆæœ¬ï¼‰"""
    height, width = img.shape
    d_embedded = cuda.device_array_like(img)
    d_payload = cuda.to_device(np.array([0], dtype=np.int32))

    threads_per_block = (16, 16)
    blocks_per_grid_x = (width + threads_per_block[0] - 1) // threads_per_block[0]
    blocks_per_grid_y = (height + threads_per_block[1] - 1) // threads_per_block[1]
    blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)

    pee_embedding_kernel[blocks_per_grid, threads_per_block](
        img, pred_img, data, d_embedded, d_payload, local_el,
        height, width, stage
    )

    embedded = d_embedded.copy_to_host()
    payload = d_payload.copy_to_host()[0]
    embedded_data = data.copy_to_host()[:payload].tolist()

    return embedded, payload, embedded_data