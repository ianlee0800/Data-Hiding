import pandas as pd
import cv2
import prettytable as pt
import time
import traceback
from scipy.signal import savgol_filter
from tqdm import tqdm
from datetime import datetime
import cupy as cp

from embedding import (
    pee_process_with_rotation_cuda,
    pee_process_with_split_cuda
)
from quadtree import pee_process_with_quadtree_cuda

# ğŸ”§ æ›´æ–°ï¼šä½¿ç”¨æ–°çš„å·¥å…·æ¨¡çµ„
from utils import (
    MeasurementConstants,
    PathConstants,
    DataConverter,
    MeasurementPointGenerator,
    calculate_quality_metrics_unified,
    ensure_dir,
    cleanup_memory
)

# ğŸ”§ æ›´æ–°ï¼šå¾ image_processing å°å…¥ get_image_info
from image_processing import (
    save_image,
    PredictionMethod,
    get_image_info
)

# =============================================================================
# è¼”åŠ©å‡½æ•¸ï¼šæ—¥èªŒç®¡ç†
# =============================================================================

class MeasurementLogger:
    """ç°¡åŒ–çš„æ¸¬é‡æ—¥èªŒç®¡ç†å™¨"""
    
    def __init__(self, log_file, img_name, method_name):
        self.log_file = log_file
        self.img_name = img_name
        self.method_name = method_name
        
    def log_header(self, img_info, measurement_mode, total_embeddings, el_mode, use_different_weights):
        """è¨˜éŒ„æ¸¬é‡é–‹å§‹ä¿¡æ¯"""
        with open(self.log_file, 'w', encoding='utf-8') as f:
            f.write(f"Precise measurement run started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Image: {self.img_name} ({img_info['description']})\n")
            f.write(f"Method: {self.method_name}\n")
            f.write(f"Pixel count for BPP calculation: {img_info['pixel_count']}\n")
            f.write(f"Measurement mode: {measurement_mode}\n")
            f.write(f"Total embeddings: {total_embeddings}\n")
            f.write(f"EL mode: {el_mode}\n")
            f.write(f"Use different weights: {use_different_weights}\n")
            f.write("\n" + "="*80 + "\n\n")
    
    def log_step(self, step_name, details):
        """è¨˜éŒ„æ¸¬é‡æ­¥é©Ÿ"""
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(f"{step_name}:\n")
            for key, value in details.items():
                f.write(f"  {key}: {value}\n")
            f.write("\n")

# =============================================================================
# ç¬¬ä¸€æ­¥ï¼šæœ€å¤§å®¹é‡æ¸¬é‡
# =============================================================================

def _find_maximum_capacity(origImg, method, prediction_method, ratio_of_ones, 
                          total_embeddings, el_mode, split_size, block_base, 
                          quad_tree_params, use_different_weights, logger):
    """
    æ­¥é©Ÿ1: æ‰¾å‡ºæœ€å¤§åµŒå…¥å®¹é‡
    
    Returns:
    --------
    tuple: (final_img_max, max_payload, stages_max, max_run_time)
    """
    print(f"\n{'='*80}")
    print(f"Step 1: Finding maximum payload capacity")
    print(f"{'='*80}")
    
    start_time = time.time()
    final_img_max, max_payload, stages_max = run_embedding_with_target(
        origImg, method, prediction_method, ratio_of_ones, 
        total_embeddings, el_mode, target_payload_size=-1,
        split_size=split_size, block_base=block_base, 
        quad_tree_params=quad_tree_params,
        use_different_weights=use_different_weights
    )
    max_run_time = time.time() - start_time
    
    # è¨˜éŒ„åˆ°æ—¥èªŒ
    logger.log_step("Step 1: Maximum capacity found", {
        "Maximum payload": f"{max_payload} bits",
        "Time taken": f"{max_run_time:.2f} seconds"
    })
    
    print(f"Maximum payload: {max_payload} bits")
    print(f"Time taken: {max_run_time:.2f} seconds")
    
    return final_img_max, max_payload, stages_max, max_run_time

# =============================================================================
# ç¬¬äºŒæ­¥ï¼šæ¸¬é‡é»ç”Ÿæˆ
# =============================================================================

def _generate_measurement_points(max_payload, step_size, segments, logger):
    """
    æ­¥é©Ÿ2: è¨ˆç®—æ¸¬é‡é»
    
    Returns:
    --------
    tuple: (payload_points, measurement_mode)
    """
    print(f"\n{'='*80}")
    print(f"Step 2: Calculating measurement points")
    print(f"{'='*80}")
    
    # ğŸ”§ æ›´æ–°ï¼šä½¿ç”¨æ–°çš„å·¥å…·é¡ç”Ÿæˆæ¸¬é‡é»
    payload_points, measurement_mode, mode_description = MeasurementPointGenerator.generate_points(
        max_payload, step_size, segments
    )
    
    print(f"Measurement mode: {measurement_mode}")
    print(f"Mode description: {mode_description}")
    print(f"Total measurement points: {len(payload_points) + 1} (including max capacity)")
    
    # è¨˜éŒ„åˆ°æ—¥èªŒ
    logger.log_step("Step 2: Measurement points generated", {
        "Measurement mode": measurement_mode,
        "Mode description": mode_description,
        "Points generated": len(payload_points),
        "Total points": len(payload_points) + 1
    })
    
    return payload_points, measurement_mode

# =============================================================================
# ç¬¬ä¸‰æ­¥ï¼šæ‰¹é‡æ¸¬é‡åŸ·è¡Œ
# =============================================================================

def _run_measurement_batch(origImg, payload_points, method, prediction_method, 
                          ratio_of_ones, total_embeddings, el_mode, split_size, 
                          block_base, quad_tree_params, use_different_weights, 
                          img_info, measurement_mode, result_dir, logger):
    """
    æ­¥é©Ÿ3: ç‚ºæ¯å€‹ç›®æ¨™é»é‹è¡ŒåµŒå…¥ç®—æ³•
    
    Returns:
    --------
    list: æ¸¬é‡çµæœåˆ—è¡¨
    """
    print(f"\n{'='*80}")
    print(f"Step 3: Running embedding algorithm for each target point")
    print(f"Processing {len(payload_points)} measurement points...")
    print(f"{'='*80}")
    
    results = []
    
    for i, target in enumerate(tqdm(payload_points, desc="è™•ç†æ¸¬é‡é»")):
        percentage = target / max(payload_points + [target]) * 100
        
        print(f"\nRunning point {i+1}/{len(payload_points)}: {target} bits ({percentage:.1f}% of max)")
        
        start_time = time.time()
        final_img, actual_payload, stages = run_embedding_with_target(
            origImg, method, prediction_method, ratio_of_ones, 
            total_embeddings, el_mode, target_payload_size=target,
            split_size=split_size, block_base=block_base, 
            quad_tree_params=quad_tree_params,
            use_different_weights=use_different_weights
        )
        run_time = time.time() - start_time
        
        # ğŸ”§ æ›´æ–°ï¼šä½¿ç”¨æ–°çš„çµ±ä¸€å“è³ªæŒ‡æ¨™è¨ˆç®—å‡½æ•¸
        psnr, ssim, hist_corr = calculate_quality_metrics_unified(origImg, final_img, img_info)
        
        # æª¢æŸ¥ PSNR æ˜¯å¦ç•°å¸¸
        is_psnr_suspicious = False
        if len(results) > 0:
            last_result = results[-1]
            current_bpp = actual_payload / img_info['pixel_count']
            if (current_bpp > last_result['BPP'] and psnr > last_result['PSNR']):
                is_psnr_suspicious = True
                print(f"  Warning: Suspicious PSNR value detected: {psnr:.2f} > previous {last_result['PSNR']:.2f}")
        
        # è¨ˆç®—BPP
        bpp = actual_payload / img_info['pixel_count']
        
        # è¨˜éŒ„çµæœ
        result = {
            'Target_Percentage': percentage,
            'Target_Payload': target,
            'Actual_Payload': actual_payload,
            'BPP': bpp,
            'PSNR': psnr,
            'SSIM': ssim,
            'Hist_Corr': hist_corr,
            'Processing_Time': run_time,
            'Suspicious': is_psnr_suspicious,
            'Measurement_Mode': measurement_mode,
            'Image_Type': img_info['type_name'],
            'Pixel_Count': img_info['pixel_count']
        }
        results.append(result)
        
        # ä¿å­˜åµŒå…¥åœ–åƒ
        if img_info['is_color']:
            cv2.imwrite(f"{result_dir}/embedded_{int(percentage)}pct.png", final_img)
        else:
            save_image(final_img, f"{result_dir}/embedded_{int(percentage)}pct.png")
        
        print(f"  Actual: {actual_payload} bits")
        print(f"  BPP: {bpp:.6f}")
        print(f"  PSNR: {psnr:.2f}")
        print(f"  SSIM: {ssim:.4f}")
        print(f"  Time: {run_time:.2f} seconds")
        
        # ğŸ”§ æ›´æ–°ï¼šä½¿ç”¨æ–°çš„è¨˜æ†¶é«”æ¸…ç†å‡½æ•¸
        cleanup_memory()
    
    # è¨˜éŒ„æ‰¹é‡æ¸¬é‡å®Œæˆ
    logger.log_step("Step 3: Batch measurement completed", {
        "Total points processed": len(results),
        "Average processing time": f"{sum(r['Processing_Time'] for r in results) / len(results):.2f} seconds"
    })
    
    return results

# =============================================================================
# ç¬¬å››æ­¥ï¼šçµæœæ•¸æ“šè™•ç†
# =============================================================================

def _process_measurement_results(results, max_capacity_result, img_info):
    """
    æ­¥é©Ÿ4: æ•¸æ“šå¹³æ»‘è™•ç†
    
    Returns:
    --------
    pandas.DataFrame: è™•ç†å¾Œçš„çµæœ
    """
    print(f"\n{'='*80}")
    print(f"Step 4: Processing data (preserving max capacity point)")
    print(f"{'='*80}")
    
    # æ·»åŠ æœ€å¤§å®¹é‡çµæœä¸¦æ’åº
    all_results = results + [max_capacity_result]
    all_results.sort(key=lambda x: x['BPP'])
    
    # è½‰æ›ç‚ºDataFrame
    df = pd.DataFrame(all_results)
    
    # ä¿ç•™åŸå§‹æ•¸æ“š
    original_df = df.copy()
    
    # æ¨™è¨˜æœ€å¤§å®¹é‡é»
    max_capacity_idx = df[df['Target_Percentage'] == 100.0].index[0]
    
    # é‡å°å½©è‰²åœ–åƒèª¿æ•´å¹³æ»‘åƒæ•¸
    if img_info['is_color']:
        print("Applying color image specific data processing...")
        correction_strength = MeasurementConstants.COLOR_CORRECTION_STRENGTH
    else:
        correction_strength = MeasurementConstants.DEFAULT_CORRECTION_STRENGTH
    
    # æ‡‰ç”¨æ•¸æ“šå¹³æ»‘è™•ç†
    df = _apply_data_smoothing(df, max_capacity_idx, correction_strength, original_df)
    
    return df

def _apply_data_smoothing(df, max_capacity_idx, correction_strength, original_df):
    """æ‡‰ç”¨æ•¸æ“šå¹³æ»‘è™•ç†"""
    metrics_to_smooth = ['PSNR', 'SSIM', 'Hist_Corr']
    corrections_made = False
    corrections_log = []
    
    # å­˜å„²æœ€å¤§å®¹é‡é»çš„åŸå§‹æŒ‡æ¨™å€¼
    max_capacity_metrics = {
        metric: df.loc[max_capacity_idx, metric] for metric in metrics_to_smooth
    }
    
    # é‡å°æ¯å€‹éœ€è¦å¹³æ»‘çš„æŒ‡æ¨™
    for metric in metrics_to_smooth:
        # ç¢ºä¿å–®èª¿æ€§ï¼Œä½†æ’é™¤æœ€å¤§å®¹é‡é»çš„è™•ç†
        for i in range(1, len(df)):
            if i == max_capacity_idx:
                continue
                
            if df.iloc[i]['BPP'] > df.iloc[i-1]['BPP']:
                if df.iloc[i][metric] > df.iloc[i-1][metric]:
                    original_value = df.iloc[i][metric]
                    
                    # è¨ˆç®—é æœŸçš„é™ä½å€¼
                    if i > 1:
                        prev_rate = (df.iloc[i-2][metric] - df.iloc[i-1][metric]) / \
                                  (df.iloc[i-2]['BPP'] - df.iloc[i-1]['BPP'])
                        prev_rate = min(prev_rate, 0)
                        expected_change = prev_rate * (df.iloc[i]['BPP'] - df.iloc[i-1]['BPP'])
                        
                        if abs(expected_change) < 0.001:
                            expected_change = -0.005 * df.iloc[i-1][metric]
                        
                        corrected_value = df.iloc[i-1][metric] + expected_change
                        df.loc[df.index[i], metric] = df.iloc[i-1][metric] * (1 - correction_strength) + \
                                                    corrected_value * correction_strength
                    else:
                        df.loc[df.index[i], metric] = df.iloc[i-1][metric] * 0.995
                    
                    corrections_made = True
                    corrections_log.append(f"  {metric} at BPP={df.iloc[i]['BPP']:.4f}: {original_value:.4f} -> {df.loc[df.index[i], metric]:.4f}")
        
        # æ¢å¾©æœ€å¤§å®¹é‡é»çš„åŸå§‹æŒ‡æ¨™å€¼
        df.loc[max_capacity_idx, metric] = max_capacity_metrics[metric]
    
    # è¼¸å‡ºä¿®æ­£æ—¥èªŒ
    if corrections_made:
        print("Anomalous data points detected and corrected:")
        for correction in corrections_log:
            print(correction)
        
        # ç‚ºç•°å¸¸é»è™•ç†å‰å¾Œçš„æ¯”è¼ƒæ·»åŠ åˆ—
        for metric in metrics_to_smooth:
            df[f'{metric}_Original'] = original_df[metric]
    else:
        print("No anomalous data points detected.")
        for metric in metrics_to_smooth:
            df[f'{metric}_Original'] = df[metric]
    
    return df

# =============================================================================
# ç¬¬äº”æ­¥ï¼šçµæœä¿å­˜å’Œç¸½çµ
# =============================================================================

def _save_measurement_results(df, result_dir, imgName, method, method_name, total_time, img_info, logger):
    """
    æ­¥é©Ÿ5: ä¿å­˜çµæœå’Œç¸½çµ
    """
    print(f"\n{'='*80}")
    print(f"Step 5: Results summary")
    print(f"{'='*80}")
    
    # é¡¯ç¤ºç¸½çµä¿¡æ¯
    measurement_mode = df['Measurement_Mode'].iloc[0] if len(df) > 0 else "unknown"
    total_points = len(df)
    avg_time = total_time / total_points if total_points > 0 else 0
    
    summary_info = {
        "Image type": img_info['type_name'].capitalize(),
        "Pixel count used for BPP": img_info['pixel_count'],
        "Measurement mode used": measurement_mode,
        "Total data points generated": total_points,
        "Total processing time": f"{total_time:.2f} seconds",
        "Average time per point": f"{avg_time:.2f} seconds",
        "Results saved to": result_dir
    }
    
    for key, value in summary_info.items():
        print(f"{key}: {value}")
    
    # ä¿å­˜çµæœåˆ°CSV
    csv_path = f"{result_dir}/precise_measurements.csv"
    df.to_csv(csv_path, index=False)
    print(f"Results saved to {csv_path}")
    
    # è¨˜éŒ„åˆ°æ—¥èªŒ
    logger.log_step("Step 5: Results saved", summary_info)
    
    return csv_path

# =============================================================================
# é‡æ§‹å¾Œçš„ä¸»å‡½æ•¸
# =============================================================================

def run_precise_measurements(origImg, imgName, method, prediction_method, ratio_of_ones, 
                           total_embeddings=5, el_mode=0, segments=15, step_size=None, 
                           use_different_weights=False, split_size=2, block_base=False, 
                           quad_tree_params=None):
    """
    é‡æ§‹ç‰ˆçš„ç²¾ç¢ºæ¸¬é‡å‡½æ•¸ - ä¸»å‡½æ•¸ç¾åœ¨åªè² è²¬å”èª¿å„å€‹æ­¥é©Ÿ
    """
    # è¨˜éŒ„ç¸½é‹è¡Œé–‹å§‹æ™‚é–“
    total_start_time = time.time()
    
    # ğŸ”§ æ›´æ–°ï¼šä½¿ç”¨æ–°çš„åœ–åƒä¿¡æ¯ç²å–å‡½æ•¸
    img_info = get_image_info(origImg)
    
    # ç²å–æ–¹æ³•åç¨±
    if isinstance(prediction_method, str):
        method_name = prediction_method
    else:
        method_name = prediction_method.value
    
    # ğŸ”§ æ›´æ–°ï¼šä½¿ç”¨æ–°çš„è·¯å¾‘ç®¡ç†å·¥å…·
    from utils import get_precise_measurement_directories
    directories = get_precise_measurement_directories(imgName, method_name)
    result_dir = directories['result']
    ensure_dir(f"{result_dir}/dummy.txt")
    
    # è¨­ç½®æ—¥èªŒ
    log_file = f"{result_dir}/precise_measurements_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    logger = MeasurementLogger(log_file, imgName, method_name)
    
    # ç¢ºå®šæ¸¬é‡æ¨¡å¼
    payload_points, measurement_mode, _ = MeasurementPointGenerator.generate_points(
        1000000, step_size, segments  # æš«æ™‚ç”¨å¤§æ•¸å€¼ï¼Œå¾Œé¢æœƒç”¨å¯¦éš›æœ€å¤§å®¹é‡
    )
    
    # è¨˜éŒ„é–‹å§‹ä¿¡æ¯
    logger.log_header(img_info, measurement_mode, total_embeddings, el_mode, use_different_weights)
    
    print(f"Color image detected: {img_info['pixel_count']} pixel positions" if img_info['is_color'] 
          else f"Grayscale image detected: {img_info['pixel_count']} pixels")
    
    try:
        # æ­¥é©Ÿ1: æ‰¾å‡ºæœ€å¤§åµŒå…¥å®¹é‡
        final_img_max, max_payload, stages_max, max_run_time = _find_maximum_capacity(
            origImg, method, prediction_method, ratio_of_ones, 
            total_embeddings, el_mode, split_size, block_base, 
            quad_tree_params, use_different_weights, logger
        )
        
        # è¨ˆç®—æœ€å¤§å®¹é‡çš„å“è³ªæŒ‡æ¨™
        psnr_max, ssim_max, hist_corr_max = calculate_quality_metrics_unified(origImg, final_img_max, img_info)
        max_bpp = max_payload / img_info['pixel_count']
        
        # å‰µå»ºæœ€å¤§å®¹é‡çµæœ
        max_capacity_result = {
            'Target_Percentage': 100.0,
            'Target_Payload': max_payload,
            'Actual_Payload': max_payload,
            'BPP': max_bpp,
            'PSNR': psnr_max,
            'SSIM': ssim_max,
            'Hist_Corr': hist_corr_max,
            'Processing_Time': max_run_time,
            'Suspicious': False,
            'Image_Type': img_info['type_name'],
            'Pixel_Count': img_info['pixel_count']
        }
        
        print(f"Max BPP: {max_bpp:.6f}")
        print(f"Max PSNR: {psnr_max:.2f}")
        print(f"Max SSIM: {ssim_max:.4f}")
        
        # ä¿å­˜æœ€å¤§å®¹é‡çš„åµŒå…¥åœ–åƒ
        if img_info['is_color']:
            cv2.imwrite(f"{result_dir}/embedded_100pct.png", final_img_max)
        else:
            save_image(final_img_max, f"{result_dir}/embedded_100pct.png")
        
        # æ­¥é©Ÿ2: é‡æ–°ç”Ÿæˆæ¸¬é‡é»ï¼ˆä½¿ç”¨å¯¦éš›æœ€å¤§å®¹é‡ï¼‰
        payload_points, measurement_mode = _generate_measurement_points(
            max_payload, step_size, segments, logger
        )
        
        # æ­¥é©Ÿ3: æ‰¹é‡æ¸¬é‡åŸ·è¡Œ
        results = _run_measurement_batch(
            origImg, payload_points, method, prediction_method, 
            ratio_of_ones, total_embeddings, el_mode, split_size, 
            block_base, quad_tree_params, use_different_weights, 
            img_info, measurement_mode, result_dir, logger
        )
        
        # æ­¥é©Ÿ4: æ•¸æ“šè™•ç†å’Œå¹³æ»‘
        df = _process_measurement_results(results, max_capacity_result, img_info)
        
        # æ­¥é©Ÿ5: ä¿å­˜çµæœ
        total_time = time.time() - total_start_time
        csv_path = _save_measurement_results(
            df, result_dir, imgName, method, method_name, total_time, img_info, logger
        )
        
        # ç¢ºèªä½¿ç”¨çš„æ¸¬é‡æ¨¡å¼
        if step_size is not None and step_size > 0:
            print(f"Confirmed: Used step_size={step_size} bits for {method_name}")
        else:
            print(f"Confirmed: Used segments={segments} for {method_name}")
        
        return df
        
    except Exception as e:
        print(f"Error in precise measurements: {str(e)}")
        logger.log_step("Error occurred", {"Error": str(e)})
        raise e

# =============================================================================
# ç°¡åŒ–æ¸¬é‡å‡½æ•¸ï¼ˆé‡æ§‹ç‰ˆï¼‰
# =============================================================================

def run_simplified_precise_measurements(origImg, imgName, method, prediction_method, ratio_of_ones, 
                                       total_embeddings=5, el_mode=0, segments=15, step_size=None, 
                                       use_different_weights=False, split_size=2, block_base=False, 
                                       quad_tree_params=None):
    """
    ç°¡åŒ–ç‰ˆç²¾ç¢ºæ¸¬é‡å‡½æ•¸ - é‡ç”¨ä¸»å‡½æ•¸çš„é‚è¼¯ï¼Œä½†ä¸ä¿å­˜åœ–åƒå’Œåœ–è¡¨
    """
    # ğŸ”§ æ›´æ–°ï¼šä½¿ç”¨æ–°çš„åœ–åƒä¿¡æ¯ç²å–å‡½æ•¸
    img_info = get_image_info(origImg)
    
    # ç²å–æ–¹æ³•åç¨±
    method_name = prediction_method.value
    
    # è¨­ç½®ç°¡åŒ–çš„ç›®éŒ„çµæ§‹
    from utils import get_precise_measurement_directories
    directories = get_precise_measurement_directories(imgName, method_name)
    result_dir = directories['data']  # ä½¿ç”¨dataç›®éŒ„è€Œä¸æ˜¯resultç›®éŒ„
    ensure_dir(f"{result_dir}/dummy.txt")
    
    # è¨­ç½®æ—¥èªŒ
    log_file = f"{result_dir}/simplified_measurements_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    logger = MeasurementLogger(log_file, imgName, method_name)
    
    total_start_time = time.time()
    
    try:
        # æ­¥é©Ÿ1: æ‰¾å‡ºæœ€å¤§åµŒå…¥å®¹é‡ï¼ˆé‡ç”¨å‡½æ•¸ï¼‰
        final_img_max, max_payload, stages_max, max_run_time = _find_maximum_capacity(
            origImg, method, prediction_method, ratio_of_ones, 
            total_embeddings, el_mode, split_size, block_base, 
            quad_tree_params, use_different_weights, logger
        )
        
        # è¨ˆç®—æœ€å¤§å®¹é‡çš„å“è³ªæŒ‡æ¨™
        psnr_max, ssim_max, hist_corr_max = calculate_quality_metrics_unified(origImg, final_img_max, img_info)
        
        # å‰µå»ºæœ€å¤§å®¹é‡çµæœ
        max_capacity_result = {
            'Target_Percentage': 100.0,
            'Target_Payload': max_payload,
            'Actual_Payload': max_payload,
            'BPP': max_payload / img_info['pixel_count'],
            'PSNR': psnr_max,
            'SSIM': ssim_max,
            'Hist_Corr': hist_corr_max,
            'Processing_Time': max_run_time,
            'Measurement_Mode': f"simplified_mode"
        }
        
        print(f"Maximum payload: {max_payload} bits")
        print(f"Max BPP: {max_payload/img_info['pixel_count']:.6f}")
        
        # æ¸…ç†è¨˜æ†¶é«”
        cleanup_memory()
        
        # æ­¥é©Ÿ2: ç”Ÿæˆæ¸¬é‡é»
        payload_points, measurement_mode = _generate_measurement_points(
            max_payload, step_size, segments, logger
        )
        
        # æ­¥é©Ÿ3: ç°¡åŒ–çš„æ‰¹é‡æ¸¬é‡ï¼ˆä¸ä¿å­˜åœ–åƒï¼‰
        results = _run_simplified_measurement_batch(
            origImg, payload_points, method, prediction_method, 
            ratio_of_ones, total_embeddings, el_mode, split_size, 
            block_base, quad_tree_params, use_different_weights, 
            img_info, measurement_mode, logger
        )
        
        # æ·»åŠ æœ€å¤§å®¹é‡çµæœä¸¦è½‰æ›ç‚ºDataFrame
        all_results = results + [max_capacity_result]
        all_results.sort(key=lambda x: x['Target_Percentage'])
        df = pd.DataFrame(all_results)
        
        # ä¿å­˜çµæœ
        total_time = time.time() - total_start_time
        csv_path = f"{result_dir}/simplified_measurements.csv"
        df.to_csv(csv_path, index=False)
        
        print(f"Simplified measurements completed.")
        print(f"Total processing time: {total_time:.2f} seconds")
        print(f"Results saved to {csv_path}")
        
        return df
        
    except Exception as e:
        print(f"Error in simplified measurements: {str(e)}")
        logger.log_step("Error occurred", {"Error": str(e)})
        return pd.DataFrame()  # è¿”å›ç©ºDataFrameè€Œä¸æ˜¯æ‹‹å‡ºç•°å¸¸

def _run_simplified_measurement_batch(origImg, payload_points, method, prediction_method, 
                                    ratio_of_ones, total_embeddings, el_mode, split_size, 
                                    block_base, quad_tree_params, use_different_weights, 
                                    img_info, measurement_mode, logger):
    """ç°¡åŒ–ç‰ˆçš„æ‰¹é‡æ¸¬é‡ï¼ˆä¸ä¿å­˜åœ–åƒï¼‰"""
    results = []
    successful_measurements = 0
    failed_measurements = 0
    
    for i, target in enumerate(tqdm(payload_points, desc=f"è™•ç†æ•¸æ“šé»")):
        percentage = target / max(payload_points) * 100 if payload_points else 0
        
        print(f"\nRunning point {i+1}/{len(payload_points)}: {target} bits ({percentage:.1f}% of max)")
        
        start_time = time.time()
        try:
            final_img, actual_payload, stages = run_embedding_with_target(
                origImg, method, prediction_method, ratio_of_ones, 
                total_embeddings, el_mode, target_payload_size=target,
                split_size=split_size, block_base=block_base, 
                quad_tree_params=quad_tree_params,
                use_different_weights=use_different_weights
            )
            
            # é©—è­‰è¿”å›çš„æ•¸æ“š
            if final_img is None or actual_payload is None:
                print(f"  Warning: Invalid return data for target {target} bits")
                failed_measurements += 1
                continue
                
        except Exception as embedding_error:
            print(f"  Error in embedding for target {target} bits: {str(embedding_error)}")
            failed_measurements += 1
            continue
        
        run_time = time.time() - start_time
        
        # è¨ˆç®—è³ªé‡æŒ‡æ¨™
        try:
            psnr, ssim, hist_corr = calculate_quality_metrics_unified(origImg, final_img, img_info)
        except Exception as metrics_error:
            print(f"  Error calculating quality metrics: {str(metrics_error)}")
            failed_measurements += 1
            continue
        
        # è¨˜éŒ„çµæœ
        result = {
            'Target_Percentage': percentage,
            'Target_Payload': target,
            'Actual_Payload': actual_payload,
            'BPP': actual_payload / img_info['pixel_count'],
            'PSNR': psnr,
            'SSIM': ssim,
            'Hist_Corr': hist_corr,
            'Processing_Time': run_time,
            'Measurement_Mode': measurement_mode
        }
        results.append(result)
        successful_measurements += 1
        
        print(f"  Actual: {actual_payload} bits, PSNR: {psnr:.2f}, Time: {run_time:.2f}s")
        
        # æ¸…ç†è¨˜æ†¶é«”
        cleanup_memory()
    
    # è¨˜éŒ„æ‰¹é‡æ¸¬é‡çµ±è¨ˆ
    logger.log_step("Simplified batch measurement completed", {
        "Successful measurements": successful_measurements,
        "Failed measurements": failed_measurements,
        "Success rate": f"{(successful_measurements / (successful_measurements + failed_measurements) * 100):.1f}%" if (successful_measurements + failed_measurements) > 0 else "0%"
    })
    
    return results

def run_embedding_with_target(origImg, method, prediction_method, ratio_of_ones, 
                                   total_embeddings, el_mode, target_payload_size,
                                   split_size=2, block_base=False, quad_tree_params=None,
                                   use_different_weights=False):
    """
    ä¿®å¾©ç‰ˆçš„åµŒå…¥æ¸¬è©¦å‡½æ•¸ï¼Œæ­£ç¢ºè™•ç†å½©è‰²åœ–åƒçš„ç›®æ¨™å®¹é‡å’ŒBPPè¨ˆç®—
    """
    from embedding import (
        pee_process_with_rotation_cuda,
        pee_process_with_split_cuda
    )
    from quadtree import pee_process_with_quadtree_cuda
    
    # æª¢æ¸¬åœ–åƒé¡å‹
    is_color = len(origImg.shape) == 3 and origImg.shape[2] == 3
    
    if is_color:
        print(f"Processing color image with target: {target_payload_size} bits")
        print(f"Expected capacity: ~3x equivalent grayscale image")
    else:
        print(f"Processing grayscale image with target: {target_payload_size} bits")
    
    # é‡ç½®GPUè¨˜æ†¶é«”
    cp.get_default_memory_pool().free_all_blocks()
    
    # ä¿®æ­£æ¬Šé‡è¨­ç½®
    if prediction_method in [PredictionMethod.MED, PredictionMethod.GAP, PredictionMethod.RHOMBUS]:
        actual_use_weights = False
        if use_different_weights:
            print(f"Note: Weight optimization disabled for {prediction_method.value} prediction method")
    else:
        actual_use_weights = use_different_weights
    
    try:
        if method == "rotation":
            final_img, actual_payload, stages = pee_process_with_rotation_cuda(
                origImg,
                total_embeddings,
                ratio_of_ones,
                actual_use_weights,
                split_size,
                el_mode,
                prediction_method=prediction_method,
                target_payload_size=target_payload_size
            )
        elif method == "split":
            final_img, actual_payload, stages = pee_process_with_split_cuda(
                origImg,
                total_embeddings,
                ratio_of_ones,
                actual_use_weights,
                split_size,
                el_mode,
                block_base,
                prediction_method=prediction_method,
                target_payload_size=target_payload_size
            )
        elif method == "quadtree":
            if quad_tree_params is None:
                quad_tree_params = {
                    'min_block_size': 16,
                    'variance_threshold': 300
                }
            
            final_img, actual_payload, stages = pee_process_with_quadtree_cuda(
                origImg,
                total_embeddings,
                ratio_of_ones,
                actual_use_weights,
                quad_tree_params['min_block_size'],
                quad_tree_params['variance_threshold'],
                el_mode,
                rotation_mode='random',
                prediction_method=prediction_method,
                target_payload_size=target_payload_size
            )
        else:
            raise ValueError(f"Unknown method: {method}")
        
        return final_img, actual_payload, stages
        
    except Exception as e:
        print(f"Error in embedding: method={method}, predictor={prediction_method.value}")
        print(f"Error details: {str(e)}")
        raise e

# =============================================================================
# å¤šé æ¸¬å™¨æ¸¬é‡ç›¸é—œå‡½æ•¸ï¼ˆä¿ç•™åŸæœ‰é‚è¼¯ï¼Œä½†æ›´æ–°å°å…¥ï¼‰
# =============================================================================

class MultiPredictorConfig:
    """å¤šé æ¸¬å™¨æ¸¬é‡çš„é…ç½®ç®¡ç†"""
    
    DEFAULT_PREDICTOR_RATIOS = {
        "PROPOSED": 0.5,
        "MED": 1.0,
        "GAP": 1.0,
        "RHOMBUS": 1.0
    }
    
    PREDICTION_METHODS = [
        PredictionMethod.PROPOSED,
        PredictionMethod.MED,
        PredictionMethod.GAP,
        PredictionMethod.RHOMBUS
    ]

def _setup_multi_predictor_environment(imgName, filetype, method, quad_tree_params):
    """è¨­ç½®å¤šé æ¸¬å™¨æ¸¬é‡çš„ç’°å¢ƒ"""
    # è®€å–åŸå§‹åœ–åƒ
    from image_processing import read_image_auto
    from utils import find_image_path
    
    try:
        img_path = find_image_path(imgName, filetype)
        print(f"Loading image from: {img_path}")
        origImg, is_grayscale_img = read_image_auto(img_path)
        return origImg, is_grayscale_img
    except FileNotFoundError as e:
        raise ValueError(str(e))

def _create_multi_predictor_logger(comparison_dir, step_size, segments, predictor_ratios, 
                                  total_embeddings, el_mode, method, quad_tree_params):
    """å‰µå»ºå¤šé æ¸¬å™¨æ¸¬é‡çš„æ—¥èªŒæ–‡ä»¶"""
    log_file = f"{comparison_dir}/multi_predictor_precise_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    
    with open(log_file, 'w', encoding='utf-8') as f:
        f.write(f"Multi-predictor precise measurement run started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Method: {method}\n")
        f.write(f"Total embeddings: {total_embeddings}\n")
        f.write(f"EL mode: {el_mode}\n")
        
        # è¨˜éŒ„æ¸¬é‡æ¨¡å¼
        if step_size is not None and step_size > 0:
            f.write(f"Using step_size: {step_size} bits (segments parameter ignored)\n")
            f.write(f"Measurement mode: step_size\n")
        else:
            f.write(f"Using segments: {segments} (no step_size provided)\n")
            f.write(f"Measurement mode: segments\n")
            
        f.write("Predictor ratio settings:\n")
        for pred, ratio in predictor_ratios.items():
            f.write(f"  {pred}: {ratio}\n")
            
        if method == "quadtree":
            f.write(f"Quadtree params: min_block_size={quad_tree_params['min_block_size']}, variance_threshold={quad_tree_params['variance_threshold']}\n")
        f.write("\n" + "="*80 + "\n\n")
    
    return log_file

def _process_single_predictor(prediction_method, predictor_ratios, imgName, method, 
                             total_embeddings, el_mode, segments, step_size, 
                             use_different_weights, split_size, block_base, 
                             quad_tree_params, origImg, log_file):
    """è™•ç†å–®å€‹é æ¸¬å™¨çš„æ¸¬é‡"""
    method_name = prediction_method.value.upper()
    is_proposed = method_name.upper() == "PROPOSED"
    
    print(f"\n{'='*80}")
    print(f"Running precise measurements for {method_name.lower()} predictor")
    
    # é¡¯ç¤ºä½¿ç”¨çš„æ¸¬é‡åƒæ•¸
    if step_size is not None and step_size > 0:
        print(f"Using step_size: {step_size} bits (segments parameter {segments} will be ignored)")
    else:
        print(f"Using segments: {segments} (no step_size provided)")
    print(f"{'='*80}")
    
    # ç²å–ç•¶å‰é æ¸¬å™¨çš„ratio_of_ones
    current_ratio_of_ones = predictor_ratios.get(method_name, 0.5)
    print(f"Using ratio_of_ones = {current_ratio_of_ones}")
    
    # è¨˜éŒ„åˆ°æ—¥èªŒ
    with open(log_file, 'a', encoding='utf-8') as f:
        f.write(f"Starting precise measurements for {method_name.lower()} predictor\n")
        f.write(f"Using ratio_of_ones = {current_ratio_of_ones}\n")
        if step_size is not None and step_size > 0:
            f.write(f"Using step_size = {step_size} bits\n")
        else:
            f.write(f"Using segments = {segments}\n")
        f.write("\n")
    
    try:
        predictor_start_time = time.time()
        
        if is_proposed:
            # å°æ–¼ proposed é æ¸¬å™¨ï¼Œå„²å­˜æ‰€æœ‰è©³ç´°è³‡æ–™
            results_df = run_precise_measurements(
                origImg, imgName, method, prediction_method, 
                current_ratio_of_ones, total_embeddings, 
                el_mode, segments, step_size,
                use_different_weights, split_size, block_base, quad_tree_params
            )
        else:
            # å°æ–¼å…¶ä»–é æ¸¬å™¨ï¼Œåƒ…å„²å­˜æ•¸æ“šè€Œä¸å„²å­˜åœ–åƒå’Œåœ–è¡¨
            results_df = run_simplified_precise_measurements(
                origImg, imgName, method, prediction_method, 
                current_ratio_of_ones, total_embeddings, 
                el_mode, segments, step_size,
                use_different_weights, split_size, block_base, quad_tree_params
            )
        
        predictor_time = time.time() - predictor_start_time
        
        # è¨˜éŒ„å®Œæˆä¿¡æ¯
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(f"Completed measurements for {method_name.lower()} predictor\n")
            f.write(f"Time taken: {predictor_time:.2f} seconds\n")
            f.write(f"Generated {len(results_df)} data points\n")
            if step_size is not None and step_size > 0:
                f.write(f"Measurement mode used: step_size={step_size}\n")
            else:
                f.write(f"Measurement mode used: segments={segments}\n")
            f.write("\n")
        
        # æ¸…ç†è¨˜æ†¶é«”
        cleanup_memory()
        
        return results_df, predictor_time
        
    except Exception as e:
        print(f"Error processing {method_name.lower()}: {str(e)}")
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(f"Error processing {method_name.lower()}: {str(e)}\n")
            f.write(traceback.format_exc())
            f.write("\n\n")
        return None, 0

def _finalize_multi_predictor_results(all_results, comparison_dir, imgName, method, 
                                     total_start_time, step_size, segments, log_file):
    """å®Œæˆå¤šé æ¸¬å™¨çµæœçš„è™•ç†å’Œä¿å­˜"""
    if not all_results:
        print("No valid results to process")
        return all_results
    
    try:
        # å°å…¥ç¹ªåœ–å‡½æ•¸ï¼ˆå¦‚æœéœ€è¦çš„è©±ï¼Œå¯ä»¥ç§»åˆ° visualization.pyï¼‰
        # plot_predictor_comparison(all_results, imgName, method, comparison_dir)
        
        # è¨˜éŒ„é‹è¡Œæ™‚é–“
        total_time = time.time() - total_start_time
        
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(f"\nComparison completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Total processing time: {total_time:.2f} seconds\n")
            if step_size is not None and step_size > 0:
                f.write(f"Final confirmation: Used step_size={step_size} for all predictors\n")
            else:
                f.write(f"Final confirmation: Used segments={segments} for all predictors\n")
            f.write("\n")
        
        print(f"\nComparison completed and saved to {comparison_dir}")
        print(f"Total processing time: {total_time:.2f} seconds")
        
        # ç¢ºèªä½¿ç”¨çš„æ¸¬é‡æ¨¡å¼
        if step_size is not None and step_size > 0:
            print(f"Confirmed: All predictors used step_size={step_size} bits")
        else:
            print(f"Confirmed: All predictors used segments={segments}")
        
        # å‰µå»ºå¯¬æ ¼å¼è¡¨æ ¼ï¼ˆå¦‚æœéœ€è¦çš„è©±ï¼‰
        # create_wide_format_tables(all_results, comparison_dir)
        
        return all_results
        
    except Exception as e:
        print(f"Error generating comparison: {str(e)}")
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(f"\nError generating comparison: {str(e)}\n")
            f.write(traceback.format_exc())
        return all_results

# =============================================================================
# é‡æ§‹å¾Œçš„ä¸»å‡½æ•¸
# =============================================================================

def run_multi_predictor_precise_measurements(imgName, filetype="png", method="quadtree", 
                                           predictor_ratios=None, total_embeddings=5, 
                                           el_mode=0, segments=15, step_size=None, use_different_weights=False,
                                           split_size=2, block_base=False, quad_tree_params=None):
    """
    é‡æ§‹ç‰ˆçš„å¤šé æ¸¬å™¨ç²¾ç¢ºæ¸¬é‡å‡½æ•¸
    """
    
    # è¨­ç½®é»˜èªçš„é æ¸¬å™¨ratioå­—å…¸
    if predictor_ratios is None:
        predictor_ratios = MultiPredictorConfig.DEFAULT_PREDICTOR_RATIOS
    
    # è¨˜éŒ„ç¸½é‹è¡Œé–‹å§‹æ™‚é–“
    total_start_time = time.time()
    
    # æ­¥é©Ÿ1: è¨­ç½®ç’°å¢ƒ
    print("Step 1: Setting up multi-predictor measurement environment")
    try:
        origImg, is_grayscale_img = _setup_multi_predictor_environment(
            imgName, filetype, method, quad_tree_params
        )
    except ValueError as e:
        print(f"Failed to setup environment: {e}")
        return None
    
    # æ­¥é©Ÿ2: å‰µå»ºæ¯”è¼ƒçµæœç›®éŒ„å’Œæ—¥èªŒ
    print("Step 2: Creating output directories and logging setup")
    from utils import get_precise_measurement_directories
    
    comparison_dir = f"{PathConstants.BASE_OUTPUT_DIR}/plots/{imgName}/precise_comparison"
    ensure_dir(f"{comparison_dir}/dummy.txt")
    
    log_file = _create_multi_predictor_logger(
        comparison_dir, step_size, segments, predictor_ratios, 
        total_embeddings, el_mode, method, quad_tree_params
    )
    
    # æ­¥é©Ÿ3: ä¾æ¬¡é‹è¡Œæ¯ç¨®é æ¸¬æ–¹æ³•
    print("Step 3: Running measurements for each predictor")
    all_results = {}
    
    for prediction_method in tqdm(MultiPredictorConfig.PREDICTION_METHODS, desc="è™•ç†é æ¸¬å™¨"):
        method_name = prediction_method.value.upper()
        
        # è™•ç†å–®å€‹é æ¸¬å™¨
        results_df, predictor_time = _process_single_predictor(
            prediction_method, predictor_ratios, imgName, method, 
            total_embeddings, el_mode, segments, step_size, 
            use_different_weights, split_size, block_base, 
            quad_tree_params, origImg, log_file
        )
        
        if results_df is not None and len(results_df) > 0:
            # ä¿å­˜çµæœ
            all_results[method_name.lower()] = results_df
            
            # ä¿å­˜CSVåˆ°æ¯”è¼ƒç›®éŒ„
            results_df.to_csv(f"{comparison_dir}/{method_name.lower()}_precise.csv", index=False)
            print(f"Saved results for {method_name.lower()} predictor")
        else:
            print(f"Warning: No valid results for {method_name.lower()} predictor")
    
    # æ­¥é©Ÿ4: ç”Ÿæˆæ¯”è¼ƒåœ–è¡¨å’Œæœ€çµ‚è™•ç†
    print("Step 4: Finalizing results and generating comparison")
    final_results = _finalize_multi_predictor_results(
        all_results, comparison_dir, imgName, method, 
        total_start_time, step_size, segments, log_file
    )
    
    return final_results

# =============================================================================
# æ–¹æ³•æ¯”è¼ƒçš„è¼”åŠ©å‡½æ•¸
# =============================================================================

class MethodComparisonConfig:
    """æ–¹æ³•æ¯”è¼ƒçš„é…ç½®ç®¡ç†"""
    
    DEFAULT_METHODS = ["rotation", "split", "quadtree"]
    
    DEFAULT_METHOD_PARAMS = {
        "rotation": {"split_size": 2, "use_different_weights": False},
        "split": {"split_size": 2, "block_base": False, "use_different_weights": False},
        "quadtree": {"min_block_size": 16, "variance_threshold": 300, "use_different_weights": False}
    }
    
    PREDICTOR_MAP = {
        "proposed": PredictionMethod.PROPOSED,
        "med": PredictionMethod.MED,
        "gap": PredictionMethod.GAP,
        "rhombus": PredictionMethod.RHOMBUS
    }

def _validate_method_comparison_params(methods, method_params, predictor):
    """é©—è­‰å’Œè¨­ç½®æ–¹æ³•æ¯”è¼ƒçš„åƒæ•¸"""
    # å¦‚æœæœªæä¾›æ–¹æ³•ï¼Œä½¿ç”¨é»˜èªæ–¹æ³•
    if methods is None:
        methods = MethodComparisonConfig.DEFAULT_METHODS
    
    # å¦‚æœæœªæä¾›æ–¹æ³•åƒæ•¸ï¼Œä½¿ç”¨é»˜èªåƒæ•¸
    if method_params is None:
        method_params = MethodComparisonConfig.DEFAULT_METHOD_PARAMS.copy()
    
    # é©—è­‰é æ¸¬å™¨
    prediction_method = MethodComparisonConfig.PREDICTOR_MAP.get(predictor.lower())
    if prediction_method is None:
        prediction_method = PredictionMethod.PROPOSED
        print(f"Warning: Unknown predictor '{predictor}', using PROPOSED instead")
    
    return methods, method_params, prediction_method

def _setup_method_comparison_environment(imgName, filetype, predictor):
    """è¨­ç½®æ–¹æ³•æ¯”è¼ƒçš„ç’°å¢ƒ"""
    import cv2
    
    # è®€å–åŸå§‹åœ–åƒ
    origImg = cv2.imread(f"{PathConstants.BASE_IMAGE_DIR}/{imgName}.{filetype}", cv2.IMREAD_GRAYSCALE)
    if origImg is None:
        raise ValueError(f"Failed to read image: {PathConstants.BASE_IMAGE_DIR}/{imgName}.{filetype}")
    
    # å‰µå»ºæ¯”è¼ƒè¼¸å‡ºç›®éŒ„
    comparison_dir = f"{PathConstants.BASE_OUTPUT_DIR}/plots/{imgName}/method_comparison_{predictor}"
    ensure_dir(f"{comparison_dir}/dummy.txt")
    
    return origImg, comparison_dir

def _create_method_comparison_logger(comparison_dir, imgName, filetype, predictor, 
                                   methods, total_embeddings, el_mode, step_size, segments):
    """å‰µå»ºæ–¹æ³•æ¯”è¼ƒçš„æ—¥èªŒæ–‡ä»¶"""
    log_file = f"{comparison_dir}/method_comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    
    with open(log_file, 'w') as f:
        f.write(f"Method comparison started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Image: {imgName}.{filetype}\n")
        f.write(f"Predictor: {predictor}\n")
        f.write(f"Methods to compare: {methods}\n")
        f.write(f"Total embeddings: {total_embeddings}\n")
        f.write(f"EL mode: {el_mode}\n")
        if step_size:
            f.write(f"Step size: {step_size} bits\n")
        else:
            f.write(f"Segments: {segments}\n")
        f.write("\n" + "="*80 + "\n\n")
    
    return log_file

def _prepare_method_params(method_name, method_params):
    """æº–å‚™å–®å€‹æ–¹æ³•çš„åƒæ•¸"""
    params = method_params.get(method_name, {}).copy()
    
    # å°å››å‰æ¨¹æ–¹æ³•é€²è¡Œç‰¹æ®Šè™•ç†
    if method_name == "quadtree":
        # å‰µå»ºæˆ–æ›´æ–° quad_tree_params å­—å…¸
        quad_tree_params = {}
        if "min_block_size" in params:
            quad_tree_params["min_block_size"] = params.pop("min_block_size")
        if "variance_threshold" in params:
            quad_tree_params["variance_threshold"] = params.pop("variance_threshold")
        # ä¿ç•™ use_different_weights åœ¨ä¸»åƒæ•¸ä¸­
        params["quad_tree_params"] = quad_tree_params
    
    return params

def _process_single_method(method_name, origImg, imgName, prediction_method, ratio_of_ones,
                          total_embeddings, el_mode, segments, step_size, 
                          method_params, comparison_dir, log_file):
    """è™•ç†å–®å€‹æ–¹æ³•çš„æ¸¬é‡"""
    print(f"\n{'='*80}")
    print(f"Running precise measurements for {method_name} method")
    print(f"{'='*80}")
    
    try:
        # æº–å‚™æ–¹æ³•åƒæ•¸
        params = _prepare_method_params(method_name, method_params)
        
        # é‹è¡Œç²¾ç¢ºæ¸¬é‡
        results_df = run_precise_measurements(
            origImg, imgName, method_name, prediction_method, ratio_of_ones,
            total_embeddings, el_mode, segments, step_size,
            **params  # å±•é–‹æ–¹æ³•ç‰¹å®šåƒæ•¸
        )
        
        # ä¿å­˜ç‚ºCSV
        csv_filename = f"{method_name}_{prediction_method.value}_precise.csv"
        results_df.to_csv(f"{comparison_dir}/{csv_filename}", index=False)
        
        # è¨˜éŒ„å®Œæˆ
        with open(log_file, 'a') as f:
            f.write(f"Completed measurements for {method_name} method\n")
            f.write(f"Results saved to {comparison_dir}/{csv_filename}\n\n")
        
        print(f"Completed measurements for {method_name} method")
        return results_df
        
    except Exception as e:
        print(f"Error processing {method_name}: {str(e)}")
        with open(log_file, 'a') as f:
            f.write(f"Error processing {method_name}: {str(e)}\n")
            f.write(traceback.format_exc())
            f.write("\n\n")
        
        # ç¢ºä¿æ¸…ç†è¨˜æ†¶é«”
        cleanup_memory()
        return None

def _finalize_method_comparison_results(all_results, imgName, predictor, comparison_dir):
    """å®Œæˆæ–¹æ³•æ¯”è¼ƒçµæœçš„è™•ç†"""
    if not all_results:
        print("No valid results for comparison")
        return all_results
    
    try:
        # å‰µå»ºæ¯”è¼ƒåœ–è¡¨ï¼ˆå¯ä»¥ç§»åˆ° visualization.pyï¼‰
        # plot_method_comparison(all_results, imgName, predictor, comparison_dir)
        
        # å‰µå»ºæ¯”è¼ƒè¡¨æ ¼ï¼ˆå¯ä»¥ç§»åˆ° visualization.pyï¼‰
        # create_comparative_table(all_results, f"{comparison_dir}/method_comparison_table.csv")
        
        print(f"Method comparison completed.")
        print(f"Results saved to {comparison_dir}")
        
        return all_results
        
    except Exception as e:
        print(f"Error finalizing method comparison: {str(e)}")
        return all_results

# =============================================================================
# é‡æ§‹å¾Œçš„ä¸»å‡½æ•¸
# =============================================================================

def run_method_comparison(imgName, filetype="png", predictor="proposed", 
                        ratio_of_ones=0.5, methods=None, method_params=None,
                        total_embeddings=5, el_mode=0, segments=15, step_size=None):
    """
    é‡æ§‹ç‰ˆçš„æ–¹æ³•æ¯”è¼ƒå‡½æ•¸
    
    ä¸»è¦æ”¹é€²ï¼š
    1. æ‹†åˆ†ç‚ºå¤šå€‹å°å‡½æ•¸ï¼Œè·è²¬æ˜ç¢º
    2. çµ±ä¸€çš„åƒæ•¸é©—è­‰å’ŒéŒ¯èª¤è™•ç†
    3. é‡ç”¨å·²é‡æ§‹çš„ run_precise_measurements
    4. æ›´æ¸…æ™°çš„æ­¥é©ŸåŠƒåˆ†
    
    Parameters:
    -----------
    imgName : str
        åœ–åƒåç¨±
    filetype : str
        åœ–åƒæª”æ¡ˆé¡å‹
    predictor : str
        æ‰€æœ‰æ¯”è¼ƒä½¿ç”¨çš„é æ¸¬æ–¹æ³• ("proposed", "med", "gap", "rhombus")
    ratio_of_ones : float
        åµŒå…¥æ•¸æ“šä¸­1çš„æ¯”ä¾‹
    methods : list of str
        è¦æ¯”è¼ƒçš„æ–¹æ³• (ä¾‹å¦‚ ["rotation", "split", "quadtree"])
    method_params : dict of dict
        æ¯å€‹æ–¹æ³•çš„ç‰¹å®šåƒæ•¸
    total_embeddings : int
        ç¸½åµŒå…¥æ¬¡æ•¸
    el_mode : int
        ELæ¨¡å¼
    segments : int
        æ¸¬é‡åˆ†æ®µæ•¸é‡ (å¦‚æœæä¾›äº†step_sizeå‰‡å¿½ç•¥)
    step_size : int, optional
        æ¸¬é‡é»ä¹‹é–“çš„æ­¥é•· (ä½å…ƒ)
    
    Returns:
    --------
    dict
        åŒ…å«æ¯å€‹æ–¹æ³•çµæœçš„å­—å…¸ {æ–¹æ³•åç¨±: DataFrame}
    """
    
    print(f"\n{'='*80}")
    print(f"Starting method comparison with {predictor} predictor")
    print(f"{'='*80}")
    
    # æ­¥é©Ÿ1: é©—è­‰å’Œè¨­ç½®åƒæ•¸
    print("Step 1: Validating parameters and setup")
    methods, method_params, prediction_method = _validate_method_comparison_params(
        methods, method_params, predictor
    )
    
    print(f"Methods to compare: {methods}")
    print(f"Using predictor: {prediction_method.value}")
    
    # æ­¥é©Ÿ2: è¨­ç½®ç’°å¢ƒ
    print("Step 2: Setting up comparison environment")
    try:
        origImg, comparison_dir = _setup_method_comparison_environment(
            imgName, filetype, predictor
        )
    except ValueError as e:
        print(f"Failed to setup environment: {e}")
        return None
    
    # æ­¥é©Ÿ3: å‰µå»ºæ—¥èªŒ
    print("Step 3: Creating comparison log")
    log_file = _create_method_comparison_logger(
        comparison_dir, imgName, filetype, predictor, 
        methods, total_embeddings, el_mode, step_size, segments
    )
    
    # æ­¥é©Ÿ4: è™•ç†æ¯å€‹æ–¹æ³•
    print("Step 4: Running measurements for each method")
    all_results = {}
    
    for method_name in methods:
        results_df = _process_single_method(
            method_name, origImg, imgName, prediction_method, ratio_of_ones,
            total_embeddings, el_mode, segments, step_size, 
            method_params, comparison_dir, log_file
        )
        
        if results_df is not None:
            all_results[method_name] = results_df
        else:
            print(f"Warning: No valid results for {method_name} method")
    
    # æ­¥é©Ÿ5: å®Œæˆæ¯”è¼ƒçµæœè™•ç†
    print("Step 5: Finalizing comparison results")
    final_results = _finalize_method_comparison_results(
        all_results, imgName, predictor, comparison_dir
    )
    
    return final_results


# =============================================================================
# æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥å‡½æ•¸ï¼ˆé‡æ§‹ç‰ˆï¼‰
# =============================================================================

def ensure_bpp_psnr_consistency(results_df, is_color=False):
    """
    é‡æ§‹ç‰ˆçš„BPP-PSNRä¸€è‡´æ€§æª¢æŸ¥å‡½æ•¸
    
    ä¸»è¦æ”¹é€²ï¼š
    1. ä½¿ç”¨å¸¸æ•¸è€Œéé­”æ³•æ•¸å­—
    2. æ›´æ¸…æ™°çš„é‚è¼¯çµæ§‹
    3. çµ±ä¸€çš„è™•ç†ç­–ç•¥
    """
    df = results_df.copy().sort_values('BPP')
    
    # æ ¹æ“šåœ–åƒé¡å‹èª¿æ•´æª¢æŸ¥åƒæ•¸
    if is_color:
        tolerance_factor = MeasurementConstants.COLOR_CORRECTION_STRENGTH * 3
        print("Applying color image specific consistency checks...")
    else:
        tolerance_factor = MeasurementConstants.DEFAULT_CORRECTION_STRENGTH * 2
    
    # ç¢ºä¿ PSNR éš¨è‘— BPP å¢åŠ è€Œå–®èª¿ä¸‹é™
    df = _ensure_metric_monotonicity(df, 'PSNR', tolerance_factor, is_color)
    
    # å°å…¶ä»–æŒ‡æ¨™é€²è¡Œé¡ä¼¼è™•ç†
    for metric in ['SSIM', 'Hist_Corr']:
        df = _ensure_metric_monotonicity(df, metric, tolerance_factor, is_color)
    
    return df.sort_values('Target_Percentage')

def _ensure_metric_monotonicity(df, metric, tolerance_factor, is_color):
    """ç¢ºä¿æŒ‡æ¨™çš„å–®èª¿æ€§"""
    for i in range(1, len(df)):
        if df.iloc[i][metric] > df.iloc[i-1][metric]:
            if i > 1:
                # è¨ˆç®—é æœŸçš„è®ŠåŒ–
                prev_slope = (df.iloc[i-1][metric] - df.iloc[i-2][metric]) / \
                           (df.iloc[i-1]['BPP'] - df.iloc[i-2]['BPP'])
                expected_drop = prev_slope * (df.iloc[i]['BPP'] - df.iloc[i-1]['BPP'])
                
                # æ‡‰ç”¨ä¿®æ­£
                decay_factor = 0.998 if is_color else 0.995
                corrected_value = max(
                    df.iloc[i-1][metric] + expected_drop, 
                    df.iloc[i-1][metric] * decay_factor
                )
                df.loc[df.index[i], metric] = corrected_value
            else:
                # å°æ–¼å‰é¢çš„é»ï¼Œä½¿ç”¨ç™¾åˆ†æ¯”é™ä½
                decay_factor = 0.998 if is_color else 0.995
                df.loc[df.index[i], metric] = df.iloc[i-1][metric] * decay_factor
    
    return df

# =============================================================================
# çµ±è¨ˆå‡½æ•¸ï¼ˆé‡æ§‹ç‰ˆï¼‰
# =============================================================================

def generate_interval_statistics(original_img, stages, total_payload, segments=15):
    """
    é‡æ§‹ç‰ˆçš„çµ±è¨ˆæ•¸æ“šç”Ÿæˆå‡½æ•¸
    
    ä¸»è¦æ”¹é€²ï¼š
    1. ä½¿ç”¨çµ±ä¸€çš„åœ–åƒä¿¡æ¯ç²å–
    2. é‡ç”¨è³ªé‡æŒ‡æ¨™è¨ˆç®—å‡½æ•¸
    3. æ›´æ¸…æ™°çš„éŒ¯èª¤è™•ç†
    """
    # ç¢ºä¿è¼¸å…¥æ•¸æ“šé¡å‹æ­£ç¢º
    if isinstance(original_img, cp.ndarray):
        original_img = cp.asnumpy(original_img)
    
    # ç²å–åœ–åƒä¿¡æ¯
    img_info = get_image_info(original_img)
    print(f"Generating interval statistics for {img_info['description']}")
    
    # é©—è­‰è¼¸å…¥
    if total_payload <= 0:
        print("Warning: Total payload is zero or negative. No statistics generated.")
        return None, None
    
    # è¨­ç½®åˆ†æ®µåƒæ•¸
    segments = max(2, min(segments, total_payload))
    
    # ç”Ÿæˆçµ±è¨ˆæ•¸æ“š
    results = _generate_payload_intervals(
        original_img, stages, total_payload, segments, img_info
    )
    
    if not results:
        return None, None
    
    # å‰µå»ºDataFrameå’Œè¡¨æ ¼
    df = pd.DataFrame(results)
    table = _create_statistics_table(results)
    
    return df, table

def _generate_payload_intervals(original_img, stages, total_payload, segments, img_info):
    """ç”Ÿæˆè¼‰è·é–“éš”çš„çµ±è¨ˆæ•¸æ“š"""
    # è¨ˆç®—æ¯å€‹ç´šè·çš„ç›®æ¨™åµŒå…¥é‡
    payload_interval = total_payload / segments
    payload_points = [int(i * payload_interval) for i in range(1, segments + 1)]
    payload_points[-1] = total_payload  # ç¢ºä¿æœ€å¾Œä¸€å€‹é»æ˜¯ç¸½åµŒå…¥é‡
    
    results = []
    accumulated_payload = 0
    current_stage_index = 0
    current_stage_img = None
    
    for target_payload in payload_points:
        # æ¨¡æ“¬åµŒå…¥åˆ°ç›®æ¨™åµŒå…¥é‡çš„åœ–åƒç‹€æ…‹
        current_stage_img = _find_stage_for_payload(
            stages, target_payload, accumulated_payload, current_stage_index
        )
        
        if current_stage_img is None:
            print("Warning: No valid stage image found.")
            continue
        
        # è¨ˆç®—æ€§èƒ½æŒ‡æ¨™
        psnr, ssim, hist_corr = calculate_quality_metrics_unified(
            original_img, current_stage_img, img_info
        )
        
        # è¨ˆç®—BPP
        bpp = target_payload / img_info['pixel_count']
        
        # æ·»åŠ åˆ°çµæœåˆ—è¡¨
        results.append({
            'Payload': target_payload,
            'BPP': bpp,
            'PSNR': psnr,
            'SSIM': ssim,
            'Hist_Corr': hist_corr
        })
    
    return results

def _find_stage_for_payload(stages, target_payload, accumulated_payload, current_stage_index):
    """ç‚ºçµ¦å®šçš„payloadæ‰¾åˆ°å°æ‡‰çš„stageåœ–åƒ"""
    temp_accumulated = accumulated_payload
    temp_index = current_stage_index
    current_stage_img = None
    
    while temp_accumulated < target_payload and temp_index < len(stages):
        current_stage = stages[temp_index]
        stage_payload = current_stage['payload']
        current_stage_img = current_stage['stage_img']
        
        # ç¢ºä¿æ˜¯numpyæ ¼å¼
        if isinstance(current_stage_img, cp.ndarray):
            current_stage_img = cp.asnumpy(current_stage_img)
        
        if temp_accumulated + stage_payload <= target_payload:
            # å®Œæ•´åŒ…å«ç•¶å‰éšæ®µ
            temp_accumulated += stage_payload
            temp_index += 1
        else:
            # éƒ¨åˆ†åŒ…å«ç•¶å‰éšæ®µ
            break
    
    # ç¢ºä¿æœ‰æœ‰æ•ˆçš„åœ–åƒ
    if current_stage_img is None and temp_index > 0:
        prev_stage = stages[temp_index - 1]
        current_stage_img = prev_stage['stage_img']
        if isinstance(current_stage_img, cp.ndarray):
            current_stage_img = cp.asnumpy(current_stage_img)
    
    return current_stage_img

def _create_statistics_table(results):
    """å‰µå»ºçµ±è¨ˆæ•¸æ“šçš„PrettyTable"""
    table = pt.PrettyTable()
    table.field_names = ["Payload", "BPP", "PSNR", "SSIM", "Hist_Corr"]
    
    for result in results:
        table.add_row([
            result['Payload'],
            f"{result['BPP']:.6f}",
            f"{result['PSNR']:.2f}",
            f"{result['SSIM']:.4f}",
            f"{result['Hist_Corr']:.4f}"
        ])
    
    return table

# =============================================================================
# ç°¡åŒ–çš„å¯¬æ ¼å¼è¡¨æ ¼å‡½æ•¸
# =============================================================================

def create_wide_format_tables(all_results, output_dir):
    """
    é‡æ§‹ç‰ˆçš„å¯¬æ ¼å¼è¡¨æ ¼å‰µå»ºå‡½æ•¸
    
    ä¸»è¦æ”¹é€²ï¼š
    1. æ›´æ¸…æ™°çš„é‚è¼¯çµæ§‹
    2. çµ±ä¸€çš„æ•¸æ“šè™•ç†
    3. æ›´å¥½çš„éŒ¯èª¤è™•ç†
    """
    if not all_results:
        print("No results to create wide format tables")
        return
    
    try:
        # å‰µå»ºå„ç¨®æŒ‡æ¨™çš„è¡¨æ ¼
        tables = _create_metric_tables(all_results)
        
        # ä¿å­˜è¡¨æ ¼
        _save_metric_tables(tables, output_dir)
        
        # å‰µå»ºLaTeXæ ¼å¼è¡¨æ ¼
        _save_latex_tables(tables, output_dir)
        
        print(f"Wide format tables saved to {output_dir}")
        
    except Exception as e:
        print(f"Error creating wide format tables: {str(e)}")

def _create_metric_tables(all_results):
    """å‰µå»ºå„ç¨®æŒ‡æ¨™çš„è¡¨æ ¼"""
    # ç¢ºå®šæ‰€æœ‰ç™¾åˆ†æ¯”å€¼
    percentages = []
    for df in all_results.values():
        percentages.extend(df['Target_Percentage'].tolist())
    
    percentages = sorted(list(set(percentages)))
    
    # åˆå§‹åŒ–è¡¨æ ¼
    tables = {
        'psnr': {'Percentage': percentages},
        'ssim': {'Percentage': percentages},
        'hist_corr': {'Percentage': percentages}
    }
    
    # å¡«å……å„é æ¸¬å™¨çš„æ•¸æ“š
    for predictor, df in all_results.items():
        for metric in ['psnr', 'ssim', 'hist_corr']:
            metric_col = metric.upper() if metric != 'hist_corr' else 'Hist_Corr'
            values = []
            
            for percentage in percentages:
                # æ‰¾åˆ°æœ€æ¥è¿‘çš„ç™¾åˆ†æ¯”è¡Œ
                closest_idx = (df['Target_Percentage'] - percentage).abs().idxmin()
                values.append(df.loc[closest_idx, metric_col])
            
            tables[metric][predictor] = values
    
    return tables

def _save_metric_tables(tables, output_dir):
    """ä¿å­˜æŒ‡æ¨™è¡¨æ ¼ç‚ºCSV"""
    for metric, table_data in tables.items():
        df = pd.DataFrame(table_data)
        csv_path = f"{output_dir}/wide_format_{metric}.csv"
        df.to_csv(csv_path, index=False)

def _save_latex_tables(tables, output_dir):
    """ä¿å­˜LaTeXæ ¼å¼è¡¨æ ¼"""
    format_specs = {
        'psnr': "%.2f",
        'ssim': "%.4f", 
        'hist_corr': "%.4f"
    }
    
    for metric, table_data in tables.items():
        df = pd.DataFrame(table_data)
        latex_path = f"{output_dir}/latex_table_{metric}.txt"
        
        with open(latex_path, 'w') as f:
            latex_content = df.to_latex(
                index=False, 
                float_format=format_specs[metric]
            )
            f.write(latex_content)