"""
visualization.py - è¦–è¦ºåŒ–ç›¸é—œè¼”åŠ©å‡½æ•¸æ¨¡çµ„

é€™å€‹æ¨¡çµ„æä¾›å„ç¨®è¦–è¦ºåŒ–å·¥å…·ï¼Œç”¨æ–¼ç”¢ç”Ÿå¯¦é©—çµæœçš„è¦–è¦ºåŒ–å‘ˆç¾ï¼Œ
ç‰¹åˆ¥æ˜¯é‡å°ä¸åŒçš„æ•¸æ“šéš±è—æ–¹æ³•ï¼ˆrotationã€split å’Œ quadtreeï¼‰ã€‚
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import cv2
import cupy as cp
import matplotlib.patches as patches

from matplotlib.patches import FancyBboxPatch
from color import combine_color_channels
from common import calculate_psnr, calculate_ssim, histogram_correlation
from image_processing import save_image, generate_histogram, merge_image_flexible

def visualize_split(img, split_size, block_base=False):
    """
    å‰µå»ºåˆ†å‰²ç¤ºæ„åœ–ï¼Œé¡¯ç¤ºåœ–åƒå¦‚ä½•è¢«åˆ†å‰²ç‚ºå­åœ–åƒ
    
    Parameters:
    -----------
    img : numpy.ndarray
        åŸå§‹åœ–åƒ
    split_size : int
        åˆ†å‰²å¤§å°
    block_base : bool
        æ˜¯å¦ä½¿ç”¨ block-based åˆ†å‰²
        
    Returns:
    --------
    numpy.ndarray
        åˆ†å‰²ç¤ºæ„åœ–ï¼Œå…¶ä¸­åˆ†å‰²ç·šä½¿ç”¨ç™½è‰²æˆ–å…¶ä»–é¡è‰²æ¨™ç¤º
    """
    # å‰µå»ºç¤ºæ„åœ–
    height, width = img.shape
    visualization = img.copy()
    
    # è¨ˆç®—å­å€å¡Šå¤§å°
    if block_base:
        # Block-based åˆ†å‰²
        sub_height = height // split_size
        sub_width = width // split_size
        
        # ç¹ªè£½æ°´å¹³ç·š
        for i in range(1, split_size):
            y = i * sub_height
            cv2.line(visualization, (0, y), (width, y), 255, 2)
        
        # ç¹ªè£½å‚ç›´ç·š
        for j in range(1, split_size):
            x = j * sub_width
            cv2.line(visualization, (x, 0), (x, height), 255, 2)
    else:
        # Quarter-based åˆ†å‰² (äº¤éŒ¯å¼åˆ†å‰²)
        # é€™ç¨®åˆ†å‰²æ–¹å¼è¼ƒé›£å¯è¦–åŒ–ï¼Œæˆ‘å€‘ä½¿ç”¨ä¸åŒçš„ç¬¦è™Ÿæ¨™ç¤º
        for i in range(0, height, split_size):
            for j in range(0, width, split_size):
                # ç¹ªè£½é»ä»¥æ¨™è¨˜åˆ†å‰²çš„é–‹å§‹ä½ç½®
                cv2.circle(visualization, (j, i), 3, 255, -1)
    
    return visualization

def visualize_quadtree(block_info, img_shape):
    """
    å‰µå»º quadtree åˆ†å‰²è¦–è¦ºåŒ–ï¼Œä½¿ç”¨ä¸åŒé¡è‰²æ¨™ç¤ºä¸åŒå¤§å°çš„å€å¡Šï¼ˆç„¡æ–‡å­—æ¨™è¨»ï¼‰
    
    Parameters:
    -----------
    block_info : dict
        åŒ…å«å€å¡Šè³‡è¨Šçš„å­—å…¸ï¼Œæ ¼å¼ç‚º {'size': {'blocks': [{'position': (y, x), 'size': size}, ...]}}
    img_shape : tuple
        åŸåœ–å°ºå¯¸ (height, width)
        
    Returns:
    --------
    numpy.ndarray
        Quadtree åˆ†å‰²è¦–è¦ºåŒ–åœ–åƒï¼ˆç´”è¦–è¦ºåŒ–ï¼Œç„¡æ–‡å­—ï¼‰
    """
    # å‰µå»ºç©ºç™½åœ–åƒ
    height, width = img_shape
    visualization = np.ones((height, width, 3), dtype=np.uint8) * 255  # ç™½è‰²èƒŒæ™¯
    
    # ç‚ºä¸åŒå¤§å°çš„å€å¡Šå®šç¾©ä¸åŒé¡è‰²
    colors = {
        1024: (220, 220, 220),  # æ›´æ·ºçš„ç°è‰²
        512: (200, 200, 200),   # æ·ºç°è‰²
        256: (100, 100, 200),   # æ·ºè—è‰²
        128: (100, 200, 100),   # æ·ºç¶ è‰²
        64: (200, 100, 100),    # æ·ºç´…è‰²
        32: (200, 200, 100),    # æ·ºé»ƒè‰²
        16: (200, 100, 200)     # æ·ºç´«è‰²
    }
    
    # å¾å¤§å€å¡Šåˆ°å°å€å¡Šç¹ªè£½ï¼Œä»¥ç¢ºä¿å°å€å¡Šä¸è¢«å¤§å€å¡Šè¦†è“‹
    for size_str in sorted(block_info.keys(), key=int, reverse=True):
        size = int(size_str)
        blocks = block_info[size_str]['blocks']
        color = colors.get(size, (150, 150, 150))
        
        for block in blocks:
            y, x = block['position']
            cv2.rectangle(visualization, (x, y), (x + size, y + size), color, -1)  # å¡«å……å€å¡Š
            cv2.rectangle(visualization, (x, y), (x + size, y + size), (0, 0, 0), 1)  # é»‘è‰²é‚Šæ¡†
    
    return visualization

def save_comparison_image(img1, img2, save_path, labels=None):
    """
    å°‡å…©å¼µåœ–åƒæ°´å¹³æ‹¼æ¥ä¸¦å„²å­˜ï¼Œç”¨æ–¼æ¯”è¼ƒï¼ˆç„¡æ–‡å­—æ¨™è¨»ç‰ˆæœ¬ï¼‰
    
    Parameters:
    -----------
    img1 : numpy.ndarray
        ç¬¬ä¸€å¼µåœ–åƒ
    img2 : numpy.ndarray
        ç¬¬äºŒå¼µåœ–åƒ
    save_path : str
        å„²å­˜è·¯å¾‘
    labels : tuple, optional
        åœ–åƒæ¨™ç±¤ï¼ˆå¿½ç•¥ï¼Œä¿æŒAPIå…¼å®¹æ€§ï¼‰
    """
    # ç¢ºä¿å…©å¼µåœ–åƒæœ‰ç›¸åŒé«˜åº¦
    h1, w1 = img1.shape[:2]
    h2, w2 = img2.shape[:2]
    
    if h1 != h2:
        # èª¿æ•´é«˜åº¦
        max_h = max(h1, h2)
        if h1 < max_h:
            if len(img1.shape) == 3:
                img1 = np.pad(img1, ((0, max_h - h1), (0, 0), (0, 0)), mode='constant', constant_values=0)
            else:
                img1 = np.pad(img1, ((0, max_h - h1), (0, 0)), mode='constant', constant_values=0)
        else:
            if len(img2.shape) == 3:
                img2 = np.pad(img2, ((0, max_h - h2), (0, 0), (0, 0)), mode='constant', constant_values=0)
            else:
                img2 = np.pad(img2, ((0, max_h - h2), (0, 0)), mode='constant', constant_values=0)
    
    # åœ¨ä¸­é–“åŠ å…¥åˆ†éš”ç·š
    if len(img1.shape) == 3:  # å½©è‰²åœ–åƒ
        separator = np.ones((max(h1, h2), 5, 3), dtype=np.uint8) * 128
    else:  # ç°åº¦åœ–åƒ
        separator = np.ones((max(h1, h2), 5), dtype=np.uint8) * 128
    
    # æ°´å¹³æ‹¼æ¥åœ–åƒï¼ˆç„¡æ–‡å­—æ¨™è¨»ï¼‰
    comparison = np.hstack((img1, separator, img2))
    
    # ç›´æ¥å„²å­˜ï¼Œä¸æ·»åŠ ä»»ä½•æ–‡å­—
    cv2.imwrite(save_path, comparison)

def create_block_size_distribution_chart(block_info, save_path, stage_num, channel_name=None):
    """
    å‰µå»ºå€å¡Šå¤§å°åˆ†å¸ƒçµ±è¨ˆåœ–ï¼ˆæ”¯æŒé€šé“åç¨±ï¼‰
    
    Parameters:
    -----------
    block_info : dict
        åŒ…å«å€å¡Šè³‡è¨Šçš„å­—å…¸
    save_path : str
        å„²å­˜è·¯å¾‘
    stage_num : int
        éšæ®µç·¨è™Ÿ
    channel_name : str, optional
        é€šé“åç¨±ï¼ˆå¦‚æœæ˜¯å½©è‰²åœ–åƒçš„ç‰¹å®šé€šé“ï¼‰
    """
    plt.figure(figsize=(10, 6))
    sizes = []
    counts = []
    
    for size_str in block_info:
        size = int(size_str)
        count = len(block_info[size_str]['blocks'])
        if count > 0:
            sizes.append(f"{size}x{size}")
            counts.append(count)
    
    # æŒ‰å€å¡Šå¤§å°å¾å¤§åˆ°å°æ’åº
    sorted_indices = sorted(range(len(sizes)), key=lambda i: int(sizes[i].split('x')[0]), reverse=True)
    sorted_sizes = [sizes[i] for i in sorted_indices]
    sorted_counts = [counts[i] for i in sorted_indices]
    
    plt.bar(sorted_sizes, sorted_counts, color='skyblue')
    plt.xlabel('Block Size')
    plt.ylabel('Count')
    
    # ğŸ”§ ä¿®æ”¹ï¼šæ ¹æ“šæ˜¯å¦æœ‰é€šé“åç¨±èª¿æ•´æ¨™é¡Œ
    if channel_name:
        plt.title(f'Block Size Distribution in Stage {stage_num} ({channel_name.capitalize()} Channel)')
    else:
        plt.title(f'Block Size Distribution in Stage {stage_num}')
    
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close()

def visualize_rotation_angles(angles, img_shape, save_path):
    """
    è¦–è¦ºåŒ–æ—‹è½‰è§’åº¦åˆ†å¸ƒ
    
    Parameters:
    -----------
    angles : dict
        å€å¡Šå¤§å°åˆ°æ—‹è½‰è§’åº¦çš„æ˜ å°„ï¼Œä¾‹å¦‚ {512: 90, 256: 180, ...}
    img_shape : tuple
        åŸåœ–å°ºå¯¸ (height, width)
    save_path : str
        å„²å­˜è·¯å¾‘
    """
    height, width = img_shape
    visualization = np.ones((height, width, 3), dtype=np.uint8) * 255  # ç™½è‰²èƒŒæ™¯
    
    # è§’åº¦å°æ‡‰çš„é¡è‰²
    angle_colors = {
        0: (200, 200, 200),      # ç°è‰²
        90: (100, 200, 100),     # ç¶ è‰²
        180: (100, 100, 200),    # è—è‰²
        270: (200, 100, 100),    # ç´…è‰²
        -90: (200, 200, 100),    # é»ƒè‰²
        -180: (200, 100, 200),   # ç´«è‰²
        -270: (100, 200, 200)    # é’è‰²
    }
    
    # ç¹ªè£½åœ–ä¾‹
    legend_y = 20
    for angle, color in angle_colors.items():
        cv2.putText(visualization, f"{angle}Â°", (10, legend_y), cv2.FONT_HERSHEY_SIMPLEX, 
                   0.5, color, 2)
        legend_y += 25
    
    # åœ¨åœ–åƒä¸Šæ¨™ç¤ºæ¯å€‹å€å¡Šçš„æ—‹è½‰è§’åº¦
    for size, angle in angles.items():
        color = angle_colors.get(angle, (0, 0, 0))  # å¦‚æœæ²’æœ‰å°æ‡‰é¡è‰²ï¼Œä½¿ç”¨é»‘è‰²
        cv2.putText(visualization, f"{size}px: {angle}Â°", (width//2 - 100, height//2), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 3)
    
    cv2.imwrite(save_path, visualization)

def create_metrics_comparison_chart(stages, metrics, save_path, title):
    """
    å‰µå»ºéšæ®µæŒ‡æ¨™æ¯”è¼ƒåœ–è¡¨
    
    Parameters:
    -----------
    stages : list
        éšæ®µç·¨è™Ÿåˆ—è¡¨
    metrics : dict
        æŒ‡æ¨™æ•¸æ“šï¼Œæ ¼å¼ç‚º {'psnr': [...], 'ssim': [...], ...}
    save_path : str
        å„²å­˜è·¯å¾‘
    title : str
        åœ–è¡¨æ¨™é¡Œ
    """
    plt.figure(figsize=(12, 8))
    
    for metric_name, values in metrics.items():
        if metric_name == 'psnr':
            plt.plot(stages, values, 'b.-', linewidth=2, markersize=8, label='PSNR (dB)')
        elif metric_name == 'ssim':
            plt.plot(stages, values, 'r.-', linewidth=2, markersize=8, label='SSIM')
        elif metric_name == 'hist_corr':
            plt.plot(stages, values, 'g.-', linewidth=2, markersize=8, label='Histogram Correlation')
        elif metric_name == 'bpp':
            plt.plot(stages, values, 'k.-', linewidth=2, markersize=8, label='BPP')
    
    plt.xlabel('Stage', fontsize=12)
    plt.ylabel('Metrics Value', fontsize=12)
    plt.title(title, fontsize=14)
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.legend(fontsize=10)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300)
    plt.close()

def visualize_embedding_heatmap(original_img, embedded_img, save_path):
    """
    å‰µå»ºåµŒå…¥ç†±åœ–ï¼Œé¡¯ç¤ºåœ–åƒä¸­å“ªäº›å€åŸŸæœ‰è¼ƒå¤šä¿®æ”¹
    
    Parameters:
    -----------
    original_img : numpy.ndarray
        åŸå§‹åœ–åƒ
    embedded_img : numpy.ndarray
        åµŒå…¥å¾Œçš„åœ–åƒ
    save_path : str
        å„²å­˜è·¯å¾‘
    """
    # è¨ˆç®—å·®ç•°
    if isinstance(original_img, cp.ndarray):
        original_img = cp.asnumpy(original_img)
    if isinstance(embedded_img, cp.ndarray):
        embedded_img = cp.asnumpy(embedded_img)
    
    diff = np.abs(embedded_img.astype(np.float32) - original_img.astype(np.float32))
    
    # æ­£è¦åŒ–å·®ç•°åˆ° 0-255 ç¯„åœ
    if np.max(diff) > 0:
        diff = diff / np.max(diff) * 255
    
    # æ‡‰ç”¨è‰²å½©æ˜ å°„
    diff_colored = cv2.applyColorMap(diff.astype(np.uint8), cv2.COLORMAP_JET)
    
    # å„²å­˜ç†±åœ–
    cv2.imwrite(save_path, diff_colored)
    
    # å°‡ç†±åœ–èˆ‡åŸåœ–èåˆä»¥ä¾¿æ›´å¥½åœ°è§€å¯Ÿ
    alpha = 0.7
    
    # å°‡åµŒå…¥åœ–åƒè½‰æ›ç‚º3é€šé“ï¼Œä»¥ä¾¿èˆ‡å½©è‰²å·®ç•°åœ–æ··åˆ
    embedded_img_colored = cv2.cvtColor(embedded_img.astype(np.uint8), cv2.COLOR_GRAY2BGR)
    
    blended = cv2.addWeighted(embedded_img_colored, 1-alpha, diff_colored, alpha, 0)
    
    # å„²å­˜èåˆåœ–
    blend_path = save_path.replace('.png', '_blend.png')
    cv2.imwrite(blend_path, blended)
    
    return diff, diff_colored, blended

def create_payload_distribution_chart(pee_stages, save_path):
    """
    å‰µå»ºå„éšæ®µæœ‰æ•ˆè¼‰è·åˆ†å¸ƒåœ–è¡¨
    
    Parameters:
    -----------
    pee_stages : list
        åŒ…å«æ‰€æœ‰éšæ®µè³‡è¨Šçš„åˆ—è¡¨
    save_path : str
        å„²å­˜è·¯å¾‘
    """
    plt.figure(figsize=(12, 8))
    
    stages = []
    payloads = []
    accumulated_payloads = []
    total = 0
    
    for stage in pee_stages:
        stages.append(stage['embedding'])
        payloads.append(stage['payload'])
        total += stage['payload']
        accumulated_payloads.append(total)
    
    # ç¹ªè£½éšæ®µæœ‰æ•ˆè¼‰è·
    plt.bar(stages, payloads, color='skyblue', alpha=0.7, label='Stage Payload')
    
    # ç¹ªè£½ç´¯ç©æœ‰æ•ˆè¼‰è·æ›²ç·š
    plt.plot(stages, accumulated_payloads, 'r.-', linewidth=2, markersize=8, label='Accumulated Payload')
    
    # æ·»åŠ æ•¸æ“šæ¨™ç±¤
    for i, (stage, payload, acc_payload) in enumerate(zip(stages, payloads, accumulated_payloads)):
        plt.annotate(f"{payload}", (stage, payload), textcoords="offset points", 
                    xytext=(0,10), ha='center')
        plt.annotate(f"{acc_payload}", (stage, acc_payload), textcoords="offset points", 
                    xytext=(0,10), ha='center')
    
    plt.xlabel('Stage', fontsize=12)
    plt.ylabel('Payload (bits)', fontsize=12)
    plt.title('Payload Distribution Across Stages', fontsize=14)
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.legend(fontsize=10)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300)
    plt.close()

def create_el_distribution_chart(pee_stages, save_path):
    """
    å‰µå»ºåµŒå…¥å±¤ç´š (EL) åˆ†å¸ƒåœ–è¡¨
    
    Parameters:
    -----------
    pee_stages : list
        åŒ…å«æ‰€æœ‰éšæ®µè³‡è¨Šçš„åˆ—è¡¨
    save_path : str
        å„²å­˜è·¯å¾‘
    """
    plt.figure(figsize=(12, 8))
    
    stages = []
    avg_els = []
    max_els = []
    
    for stage in pee_stages:
        stages.append(stage['embedding'])
        
        # æ”¶é›†æ‰€æœ‰å€å¡Šçš„ EL å€¼
        all_els = []
        
        if 'block_params' in stage:
            for block in stage['block_params']:
                if 'EL' in block:
                    all_els.append(block['EL'])
        
        # è¨ˆç®—å¹³å‡å’Œæœ€å¤§ EL
        if all_els:
            avg_els.append(np.mean(all_els))
            max_els.append(np.max(all_els))
        else:
            avg_els.append(0)
            max_els.append(0)
    
    # ç¹ªè£½å¹³å‡ EL
    plt.plot(stages, avg_els, 'b.-', linewidth=2, markersize=8, label='Average EL')
    
    # ç¹ªè£½æœ€å¤§ EL
    plt.plot(stages, max_els, 'r.-', linewidth=2, markersize=8, label='Maximum EL')
    
    plt.xlabel('Stage', fontsize=12)
    plt.ylabel('Embedding Level (EL)', fontsize=12)
    plt.title('Embedding Level Distribution Across Stages', fontsize=14)
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.legend(fontsize=10)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300)
    plt.close()

def create_histogram_animation(pee_stages, original_img, save_dir, imgName, method):
    """
    å‰µå»ºç›´æ–¹åœ–è®ŠåŒ–å‹•ç•«
    
    Parameters:
    -----------
    pee_stages : list
        åŒ…å«æ‰€æœ‰éšæ®µè³‡è¨Šçš„åˆ—è¡¨
    original_img : numpy.ndarray
        åŸå§‹åœ–åƒ
    save_dir : str
        å„²å­˜ç›®éŒ„
    imgName : str
        åœ–åƒåç¨±
    method : str
        ä½¿ç”¨çš„æ–¹æ³•
    """
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    animation_dir = f"{save_dir}/animation"
    os.makedirs(animation_dir, exist_ok=True)
    
    # ç²å–åŸå§‹åœ–åƒç›´æ–¹åœ–
    orig_hist = generate_histogram(original_img)
    
    # ç‚ºæ¯å€‹éšæ®µå‰µå»ºç›´æ–¹åœ–æ¯”è¼ƒ
    for i, stage in enumerate(pee_stages):
        stage_img = cp.asnumpy(stage['stage_img'])
        stage_hist = generate_histogram(stage_img)
        
        # å‰µå»ºç›´æ–¹åœ–æ¯”è¼ƒåœ–
        plt.figure(figsize=(12, 6))
        
        # åŸå§‹ç›´æ–¹åœ–
        plt.subplot(1, 2, 1)
        plt.bar(range(256), orig_hist, alpha=0.7, color='blue')
        plt.title(f"Original Histogram")
        plt.xlabel("Pixel Value")
        plt.ylabel("Frequency")
        
        # éšæ®µç›´æ–¹åœ–
        plt.subplot(1, 2, 2)
        plt.bar(range(256), stage_hist, alpha=0.7, color='red')
        plt.title(f"Stage {i} Histogram")
        plt.xlabel("Pixel Value")
        plt.ylabel("Frequency")
        
        plt.tight_layout()
        plt.savefig(f"{animation_dir}/{imgName}_{method}_histogram_stage_{i}.png")
        plt.close()
    
    # å¯ä»¥é¸æ“‡ä½¿ç”¨ ImageMagick æˆ–å…¶ä»–å·¥å…·å°‡é€™äº›åœ–åƒåˆæˆå‹•ç•«
    # é€™è£¡æä¾›å‘½ä»¤æç¤º
    print(f"åœ–åƒå·²å„²å­˜è‡³ {animation_dir}ï¼Œå¯ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å‰µå»ºå‹•ç•«ï¼š")
    print(f"convert -delay 100 {animation_dir}/{imgName}_{method}_histogram_stage_*.png {animation_dir}/{imgName}_{method}_histogram_animation.gif")
    
    # Add these functions to visualization.py

def visualize_color_histograms(img, save_path, title="Color Image Histograms"):
    """
    Create and save histograms for each channel of a color image.
    
    Parameters:
    -----------
    img : numpy.ndarray
        Input color image (BGR format)
    save_path : str
        Path to save the histogram image
    title : str, optional
        Main title for the histogram plot
    """
    
    # Split channels
    b, g, r = cv2.split(img)
    
    # Create figure with subplots
    plt.figure(figsize=(15, 5))
    
    # Blue channel histogram
    plt.subplot(1, 3, 1)
    plt.hist(b.flatten(), bins=256, range=[0,255], color='blue', alpha=0.7)
    plt.title("Blue Channel")
    plt.xlabel("Pixel Value")
    plt.ylabel("Frequency")
    
    # Green channel histogram  
    plt.subplot(1, 3, 2)
    plt.hist(g.flatten(), bins=256, range=[0,255], color='green', alpha=0.7)
    plt.title("Green Channel")
    plt.xlabel("Pixel Value")
    plt.ylabel("Frequency")
    
    # Red channel histogram
    plt.subplot(1, 3, 3)
    plt.hist(r.flatten(), bins=256, range=[0,255], color='red', alpha=0.7)
    plt.title("Red Channel")
    plt.xlabel("Pixel Value")
    plt.ylabel("Frequency")
    
    # Add main title
    plt.suptitle(title, fontsize=16)
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout for main title
    
    # Save figure
    plt.savefig(save_path)
    plt.close()

def create_color_heatmap(original_img, embedded_img, save_path, intensity_scale=1.0):
    """
    Create a heatmap showing the differences between original and embedded color images.
    
    Parameters:
    -----------
    original_img : numpy.ndarray
        Original color image
    embedded_img : numpy.ndarray
        Embedded color image
    save_path : str
        Path to save the heatmap
    intensity_scale : float, optional
        Scale factor for difference visualization (default: 1.0)
    """
    
    # Calculate absolute difference for each channel
    b_diff = np.abs(embedded_img[:,:,0].astype(np.float32) - original_img[:,:,0].astype(np.float32))
    g_diff = np.abs(embedded_img[:,:,1].astype(np.float32) - original_img[:,:,1].astype(np.float32))
    r_diff = np.abs(embedded_img[:,:,2].astype(np.float32) - original_img[:,:,2].astype(np.float32))
    
    # Enhance contrast in the visualization
    b_diff = np.clip(b_diff * intensity_scale, 0, 255)
    g_diff = np.clip(g_diff * intensity_scale, 0, 255)
    r_diff = np.clip(r_diff * intensity_scale, 0, 255)
    
    # Create a combined RGB heatmap
    heatmap = np.stack([r_diff, g_diff, b_diff], axis=2).astype(np.uint8)
    
    # Apply color map for better visualization
    combined_diff = cv2.cvtColor(heatmap, cv2.COLOR_BGR2GRAY)
    heatmap_colored = cv2.applyColorMap(combined_diff, cv2.COLORMAP_JET)
    
    # Save heatmap
    cv2.imwrite(save_path, heatmap_colored)
    
    # Create a blend of original with heatmap overlay
    alpha = 0.7
    embedded_img_colored = embedded_img.copy()
    blended = cv2.addWeighted(embedded_img_colored, 1-alpha, heatmap_colored, alpha, 0)
    
    # Save blended image
    blend_path = save_path.replace('.png', '_blend.png')
    cv2.imwrite(blend_path, blended)
    
    # Create per-channel heatmaps
    blue_heatmap = cv2.applyColorMap(b_diff.astype(np.uint8), cv2.COLORMAP_JET)
    green_heatmap = cv2.applyColorMap(g_diff.astype(np.uint8), cv2.COLORMAP_JET)
    red_heatmap = cv2.applyColorMap(r_diff.astype(np.uint8), cv2.COLORMAP_JET)
    
    # Save channel heatmaps
    cv2.imwrite(save_path.replace('.png', '_blue.png'), blue_heatmap)
    cv2.imwrite(save_path.replace('.png', '_green.png'), green_heatmap)
    cv2.imwrite(save_path.replace('.png', '_red.png'), red_heatmap)
    
    return heatmap_colored, blended

def visualize_color_metrics_comparison(pee_stages, save_path, title="Channel Metrics Comparison"):
    """
    Create visualization comparing image quality metrics across different channels.
    
    Parameters:
    -----------
    pee_stages : list
        List of stages with channel metrics
    save_path : str
        Path to save the visualization
    title : str, optional
        Title for the plot
    """
    
    # Extract data
    stages = []
    blue_psnr = []
    green_psnr = []
    red_psnr = []
    blue_ssim = []
    green_ssim = []
    red_ssim = []
    
    for i, stage in enumerate(pee_stages):
        if 'channel_metrics' in stage:
            stages.append(i)
            blue_psnr.append(stage['channel_metrics']['blue']['psnr'])
            green_psnr.append(stage['channel_metrics']['green']['psnr'])
            red_psnr.append(stage['channel_metrics']['red']['psnr'])
            blue_ssim.append(stage['channel_metrics']['blue']['ssim'])
            green_ssim.append(stage['channel_metrics']['green']['ssim'])
            red_ssim.append(stage['channel_metrics']['red']['ssim'])
    
    # Create figure with two subplots
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # Plot PSNR values
    ax1.plot(stages, blue_psnr, 'b-o', linewidth=2, label='Blue Channel')
    ax1.plot(stages, green_psnr, 'g-o', linewidth=2, label='Green Channel')
    ax1.plot(stages, red_psnr, 'r-o', linewidth=2, label='Red Channel')
    ax1.set_xlabel('Stage')
    ax1.set_ylabel('PSNR (dB)')
    ax1.set_title('PSNR Comparison by Channel')
    ax1.grid(True, linestyle='--', alpha=0.7)
    ax1.legend()
    
    # Plot SSIM values
    ax2.plot(stages, blue_ssim, 'b-o', linewidth=2, label='Blue Channel')
    ax2.plot(stages, green_ssim, 'g-o', linewidth=2, label='Green Channel')
    ax2.plot(stages, red_ssim, 'r-o', linewidth=2, label='Red Channel')
    ax2.set_xlabel('Stage')
    ax2.set_ylabel('SSIM')
    ax2.set_title('SSIM Comparison by Channel')
    ax2.grid(True, linestyle='--', alpha=0.7)
    ax2.legend()
    
    # Add main title
    plt.suptitle(title, fontsize=16)
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout for main title
    
    # Save figure
    plt.savefig(save_path)
    plt.close()

def create_color_channel_comparison(original_img, embedded_img, save_path):
    """
    å‰µå»ºå½©è‰²é€šé“å°æ¯”çš„è¦–è¦ºåŒ–ï¼ˆç„¡æ–‡å­—æ¨™è¨»ç‰ˆæœ¬ï¼‰
    
    Parameters:
    -----------
    original_img : numpy.ndarray
        åŸå§‹å½©è‰²åœ–åƒ
    embedded_img : numpy.ndarray
        åµŒå…¥å¾Œçš„å½©è‰²åœ–åƒ
    save_path : str
        ä¿å­˜è·¯å¾‘
    """
    import numpy as np
    import cv2
    
    # Split channels
    b1, g1, r1 = cv2.split(original_img)
    b2, g2, r2 = cv2.split(embedded_img)
    
    # Create blank canvas for the comparison
    h, w = original_img.shape[:2]
    comparison = np.ones((h*3, w*2 + 10, 3), dtype=np.uint8) * 255  # White background
    
    # Place images in grid (ç„¡æ–‡å­—æ¨™è¨»ï¼Œç´”åœ–åƒå°æ¯”)
    # Blue channel row
    comparison[:h, :w, 0] = b1
    comparison[:h, :w, 1:] = 0
    comparison[:h, w+10:w*2+10, 0] = b2
    comparison[:h, w+10:w*2+10, 1:] = 0
    
    # Green channel row
    comparison[h:h*2, :w, 1] = g1
    comparison[h:h*2, :w, 0] = 0
    comparison[h:h*2, :w, 2] = 0
    comparison[h:h*2, w+10:w*2+10, 1] = g2
    comparison[h:h*2, w+10:w*2+10, 0] = 0
    comparison[h:h*2, w+10:w*2+10, 2] = 0
    
    # Red channel row
    comparison[h*2:h*3, :w, 2] = r1
    comparison[h*2:h*3, :w, :2] = 0
    comparison[h*2:h*3, w+10:w*2+10, 2] = r2
    comparison[h*2:h*3, w+10:w*2+10, :2] = 0
    
    # ç›´æ¥ä¿å­˜ï¼Œä¸æ·»åŠ ä»»ä½•æ–‡å­—æ¨™ç±¤
    cv2.imwrite(save_path, comparison)
    
    return comparison

def visualize_specific_quadtree_blocks(block_info, original_img, specific_size, save_path):
    """
    å‰µå»ºåƒ…é¡¯ç¤ºç‰¹å®šå¤§å°å€å¡Šçš„quadtreeè¦–è¦ºåŒ–ï¼Œä¿ç•™åŸåœ–ä¸­ç‰¹å®šå¤§å°å€å¡Šçš„å…§å®¹ï¼Œå…¶ä»–å€å¡Šè½‰ç‚ºé»‘è‰²
    
    Parameters:
    -----------
    block_info : dict
        åŒ…å«å€å¡Šè³‡è¨Šçš„å­—å…¸ï¼Œæ ¼å¼ç‚º {'size': {'blocks': [{'position': (y, x), 'size': size}, ...]}}
    original_img : numpy.ndarray
        åŸå§‹åœ–åƒ
    specific_size : int
        è¦ç‰¹åˆ¥é¡¯ç¤ºçš„å€å¡Šå¤§å°ï¼ˆä¾‹å¦‚ 16, 32, 64, 128, 256, 512ï¼‰
    save_path : str
        å„²å­˜è·¯å¾‘
        
    Returns:
    --------
    numpy.ndarray
        ç‰¹å®šå€å¡Šå¤§å°è¦–è¦ºåŒ–åœ–åƒ
    """
    # å‰µå»ºç©ºç™½åœ–åƒ (é»‘è‰²èƒŒæ™¯)
    height, width = original_img.shape[:2]
    
    # åˆ¤æ–·æ˜¯å¦ç‚ºå½©è‰²åœ–åƒ
    is_color = len(original_img.shape) == 3
    
    # å‰µå»ºé©ç•¶çš„é»‘è‰²èƒŒæ™¯åœ–åƒ
    if is_color:
        visualization = np.zeros((height, width, 3), dtype=np.uint8)  # é»‘è‰²èƒŒæ™¯
    else:
        visualization = np.zeros((height, width), dtype=np.uint8)  # é»‘è‰²èƒŒæ™¯
    
    # æª¢æŸ¥æ˜¯å¦æœ‰æŒ‡å®šå¤§å°çš„å€å¡Š
    size_str = str(specific_size)
    blocks_count = 0
    
    if size_str in block_info:
        blocks = block_info[size_str]['blocks']
        blocks_count = len(blocks)
        
        # ç¹ªè£½ç‰¹å®šå¤§å°çš„å€å¡Šï¼Œä¿ç•™åŸåœ–å…§å®¹
        for block in blocks:
            y, x = block['position']
            
            # è¤‡è£½åŸåœ–é€™å€‹å€å¡Šçš„å…§å®¹
            visualization[y:y+specific_size, x:x+specific_size] = original_img[y:y+specific_size, x:x+specific_size]
            
            # æ·»åŠ é‚Šæ¡† (æ ¼ç·š)
            border_width = max(1, specific_size // 64)  # æ ¹æ“šå€å¡Šå¤§å°èª¿æ•´é‚Šæ¡†å¯¬åº¦
            
            # ç¹ªè£½é‚Šæ¡†
            if is_color:
                # å½©è‰²åœ–åƒ
                # ä¸Šé‚Šæ¡†
                visualization[y:y+border_width, x:x+specific_size] = [255, 255, 0]  # é»ƒè‰²é‚Šæ¡†
                # ä¸‹é‚Šæ¡†
                visualization[y+specific_size-border_width:y+specific_size, x:x+specific_size] = [255, 255, 0]
                # å·¦é‚Šæ¡†
                visualization[y:y+specific_size, x:x+border_width] = [255, 255, 0]
                # å³é‚Šæ¡†
                visualization[y:y+specific_size, x+specific_size-border_width:x+specific_size] = [255, 255, 0]
            else:
                # ç°éšåœ–åƒ
                # ä¸Šé‚Šæ¡†
                visualization[y:y+border_width, x:x+specific_size] = 255
                # ä¸‹é‚Šæ¡†
                visualization[y+specific_size-border_width:y+specific_size, x:x+specific_size] = 255
                # å·¦é‚Šæ¡†
                visualization[y:y+specific_size, x:x+border_width] = 255
                # å³é‚Šæ¡†
                visualization[y:y+specific_size, x+specific_size-border_width:x+specific_size] = 255
    
    # Directly save the visualization without adding text
    cv2.imwrite(save_path, visualization)
    
    # Return the visualization
    return visualization

def create_all_quadtree_block_visualizations(block_info, original_img, output_dir, stage_num):
    """
    ç‚ºæ‰€æœ‰å€å¡Šå¤§å°å‰µå»ºå–®ç¨çš„è¦–è¦ºåŒ–åœ–åƒï¼Œä¿ç•™åŸåœ–ä¸­ç‰¹å®šå¤§å°å€å¡Šçš„å…§å®¹
    
    Parameters:
    -----------
    block_info : dict
        åŒ…å«å€å¡Šè³‡è¨Šçš„å­—å…¸
    original_img : numpy.ndarray
        åŸå§‹åœ–åƒ
    output_dir : str
        è¼¸å‡ºç›®éŒ„
    stage_num : int
        éšæ®µç·¨è™Ÿ
    
    Returns:
    --------
    dict
        å„å€å¡Šå¤§å°åœ–åƒçš„è·¯å¾‘å­—å…¸
    """
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # æ¨™æº–å€å¡Šå¤§å°åˆ—è¡¨
    block_sizes = [16, 32, 64, 128, 256, 512, 1024]
    
    # å„²å­˜å„åœ–åƒè·¯å¾‘
    visualization_paths = {}
    
    # ç‚ºæ¯å€‹å‡ºç¾çš„å€å¡Šå¤§å°å‰µå»ºè¦–è¦ºåŒ–
    for size in block_sizes:
        size_str = str(size)
        if size_str in block_info and len(block_info[size_str]['blocks']) > 0:
            save_path = f"{output_dir}/stage_{stage_num}_blocks_{size}x{size}.png"
            visualize_specific_quadtree_blocks(block_info, original_img, size, save_path)
            visualization_paths[size] = save_path
    
    # é¡å¤–å‰µå»ºä¸€å€‹æ‰€æœ‰å€å¡Šçš„åˆä½µè¦–è¦ºåŒ–
    combined_path = f"{output_dir}/stage_{stage_num}_all_blocks.png"
    all_blocks_vis = visualize_quadtree(block_info, original_img.shape[:2])  # åªéœ€è¦å½¢ç‹€
    cv2.imwrite(combined_path, all_blocks_vis)
    visualization_paths['all'] = combined_path
    
    return visualization_paths

def create_all_quadtree_block_visualizations_color(block_info, original_img, output_dir, stage_num, channel_name=None):
    """
    ç‚ºå½©è‰²åœ–åƒçš„æ‰€æœ‰å€å¡Šå¤§å°å‰µå»ºå–®ç¨çš„è¦–è¦ºåŒ–åœ–åƒ
    
    Parameters:
    -----------
    block_info : dict
        åŒ…å«å€å¡Šè³‡è¨Šçš„å­—å…¸
    original_img : numpy.ndarray
        åŸå§‹åœ–åƒï¼ˆå½©è‰²æˆ–å°æ‡‰é€šé“çš„ç°åº¦åœ–åƒï¼‰
    output_dir : str
        è¼¸å‡ºç›®éŒ„
    stage_num : int
        éšæ®µç·¨è™Ÿ
    channel_name : str, optional
        é€šé“åç¨±ï¼ˆ'red', 'green', 'blue' æˆ– Noneï¼‰
    
    Returns:
    --------
    dict
        å„å€å¡Šå¤§å°åœ–åƒçš„è·¯å¾‘å­—å…¸
    """
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # æ¨™æº–å€å¡Šå¤§å°åˆ—è¡¨
    block_sizes = [16, 32, 64, 128, 256, 512, 1024]
    
    # å„²å­˜å„åœ–åƒè·¯å¾‘
    visualization_paths = {}
    
    # ç‚ºæ¯å€‹å‡ºç¾çš„å€å¡Šå¤§å°å‰µå»ºè¦–è¦ºåŒ–
    for size in block_sizes:
        size_str = str(size)
        if size_str in block_info and len(block_info[size_str]['blocks']) > 0:
            if channel_name:
                save_path = f"{output_dir}/stage_{stage_num}_{channel_name}_blocks_{size}x{size}.png"
            else:
                save_path = f"{output_dir}/stage_{stage_num}_blocks_{size}x{size}.png"
            
            visualize_specific_quadtree_blocks_color(block_info, original_img, size, save_path, channel_name)
            visualization_paths[size] = save_path
    
    # é¡å¤–å‰µå»ºä¸€å€‹æ‰€æœ‰å€å¡Šçš„åˆä½µè¦–è¦ºåŒ–
    if channel_name:
        combined_path = f"{output_dir}/stage_{stage_num}_{channel_name}_all_blocks.png"
    else:
        combined_path = f"{output_dir}/stage_{stage_num}_all_blocks.png"
    
    all_blocks_vis = visualize_quadtree(block_info, original_img.shape[:2])
    cv2.imwrite(combined_path, all_blocks_vis)
    visualization_paths['all'] = combined_path
    
    return visualization_paths

def create_difference_histograms(original_img, pred_img, embedded_img, save_dir, method_name, stage_num, local_el=None):
    """
    å‰µå»ºä¸‰ç¨®å·®ç•°ç›´æ–¹åœ–è¦–è¦ºåŒ–ï¼š
    1. åµŒå…¥å‰çš„é æ¸¬èª¤å·®ç›´æ–¹åœ–
    2. ç§»ä½å¾Œçš„é æ¸¬èª¤å·®ç›´æ–¹åœ– (æ¨¡æ“¬ç›´æ–¹åœ–ç§»ä½éç¨‹)
    3. åµŒå…¥å¾Œçš„é æ¸¬èª¤å·®ç›´æ–¹åœ–
    
    Parameters:
    -----------
    original_img : numpy.ndarray
        åŸå§‹åœ–åƒ
    pred_img : numpy.ndarray
        é æ¸¬åœ–åƒ
    embedded_img : numpy.ndarray
        åµŒå…¥å¾Œçš„åœ–åƒ
    save_dir : str
        å„²å­˜ç›®éŒ„
    method_name : str
        ä½¿ç”¨çš„æ–¹æ³•åç¨± (rotation, split, quadtree)
    stage_num : int or str
        éšæ®µç·¨è™Ÿ
    local_el : int or numpy.ndarray, optional
        ELå€¼ (ç”¨æ–¼ç›´æ–¹åœ–ç§»ä½æ¨¡æ“¬)ï¼Œå¯ä»¥æ˜¯å–®ä¸€å€¼æˆ–åƒç´ ä½ç½®çš„ELé™£åˆ—
        
    Returns:
    --------
    tuple
        (before_path, shifted_path, after_path, comparison_path) å››å€‹ç›´æ–¹åœ–åœ–åƒçš„è·¯å¾‘
    """
    # ç¢ºä¿è¼¸å…¥æ˜¯ numpy æ•¸çµ„
    if not isinstance(original_img, np.ndarray):
        original_img = np.array(original_img)
    if not isinstance(pred_img, np.ndarray):
        pred_img = np.array(pred_img)
    if not isinstance(embedded_img, np.ndarray):
        embedded_img = np.array(embedded_img)
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    hist_dir = os.path.join(save_dir, "difference_histograms")
    os.makedirs(hist_dir, exist_ok=True)
    
    # è¨ˆç®—é æ¸¬èª¤å·® (before embedding)
    pred_error = original_img.astype(np.int16) - pred_img.astype(np.int16)
    
    # è¨ˆç®—åµŒå…¥å¾Œçš„èª¤å·® (after embedding)
    embedded_error = embedded_img.astype(np.int16) - pred_img.astype(np.int16)
    
    # æ”¹é€²çš„ç›´æ–¹åœ–ç§»ä½æ¨¡æ“¬ - æ ¹æ“šå¯¦éš›ELå€¼
    shifted_error = pred_error.copy()
    
    # æ±ºå®šä½¿ç”¨çš„æœ€å¤§ELå€¼
    if local_el is None:
        # å¦‚æœæ²’æœ‰æä¾›ELå€¼ï¼Œä½¿ç”¨é è¨­å€¼5
        max_el = 5
    elif isinstance(local_el, np.ndarray):
        # å¦‚æœæ˜¯é™£åˆ—ï¼Œä½¿ç”¨å¹³å‡å€¼
        max_el = int(np.mean(local_el))
    else:
        # ä½¿ç”¨æä¾›çš„å–®ä¸€å€¼
        max_el = int(local_el)
    
    # è¨˜éŒ„ä½¿ç”¨çš„ELå€¼ï¼ˆç”¨æ–¼æ¨™é¡Œï¼‰
    el_text = f"EL={max_el}"
    
    # åŸ·è¡Œæ›´ç²¾ç¢ºçš„ç›´æ–¹åœ–ç§»ä½æ¨¡æ“¬
    # æ­£å€¼èª¤å·®éƒ¨åˆ†: æ ¹æ“šELç¯„åœç§»ä½
    for i in range(max_el):
        # å°‡å·®å€¼ç‚ºiçš„åƒç´ å‘å³ç§»å‹•è‡³i+1
        shifted_error[pred_error == i] = i + 1
    
    # è² å€¼èª¤å·®éƒ¨åˆ†: é¡ä¼¼è™•ç†ï¼Œä½†å¯é¸
    # æ³¨æ„ï¼šæ ¹æ“šå¯¦éš›ç®—æ³•ï¼Œæ˜¯å¦ç§»å‹•è² å€¼èª¤å·®è¦çœ‹å…·é«”å¯¦ç¾
    # é€™è£¡æä¾›ä¸€å€‹é¸é …ï¼Œé è¨­ä¸ç§»å‹•
    shift_negative = False
    if shift_negative:
        for i in range(1, max_el+1):
            shifted_error[pred_error == -i] = -(i + 1)
    
    # è¨­å®šç›´æ–¹åœ–ç¯„åœï¼Œä»¥ç¢ºä¿ä¸‰å€‹ç›´æ–¹åœ–ä½¿ç”¨ç›¸åŒçš„xè»¸
    error_min = min(pred_error.min(), shifted_error.min(), embedded_error.min())
    error_max = max(pred_error.max(), shifted_error.max(), embedded_error.max())
    
    # ç‚ºäº†æ›´å¥½çš„è¦–è¦ºæ•ˆæœï¼Œå°‡ç¯„åœé™åˆ¶åœ¨åˆç†å€é–“å…§
    hist_range = (max(-50, error_min), min(50, error_max))
    bins = hist_range[1] - hist_range[0] + 1
    
    # å‰µå»º "Before Embedding" ç›´æ–¹åœ–
    plt.figure(figsize=(10, 6))
    plt.hist(pred_error.flatten(), bins=bins, range=hist_range, 
             alpha=0.7, color='blue', density=True)
    plt.axvline(x=0, color='red', linestyle='--', alpha=0.7)
    plt.title(f"Prediction Error Histogram Before Embedding\nMethod: {method_name.capitalize()}, Stage: {stage_num}")
    plt.xlabel("Prediction Error Value")
    plt.ylabel("Normalized Frequency")
    plt.grid(True, linestyle='--', alpha=0.5)
    before_path = os.path.join(hist_dir, f"{method_name}_stage{stage_num}_error_before.png")
    plt.savefig(before_path)
    plt.close()
    
    # å‰µå»º "Shifted" ç›´æ–¹åœ–
    plt.figure(figsize=(10, 6))
    plt.hist(shifted_error.flatten(), bins=bins, range=hist_range, 
             alpha=0.7, color='green', density=True)
    plt.axvline(x=0, color='red', linestyle='--', alpha=0.7)
    plt.title(f"Prediction Error Histogram After Shifting\nMethod: {method_name.capitalize()}, Stage: {stage_num}, {el_text}")
    plt.xlabel("Prediction Error Value")
    plt.ylabel("Normalized Frequency")
    plt.grid(True, linestyle='--', alpha=0.5)
    shifted_path = os.path.join(hist_dir, f"{method_name}_stage{stage_num}_error_shifted.png")
    plt.savefig(shifted_path)
    plt.close()
    
    # å‰µå»º "After Embedding" ç›´æ–¹åœ–
    plt.figure(figsize=(10, 6))
    plt.hist(embedded_error.flatten(), bins=bins, range=hist_range, 
             alpha=0.7, color='purple', density=True)
    plt.axvline(x=0, color='red', linestyle='--', alpha=0.7)
    plt.title(f"Prediction Error Histogram After Embedding\nMethod: {method_name.capitalize()}, Stage: {stage_num}")
    plt.xlabel("Prediction Error Value")
    plt.ylabel("Normalized Frequency")
    plt.grid(True, linestyle='--', alpha=0.5)
    after_path = os.path.join(hist_dir, f"{method_name}_stage{stage_num}_error_after.png")
    plt.savefig(after_path)
    plt.close()
    
    # å‰µå»ºä¸‰å€‹ç›´æ–¹åœ–çš„å°æ¯”åœ–
    plt.figure(figsize=(15, 8))
    plt.hist(pred_error.flatten(), bins=bins, range=hist_range, 
             alpha=0.5, color='blue', density=True, label="Before Embedding")
    plt.hist(shifted_error.flatten(), bins=bins, range=hist_range, 
             alpha=0.5, color='green', density=True, label="After Shifting")
    plt.hist(embedded_error.flatten(), bins=bins, range=hist_range, 
             alpha=0.5, color='purple', density=True, label="After Embedding")
    plt.axvline(x=0, color='red', linestyle='--', alpha=0.7)
    plt.title(f"Prediction Error Histogram Comparison\nMethod: {method_name.capitalize()}, Stage: {stage_num}, {el_text}")
    plt.xlabel("Prediction Error Value")
    plt.ylabel("Normalized Frequency")
    plt.grid(True, linestyle='--', alpha=0.5)
    plt.legend()
    comparison_path = os.path.join(hist_dir, f"{method_name}_stage{stage_num}_error_comparison.png")
    plt.savefig(comparison_path)
    plt.close()
    
    # è¿”å›å››å€‹åœ–åƒçš„è·¯å¾‘ï¼Œæ–¹ä¾¿å¾ŒçºŒä½¿ç”¨
    return before_path, shifted_path, after_path, comparison_path

def create_rotation_method_flowchart(original_img, imgName, method, prediction_method, output_dir):
    """
    å‰µå»ºæ—‹è½‰æ–¹æ³•çš„å®Œæ•´æµç¨‹ç¤ºæ„åœ–
    
    Parameters:
    -----------
    original_img : numpy.ndarray
        åŸå§‹å½±åƒ
    imgName : str
        å½±åƒåç¨±
    method : str
        æ–¹æ³•åç¨± ("rotation")
    prediction_method : str
        é æ¸¬æ–¹æ³•åç¨±
    output_dir : str
        è¼¸å‡ºç›®éŒ„
    """
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    method_dir = f"{output_dir}/image/{imgName}/{method}"
    os.makedirs(method_dir, exist_ok=True)
    
    # è¨­å®šåœ–åƒåƒæ•¸
    fig = plt.figure(figsize=(16, 12))
    fig.suptitle('Multi-Round Rotation Embedding Process Flow', fontsize=16, fontweight='bold')
    
    # å‰µå»ºç¶²æ ¼å¸ƒå±€
    gs = fig.add_gridspec(3, 5, hspace=0.3, wspace=0.2)
    
    # åŸå§‹å½±åƒ
    ax_orig = fig.add_subplot(gs[0, 0])
    ax_orig.imshow(original_img, cmap='gray')
    ax_orig.set_title('Original Image\n$I_0$', fontsize=12, fontweight='bold')
    ax_orig.axis('off')
    
    # å››å€‹æ—‹è½‰éšæ®µ
    rotation_angles = [90, 180, 270, 360]
    stage_positions = [(0, 1), (0, 2), (0, 3), (0, 4)]
    
    for i, (angle, pos) in enumerate(zip(rotation_angles, stage_positions)):
        # æ—‹è½‰å¾Œçš„å½±åƒ
        ax_rot = fig.add_subplot(gs[pos[0], pos[1]])
        
        # å¯¦éš›æ—‹è½‰å½±åƒ
        if angle == 360:
            rotated_img = original_img
            angle_display = 0
        else:
            rotated_img = np.rot90(original_img, k=angle//90)
            angle_display = angle
        
        ax_rot.imshow(rotated_img, cmap='gray')
        ax_rot.set_title(f'Stage {i+1}\nRotate {angle_display}Â°\n$I_{i+1}^{{rot}}$', 
                        fontsize=10, fontweight='bold')
        ax_rot.axis('off')
    
    # PEEéç¨‹è¦–è¦ºåŒ–
    pee_row = 1
    for i in range(4):
        ax_pee = fig.add_subplot(gs[pee_row, i+1])
        ax_pee.set_xlim(0, 10)
        ax_pee.set_ylim(0, 10)
        
        # é æ¸¬æ–¹å¡Š
        pred_box = FancyBboxPatch((1, 7), 8, 2, boxstyle="round,pad=0.1", 
                                 facecolor='lightblue', edgecolor='blue')
        ax_pee.add_patch(pred_box)
        ax_pee.text(5, 8, 'Weighted\nPrediction', ha='center', va='center', fontsize=9)
        
        # åµŒå…¥æ–¹å¡Š
        embed_box = FancyBboxPatch((1, 4), 8, 2, boxstyle="round,pad=0.1", 
                                  facecolor='lightgreen', edgecolor='green')
        ax_pee.add_patch(embed_box)
        ax_pee.text(5, 5, f'Data Embedding\n$D_{i+1}$', ha='center', va='center', fontsize=9)
        
        # ELæ§åˆ¶æ–¹å¡Š
        el_box = FancyBboxPatch((1, 1), 8, 2, boxstyle="round,pad=0.1", 
                               facecolor='lightyellow', edgecolor='orange')
        ax_pee.add_patch(el_box)
        ax_pee.text(5, 2, f'Adaptive EL\n$EL_{i+1}$', ha='center', va='center', fontsize=9)
        
        # æ·»åŠ ç®­é ­
        ax_pee.annotate('', xy=(5, 6.8), xytext=(5, 7.2),
                       arrowprops=dict(arrowstyle='->', lw=1.5, color='black'))
        ax_pee.annotate('', xy=(5, 3.8), xytext=(5, 4.2),
                       arrowprops=dict(arrowstyle='->', lw=1.5, color='black'))
        
        ax_pee.set_title(f'PEE Process\nStage {i+1}', fontsize=10, fontweight='bold')
        ax_pee.axis('off')
    
    # æœ€çµ‚çµæœï¼ˆæ¨¡æ“¬åµŒå…¥æ•ˆæœï¼‰
    final_row = 2
    for i in range(4):
        ax_final = fig.add_subplot(gs[final_row, i+1])
        
        # ç°¡å–®æ¨¡æ“¬åµŒå…¥å¾Œçš„å½±åƒ
        if rotation_angles[i] == 360:
            final_img = original_img
        else:
            final_img = np.rot90(original_img, k=-(rotation_angles[i]//90))
        
        ax_final.imshow(final_img, cmap='gray')
        ax_final.set_title(f'Embedded Result\n$I_{i+1}$', fontsize=10, fontweight='bold')
        ax_final.axis('off')
    
    # æ·»åŠ æµç¨‹ç®­é ­å’Œèªªæ˜æ–‡å­—
    for i in range(4):
        fig.text(0.35 + i*0.16, 0.67, 'â†“', fontsize=20, ha='center', color='blue')
        fig.text(0.35 + i*0.16, 0.64, 'PEE', fontsize=8, ha='center', color='blue')
        
        fig.text(0.35 + i*0.16, 0.37, 'â†“', fontsize=20, ha='center', color='green')
        angle_back = rotation_angles[i] if rotation_angles[i] != 360 else 0
        fig.text(0.35 + i*0.16, 0.34, f'Rotate\n-{angle_back}Â°', 
                fontsize=8, ha='center', color='green')
    
    # åœ–ä¾‹
    legend_elements = [
        patches.Patch(color='lightblue', label='Prediction Process'),
        patches.Patch(color='lightgreen', label='Data Embedding'),
        patches.Patch(color='lightyellow', label='Embedding Level Control'),
    ]
    fig.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(0.98, 0.95))
    
    plt.tight_layout()
    save_path = f"{method_dir}/rotation_embedding_flowchart_{prediction_method}.png"
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    return save_path

def create_rotation_prediction_error_analysis(original_img, imgName, method, prediction_method, output_dir):
    """
    å‰µå»ºæ—‹è½‰æ–¹æ³•çš„é æ¸¬èª¤å·®åˆ†æåœ–
    
    Parameters:
    -----------
    original_img : numpy.ndarray
        åŸå§‹å½±åƒ
    imgName : str
        å½±åƒåç¨±
    method : str
        æ–¹æ³•åç¨±
    prediction_method : str
        é æ¸¬æ–¹æ³•åç¨±
    output_dir : str
        è¼¸å‡ºç›®éŒ„
    """
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    method_dir = f"{output_dir}/image/{imgName}/{method}"
    os.makedirs(method_dir, exist_ok=True)
    
    fig, axes = plt.subplots(2, 4, figsize=(16, 8))
    fig.suptitle('Prediction Error Distribution Across Rotation Stages', fontsize=16, fontweight='bold')
    
    rotation_angles = [0, 90, 180, 270]
    
    # æ¨¡æ“¬ä¸åŒéšæ®µçš„æœ€ä½³åŒ–æ¬Šé‡
    stage_weights = {
        0: [0.3, 0.3, 0.2, 0.2],    # åˆå§‹æ¬Šé‡
        90: [0.25, 0.35, 0.25, 0.15], # 90åº¦æœ€ä½³åŒ–å¾Œ
        180: [0.4, 0.25, 0.2, 0.15],  # 180åº¦æœ€ä½³åŒ–å¾Œ
        270: [0.2, 0.4, 0.3, 0.1]     # 270åº¦æœ€ä½³åŒ–å¾Œ
    }
    
    for i, angle in enumerate(rotation_angles):
        # æ—‹è½‰å½±åƒ
        if angle == 0:
            rotated_img = original_img.astype(np.float32)
        else:
            rotated_img = np.rot90(original_img, k=angle//90).astype(np.float32)
        
        # ä½¿ç”¨å°æ‡‰çš„æœ€ä½³åŒ–æ¬Šé‡
        weights = stage_weights[angle]
        
        # è¨ˆç®—é æ¸¬èª¤å·®
        pred_error = compute_prediction_error(rotated_img, weights)
        
        # é¡¯ç¤ºæ—‹è½‰å¾Œçš„å½±åƒ
        axes[0, i].imshow(rotated_img, cmap='gray')
        axes[0, i].set_title(f'Stage {i+1}: Rotated {angle}Â°', fontsize=12, fontweight='bold')
        axes[0, i].axis('off')
        
        # é¡¯ç¤ºé æ¸¬èª¤å·®ç†±åœ–
        im = axes[1, i].imshow(pred_error, cmap='RdBu_r', vmin=-15, vmax=15)
        axes[1, i].set_title(f'Prediction Error\nWeights: {weights}', fontsize=10)
        axes[1, i].axis('off')
        
        # è¨ˆç®—å¯åµŒå…¥åƒç´ çµ±è¨ˆ
        embedable_pixels = np.sum(np.abs(pred_error) <= 5)  # å‡è¨­EL=5
        total_pixels = pred_error.size
        embed_ratio = embedable_pixels / total_pixels * 100
        
        axes[1, i].text(0.02, 0.98, f'Embeddable: {embed_ratio:.1f}%', 
                       transform=axes[1, i].transAxes, 
                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),
                       fontsize=9, verticalalignment='top')
    
    # æ·»åŠ é¡è‰²æ¢
    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.3])
    cbar = fig.colorbar(im, cax=cbar_ax)
    cbar.set_label('Prediction Error', rotation=270, labelpad=15)
    
    plt.tight_layout()
    plt.subplots_adjust(right=0.9)
    save_path = f"{method_dir}/rotation_prediction_error_{prediction_method}.png"
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    return save_path

def compute_prediction_error(img, weights):
    """
    è¨ˆç®—é æ¸¬èª¤å·®çš„è¼”åŠ©å‡½æ•¸
    """
    pred_img = np.zeros_like(img)
    h, w = img.shape
    
    for y in range(1, h-1):
        for x in range(1, w-1):
            up = img[y-1, x]
            left = img[y, x-1]
            up_left = img[y-1, x-1]
            up_right = img[y-1, x+1] if x+1 < w else img[y-1, x-1]
            
            pred_img[y, x] = (weights[0]*up + weights[1]*left + 
                            weights[2]*up_left + weights[3]*up_right)
    
    return img - pred_img

def create_rotation_method_flowchart_color(original_img, imgName, method, prediction_method, output_dir):
    """
    å‰µå»ºå½©è‰²åœ–åƒæ—‹è½‰æ–¹æ³•çš„å®Œæ•´æµç¨‹ç¤ºæ„åœ–
    """
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    method_dir = f"{output_dir}/image/{imgName}/{method}"
    os.makedirs(method_dir, exist_ok=True)
    
    # è½‰æ›BGRåˆ°RGBä»¥ä¾¿matplotlibé¡¯ç¤º
    original_img_rgb = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)
    
    # è¨­å®šåœ–åƒåƒæ•¸
    fig = plt.figure(figsize=(16, 14))
    fig.suptitle('Multi-Round Rotation Embedding Process Flow (Color Image)', fontsize=16, fontweight='bold')
    
    # å‰µå»ºç¶²æ ¼å¸ƒå±€ï¼Œç‚ºå½©è‰²åœ–åƒå¢åŠ æ›´å¤šç©ºé–“
    gs = fig.add_gridspec(4, 5, hspace=0.4, wspace=0.2)
    
    # åŸå§‹å½±åƒ
    ax_orig = fig.add_subplot(gs[0, 0])
    ax_orig.imshow(original_img_rgb)
    ax_orig.set_title('Original Color Image\n$I_0$', fontsize=12, fontweight='bold')
    ax_orig.axis('off')
    
    # å››å€‹æ—‹è½‰éšæ®µ
    rotation_angles = [90, 180, 270, 360]
    stage_positions = [(0, 1), (0, 2), (0, 3), (0, 4)]
    
    for i, (angle, pos) in enumerate(zip(rotation_angles, stage_positions)):
        # æ—‹è½‰å¾Œçš„å½±åƒ
        ax_rot = fig.add_subplot(gs[pos[0], pos[1]])
        
        # å¯¦éš›æ—‹è½‰å½±åƒ
        if angle == 360:
            rotated_img_rgb = original_img_rgb
            angle_display = 0
        else:
            rotated_img_rgb = np.rot90(original_img_rgb, k=angle//90)
            angle_display = angle
        
        ax_rot.imshow(rotated_img_rgb)
        ax_rot.set_title(f'Stage {i+1}\nRotate {angle_display}Â°\n$I_{i+1}^{{rot}}$', 
                        fontsize=10, fontweight='bold')
        ax_rot.axis('off')
    
    # é€šé“åˆ†é›¢è™•ç†ç¤ºæ„åœ–
    channel_row = 1
    channel_names = ['Blue', 'Green', 'Red']
    channel_colors = ['blue', 'green', 'red']
    
    for i in range(4):
        ax_channels = fig.add_subplot(gs[channel_row, i+1])
        ax_channels.set_xlim(0, 10)
        ax_channels.set_ylim(0, 12)
        
        # é€šé“åˆ†é›¢æ–¹å¡Š
        for j, (ch_name, ch_color) in enumerate(zip(channel_names, channel_colors)):
            ch_box = FancyBboxPatch((0.5, 9-j*3), 9, 2, boxstyle="round,pad=0.1", 
                                   facecolor=ch_color, alpha=0.3, edgecolor=ch_color)
            ax_channels.add_patch(ch_box)
            ax_channels.text(5, 10-j*3, f'{ch_name} Channel\nPEE Processing', 
                           ha='center', va='center', fontsize=8, fontweight='bold')
        
        ax_channels.set_title(f'Channel Processing\nStage {i+1}', fontsize=10, fontweight='bold')
        ax_channels.axis('off')
    
    # PEEéç¨‹è©³ç´°å±•ç¤º
    pee_row = 2
    for i in range(4):
        ax_pee = fig.add_subplot(gs[pee_row, i+1])
        ax_pee.set_xlim(0, 10)
        ax_pee.set_ylim(0, 10)
        
        # é æ¸¬æ–¹å¡Š
        pred_box = FancyBboxPatch((1, 7), 8, 2, boxstyle="round,pad=0.1", 
                                 facecolor='lightblue', edgecolor='blue')
        ax_pee.add_patch(pred_box)
        ax_pee.text(5, 8, 'Weighted\nPrediction', ha='center', va='center', fontsize=9)
        
        # åµŒå…¥æ–¹å¡Š
        embed_box = FancyBboxPatch((1, 4), 8, 2, boxstyle="round,pad=0.1", 
                                  facecolor='lightgreen', edgecolor='green')
        ax_pee.add_patch(embed_box)
        ax_pee.text(5, 5, f'Data Embedding\n$D_{i+1}$/3 per channel', ha='center', va='center', fontsize=9)
        
        # ELæ§åˆ¶æ–¹å¡Š
        el_box = FancyBboxPatch((1, 1), 8, 2, boxstyle="round,pad=0.1", 
                               facecolor='lightyellow', edgecolor='orange')
        ax_pee.add_patch(el_box)
        ax_pee.text(5, 2, f'Adaptive EL\n$EL_{i+1}$', ha='center', va='center', fontsize=9)
        
        # æ·»åŠ ç®­é ­
        ax_pee.annotate('', xy=(5, 6.8), xytext=(5, 7.2),
                       arrowprops=dict(arrowstyle='->', lw=1.5, color='black'))
        ax_pee.annotate('', xy=(5, 3.8), xytext=(5, 4.2),
                       arrowprops=dict(arrowstyle='->', lw=1.5, color='black'))
        
        ax_pee.set_title(f'PEE Process\nStage {i+1}', fontsize=10, fontweight='bold')
        ax_pee.axis('off')
    
    # æœ€çµ‚çµæœ
    final_row = 3
    for i in range(4):
        ax_final = fig.add_subplot(gs[final_row, i+1])
        
        # ç°¡å–®æ¨¡æ“¬åµŒå…¥å¾Œçš„å½±åƒ
        if rotation_angles[i] == 360:
            final_img_rgb = original_img_rgb
        else:
            final_img_rgb = np.rot90(original_img_rgb, k=-(rotation_angles[i]//90))
        
        ax_final.imshow(final_img_rgb)
        ax_final.set_title(f'Color Embedded Result\n$I_{i+1}$', fontsize=10, fontweight='bold')
        ax_final.axis('off')
    
    # æ›¿ä»£æ–¹æ¡ˆï¼šæ›´ç²¾ç¢ºçš„ä½ç½®è¨ˆç®—
    for i in range(4):
        # è¨ˆç®—æ¯å€‹éšæ®µçš„æº–ç¢ºxä½ç½®
        x_pos = 0.35 + (i * 0.16)  # å‡å‹»åˆ†ä½ˆåœ¨0.2åˆ°1.0ä¹‹é–“
        
        # ç¬¬ä¸€çµ„ç®­é ­
        fig.text(x_pos, 0.72, 'â†“', fontsize=16, ha='center', color='purple')
        fig.text(x_pos, 0.70, 'Split\nChannels', fontsize=7, ha='center', color='purple')
        
        # ç¬¬äºŒçµ„ç®­é ­
        fig.text(x_pos, 0.52, 'â†“', fontsize=16, ha='center', color='blue')
        fig.text(x_pos, 0.50, 'PEE', fontsize=8, ha='center', color='blue')
        
        # ç¬¬ä¸‰çµ„ç®­é ­
        angle_back = rotation_angles[i] if rotation_angles[i] != 360 else 0
        fig.text(x_pos, 0.32, 'â†“', fontsize=16, ha='center', color='green')
        fig.text(x_pos, 0.30, f'Combine &\nRotate -{angle_back}Â°', 
                fontsize=7, ha='center', color='green')
    
    # åœ–ä¾‹
    legend_elements = [
        patches.Patch(color='lightblue', label='Prediction Process'),
        patches.Patch(color='lightgreen', label='Data Embedding'),
        patches.Patch(color='lightyellow', label='Embedding Level Control'),
        patches.Patch(color='purple', alpha=0.3, label='Channel Processing'),
    ]
    fig.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(0.98, 0.95))
    
    plt.tight_layout()
    save_path = f"{method_dir}/rotation_embedding_flowchart_color_{prediction_method}.png"
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    return save_path

def create_rotation_prediction_error_analysis_color(original_img, imgName, method, prediction_method, output_dir):
    """
    å‰µå»ºå½©è‰²åœ–åƒæ—‹è½‰æ–¹æ³•çš„é æ¸¬èª¤å·®åˆ†æåœ–
    """
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    method_dir = f"{output_dir}/image/{imgName}/{method}"
    os.makedirs(method_dir, exist_ok=True)
    
    # åˆ†é›¢å½©è‰²é€šé“
    b_channel, g_channel, r_channel = cv2.split(original_img)
    channels = [b_channel, g_channel, r_channel]
    channel_names = ['Blue', 'Green', 'Red']
    
    fig, axes = plt.subplots(3, 4, figsize=(16, 12))
    fig.suptitle('Color Image Prediction Error Analysis Across Rotation Stages', fontsize=16, fontweight='bold')
    
    rotation_angles = [0, 90, 180, 270]
    stage_weights = {
        0: [0.3, 0.3, 0.2, 0.2],
        90: [0.25, 0.35, 0.25, 0.15],
        180: [0.4, 0.25, 0.2, 0.15],
        270: [0.2, 0.4, 0.3, 0.1]
    }
    
    for ch_idx, (channel, ch_name) in enumerate(zip(channels, channel_names)):
        for i, angle in enumerate(rotation_angles):
            # æ—‹è½‰é€šé“
            if angle == 0:
                rotated_channel = channel.astype(np.float32)
            else:
                rotated_channel = np.rot90(channel, k=angle//90).astype(np.float32)
            
            # è¨ˆç®—é æ¸¬èª¤å·®
            weights = stage_weights[angle]
            pred_error = compute_prediction_error(rotated_channel, weights)
            
            # é¡¯ç¤ºé æ¸¬èª¤å·®ç†±åœ–
            im = axes[ch_idx, i].imshow(pred_error, cmap='RdBu_r', vmin=-15, vmax=15)
            
            if ch_idx == 0:  # åªåœ¨ç¬¬ä¸€è¡Œæ·»åŠ è§’åº¦æ¨™é¡Œ
                axes[ch_idx, i].set_title(f'Stage {i+1}: {angle}Â°', fontsize=12, fontweight='bold')
            
            # åœ¨å·¦å´æ·»åŠ é€šé“æ¨™ç±¤
            if i == 0:
                axes[ch_idx, i].set_ylabel(f'{ch_name}\nChannel', fontsize=12, fontweight='bold')
            
            axes[ch_idx, i].axis('off')
            
            # è¨ˆç®—å¯åµŒå…¥åƒç´ çµ±è¨ˆ
            embedable_pixels = np.sum(np.abs(pred_error) <= 5)
            total_pixels = pred_error.size
            embed_ratio = embedable_pixels / total_pixels * 100
            
            axes[ch_idx, i].text(0.02, 0.98, f'{embed_ratio:.1f}%', 
                               transform=axes[ch_idx, i].transAxes, 
                               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),
                               fontsize=9, verticalalignment='top')
    
    # æ·»åŠ é¡è‰²æ¢
    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])
    cbar = fig.colorbar(im, cax=cbar_ax)
    cbar.set_label('Prediction Error', rotation=270, labelpad=15)
    
    plt.tight_layout()
    plt.subplots_adjust(right=0.9)
    save_path = f"{method_dir}/rotation_prediction_error_color_{prediction_method}.png"
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    return save_path

def compute_prediction_error(img, weights):
    """
    è¨ˆç®—é æ¸¬èª¤å·®çš„è¼”åŠ©å‡½æ•¸
    """
    pred_img = np.zeros_like(img)
    h, w = img.shape
    
    for y in range(1, h-1):
        for x in range(1, w-1):
            up = img[y-1, x]
            left = img[y, x-1]
            up_left = img[y-1, x-1]
            up_right = img[y-1, x+1] if x+1 < w else img[y-1, x-1]
            
            pred_img[y, x] = (weights[0]*up + weights[1]*left + 
                            weights[2]*up_left + weights[3]*up_right)
    
    return img - pred_img

# æ›¿æ¢åŸæœ‰çš„Splitå¯è§†åŒ–å‡½æ•°

def create_split_rotation_effect_grayscale(sub_images, rotations, split_size, block_base, save_path, stage_num=None):
    """
    å‰µå»ºç°éšåœ–åƒSplitæ–¹æ³•çš„æ—‹è½‰æ•ˆæœè¦–è¦ºåŒ–ï¼ˆä¿®å¾©ç‰ˆæœ¬ï¼‰
    
    Parameters:
    -----------
    sub_images : list
        åµŒå…¥å¾Œä½†æœªæ—‹è½‰å›ä¾†çš„å­åœ–åƒåˆ—è¡¨
    rotations : list or np.ndarray
        æ¯å€‹å­åœ–åƒå°æ‡‰çš„æ—‹è½‰è§’åº¦
    split_size : int
        åˆ†å‰²å¤§å° (ä¾‹å¦‚: 2 è¡¨ç¤º 2x2 åˆ†å‰²)
    block_base : bool
        True: Block-basedåˆ†å‰², False: Quarter-basedåˆ†å‰²
    save_path : str
        ä¿å­˜è·¯å¾‘
    stage_num : int, optional
        éšæ®µç·¨è™Ÿï¼Œç”¨æ–¼æ–‡ä»¶å‘½å
        
    Returns:
    --------
    tuple
        (merged_image, tiled_image) åˆæˆåœ–åƒå’Œæ‹¼è²¼åœ–åƒ
    """
    
    # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
    # æª¢æŸ¥è¼¸å…¥æ•¸æ“š
    if not sub_images or len(sub_images) == 0:
        print("ERROR: No sub_images provided to create_split_rotation_effect_grayscale")
        return None, None
    
    print(f"Processing {len(sub_images)} sub-images for grayscale rotation effect")
    
    # è½‰æ›CuPyæ•¸çµ„ç‚ºNumPyæ•¸çµ„
    numpy_sub_images = []
    for i, sub_img in enumerate(sub_images):
        if isinstance(sub_img, cp.ndarray):
            numpy_sub_img = cp.asnumpy(sub_img)
        else:
            numpy_sub_img = np.array(sub_img)
        
        # ç¢ºä¿æ˜¯uint8é¡å‹
        if numpy_sub_img.dtype != np.uint8:
            numpy_sub_img = numpy_sub_img.astype(np.uint8)
        
        numpy_sub_images.append(numpy_sub_img)
        print(f"  Sub-image {i}: shape={numpy_sub_img.shape}, dtype={numpy_sub_img.dtype}")
    
    try:
        # 1. å‰µå»ºç›´æ¥åˆæˆçš„åœ–åƒï¼ˆæ²’æ—‹è½‰å›0åº¦çš„å­åœ–åƒç›´æ¥åˆæˆï¼‰
        if isinstance(sub_images[0], cp.ndarray):
            merged_effect_img = merge_image_flexible(sub_images, split_size, block_base)
            merged_effect_img = cp.asnumpy(merged_effect_img)
        else:
            cupy_sub_images = [cp.asarray(sub_img) for sub_img in numpy_sub_images]
            merged_effect_img = merge_image_flexible(cupy_sub_images, split_size, block_base)
            merged_effect_img = cp.asnumpy(merged_effect_img)
        
        # ç¢ºä¿åˆæˆåœ–åƒæ˜¯æ­£ç¢ºçš„æ•¸æ“šé¡å‹
        if merged_effect_img.dtype != np.uint8:
            merged_effect_img = merged_effect_img.astype(np.uint8)
        
        print(f"Merged image: shape={merged_effect_img.shape}, dtype={merged_effect_img.dtype}")
        
    except Exception as e:
        print(f"ERROR creating merged image: {e}")
        return None, None
    
    try:
        # 2. å‰µå»ºæ‹¼è²¼ç•«æ–¹å¼çš„åœ–åƒï¼ˆæ‰€æœ‰å­åœ–åƒæ’åˆ—æˆç¶²æ ¼ï¼‰
        tiled_image = create_tiled_subimages(numpy_sub_images, split_size)
        
        # ç¢ºä¿æ‹¼è²¼åœ–åƒæ˜¯æ­£ç¢ºçš„æ•¸æ“šé¡å‹
        if tiled_image.dtype != np.uint8:
            tiled_image = tiled_image.astype(np.uint8)
        
        print(f"Tiled image: shape={tiled_image.shape}, dtype={tiled_image.dtype}")
        
    except Exception as e:
        print(f"ERROR creating tiled image: {e}")
        return merged_effect_img, None
    
    # ç”Ÿæˆä¿å­˜è·¯å¾‘
    base_path = save_path.replace('.png', '')
    split_type = 'block' if block_base else 'quarter'
    
    # ä¿å­˜å…©ç¨®é¡å‹çš„åœ–åƒ
    merged_path = f"{base_path}_{split_type}_merged.png"
    tiled_path = f"{base_path}_{split_type}_tiled.png"
    
    # å¯¦éš›ä¿å­˜åœ–åƒä¸¦æª¢æŸ¥çµæœ
    try:
        success_merged = cv2.imwrite(merged_path, merged_effect_img)
        if success_merged:
            print(f"âœ“ Split rotation merged image saved: {merged_path}")
        else:
            print(f"âœ— Failed to save merged image: {merged_path}")
    except Exception as e:
        print(f"âœ— Exception saving merged image: {e}")
        success_merged = False
    
    try:
        success_tiled = cv2.imwrite(tiled_path, tiled_image)
        if success_tiled:
            print(f"âœ“ Split rotation tiled image saved: {tiled_path}")
        else:
            print(f"âœ— Failed to save tiled image: {tiled_path}")
    except Exception as e:
        print(f"âœ— Exception saving tiled image: {e}")
        success_tiled = False
    
    # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨
    if success_merged and os.path.exists(merged_path):
        file_size = os.path.getsize(merged_path)
        print(f"  Merged file exists, size: {file_size} bytes")
    
    if success_tiled and os.path.exists(tiled_path):
        file_size = os.path.getsize(tiled_path)
        print(f"  Tiled file exists, size: {file_size} bytes")
    
    return merged_effect_img, tiled_image

def create_split_rotation_effect_color(channel_sub_images, rotations, split_size, block_base, 
                                     save_dir, stage_num=None):
    """
    å‰µå»ºå½©è‰²åœ–åƒSplitæ–¹æ³•çš„æ—‹è½‰æ•ˆæœè¦–è¦ºåŒ–ï¼ˆå„é€šé“ä»¥å°æ‡‰é¡è‰²é¡¯ç¤ºï¼‰
    
    Parameters:
    -----------
    channel_sub_images : dict
        åŒ…å«ä¸‰å€‹é€šé“çš„å­åœ–åƒå­—å…¸ {'blue': [], 'green': [], 'red': []}
    rotations : list or np.ndarray
        æ¯å€‹å­åœ–åƒå°æ‡‰çš„æ—‹è½‰è§’åº¦
    split_size : int
        åˆ†å‰²å¤§å°
    block_base : bool
        åˆ†å‰²æ–¹å¼
    save_dir : str
        ä¿å­˜ç›®éŒ„
    stage_num : int, optional
        éšæ®µç·¨è™Ÿ
        
    Returns:
    --------
    dict
        åŒ…å«å„é€šé“çµæœçš„å­—å…¸
    """
    
    # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    os.makedirs(save_dir, exist_ok=True)
    
    channel_names = ['blue', 'green', 'red']
    channel_results = {}
    split_type = 'block' if block_base else 'quarter'
    
    # è™•ç†æ¯å€‹é€šé“
    merged_channels_gray = []  # ç”¨æ–¼æœ€çµ‚å½©è‰²åˆæˆçš„ç°åº¦ç‰ˆæœ¬
    tiled_channels_gray = []   # ç”¨æ–¼æœ€çµ‚å½©è‰²åˆæˆçš„ç°åº¦ç‰ˆæœ¬
    
    for ch_idx, ch_name in enumerate(channel_names):
        if ch_name in channel_sub_images:
            sub_images = channel_sub_images[ch_name]

            
            # è½‰æ›ç‚ºNumPyæ•¸çµ„
            numpy_sub_images = []
            for sub_img in sub_images:
                if isinstance(sub_img, cp.ndarray):
                    numpy_sub_images.append(cp.asnumpy(sub_img))
                else:
                    numpy_sub_images.append(np.array(sub_img))
            
            # 1. å‰µå»ºåˆæˆåœ–åƒï¼ˆç°åº¦ç‰ˆæœ¬ï¼‰
            if isinstance(sub_images[0], cp.ndarray):
                channel_merged_gray = merge_image_flexible(sub_images, split_size, block_base)
                channel_merged_gray = cp.asnumpy(channel_merged_gray)
            else:
                cupy_sub_images = [cp.asarray(sub_img) for sub_img in numpy_sub_images]
                channel_merged_gray = merge_image_flexible(cupy_sub_images, split_size, block_base)
                channel_merged_gray = cp.asnumpy(channel_merged_gray)
            
            # 2. å‰µå»ºæ‹¼è²¼åœ–åƒï¼ˆç°åº¦ç‰ˆæœ¬ï¼‰
            channel_tiled_gray = create_tiled_subimages(numpy_sub_images, split_size)
            
            # 3. é—œéµæ­¥é©Ÿï¼šè½‰æ›ç‚ºå°æ‡‰é¡è‰²çš„å½©è‰²åœ–åƒ
            channel_merged_colored = convert_single_channel_to_color(channel_merged_gray, ch_name)
            channel_tiled_colored = convert_single_channel_to_color(channel_tiled_gray, ch_name)
            
            # ä¿å­˜ç°åº¦ç‰ˆæœ¬ç”¨æ–¼æœ€çµ‚åˆæˆ
            merged_channels_gray.append(channel_merged_gray)
            tiled_channels_gray.append(channel_tiled_gray)
            
            # 4. é—œéµä¿®å¾©ï¼šå¯¦éš›ä¿å­˜å½©è‰²ç‰ˆæœ¬çš„å–®é€šé“çµæœ
            channel_merged_path = os.path.join(save_dir, f"{ch_name}_channel_{split_type}_merged.png")
            channel_tiled_path = os.path.join(save_dir, f"{ch_name}_channel_{split_type}_tiled.png")
            
            # å¯¦éš›ä¿å­˜åœ–åƒï¼ˆé€™æ˜¯ä¹‹å‰ç¼ºå°‘çš„éƒ¨åˆ†ï¼‰
            success_merged = cv2.imwrite(channel_merged_path, channel_merged_colored)
            success_tiled = cv2.imwrite(channel_tiled_path, channel_tiled_colored)
            
            # æª¢æŸ¥ä¿å­˜æ˜¯å¦æˆåŠŸ
            if success_merged:
                print(f"{ch_name.capitalize()} channel colored merged saved: {channel_merged_path}")
            else:
                print(f"Failed to save {ch_name} channel merged image: {channel_merged_path}")
                
            if success_tiled:
                print(f"{ch_name.capitalize()} channel colored tiled saved: {channel_tiled_path}")
            else:
                print(f"Failed to save {ch_name} channel tiled image: {channel_tiled_path}")
            
            # å­˜å„²çµæœ
            channel_results[f'{ch_name}_merged'] = channel_merged_colored
            channel_results[f'{ch_name}_tiled'] = channel_tiled_colored
            
        else:
            print(f"WARNING: {ch_name} channel not found in channel_sub_images")
    
    # å‰µå»ºå½©è‰²åˆæˆåœ–åƒï¼ˆä½¿ç”¨ç°åº¦ç‰ˆæœ¬åˆæˆï¼‰
    if len(merged_channels_gray) == 3:
        
        # åˆæˆçš„å½©è‰²åœ–åƒï¼ˆåˆä½µæ–¹å¼ï¼‰
        color_merged = combine_color_channels(
            merged_channels_gray[0],  # blue
            merged_channels_gray[1],  # green
            merged_channels_gray[2]   # red
        )
        
        # åˆæˆçš„å½©è‰²åœ–åƒï¼ˆæ‹¼è²¼æ–¹å¼ï¼‰
        color_tiled = combine_color_channels(
            tiled_channels_gray[0],   # blue
            tiled_channels_gray[1],   # green
            tiled_channels_gray[2]    # red
        )
        
        # é—œéµä¿®å¾©ï¼šå¯¦éš›ä¿å­˜å½©è‰²åˆæˆçµæœ
        color_merged_path = os.path.join(save_dir, f"color_{split_type}_merged.png")
        color_tiled_path = os.path.join(save_dir, f"color_{split_type}_tiled.png")
        
        # å¯¦éš›ä¿å­˜åœ–åƒï¼ˆé€™æ˜¯ä¹‹å‰ç¼ºå°‘çš„éƒ¨åˆ†ï¼‰
        success_color_merged = cv2.imwrite(color_merged_path, color_merged)
        success_color_tiled = cv2.imwrite(color_tiled_path, color_tiled)
        
        # æª¢æŸ¥ä¿å­˜æ˜¯å¦æˆåŠŸ
        if success_color_merged:
            print(f"Color merged image saved: {color_merged_path}")
        else:
            print(f"Failed to save color merged image: {color_merged_path}")
            
        if success_color_tiled:
            print(f"Color tiled image saved: {color_tiled_path}")
        else:
            print(f"Failed to save color tiled image: {color_tiled_path}")
        
        channel_results['color_merged'] = color_merged
        channel_results['color_tiled'] = color_tiled
        
    else:
        print(f"WARNING: Expected 3 channels but got {len(merged_channels_gray)}")
    
    return channel_results

def create_tiled_subimages(sub_images, split_size, padding=2):
    """
    å°‡å­åœ–åƒä»¥æ‹¼è²¼ç•«æ–¹å¼æ’åˆ—æˆç¶²æ ¼
    
    Parameters:
    -----------
    sub_images : list
        å­åœ–åƒåˆ—è¡¨
    split_size : int
        åˆ†å‰²å¤§å°
    padding : int
        å­åœ–åƒä¹‹é–“çš„é–“è·ï¼ˆåƒç´ ï¼‰
        
    Returns:
    --------
    numpy.ndarray
        æ‹¼è²¼ç•«åœ–åƒ
    """
    if not sub_images:
        return np.array([])
    
    # ç²å–å­åœ–åƒå°ºå¯¸
    sub_height, sub_width = sub_images[0].shape[:2]
    
    # è¨ˆç®—ç¶²æ ¼å°ºå¯¸
    grid_width = split_size * sub_width + (split_size - 1) * padding
    grid_height = split_size * sub_height + (split_size - 1) * padding
    
    # å‰µå»ºç©ºç™½ç•«å¸ƒ
    if len(sub_images[0].shape) == 3:  # å½©è‰²åœ–åƒ
        tiled_image = np.zeros((grid_height, grid_width, 3), dtype=np.uint8)
    else:  # ç°åº¦åœ–åƒ
        tiled_image = np.zeros((grid_height, grid_width), dtype=np.uint8)
    
    # å°‡å­åœ–åƒæ”¾ç½®åˆ°ç¶²æ ¼ä¸­
    for i in range(split_size):
        for j in range(split_size):
            idx = i * split_size + j
            if idx < len(sub_images):
                # è¨ˆç®—æ”¾ç½®ä½ç½®
                start_y = i * (sub_height + padding)
                end_y = start_y + sub_height
                start_x = j * (sub_width + padding)
                end_x = start_x + sub_width
                
                # æ”¾ç½®å­åœ–åƒ
                tiled_image[start_y:end_y, start_x:end_x] = sub_images[idx]
    
    return tiled_image

def save_split_rotation_effects(pee_stages, method, imgName, output_dir, is_color_image=False):
    """
    æ‰¹é‡ä¿å­˜Splitæ–¹æ³•çš„æ‰€æœ‰æ—‹è½‰æ•ˆæœåœ–åƒï¼ˆä¿®æ”¹ç‰ˆï¼Œç„¡æ–‡å­—æ¨™æ³¨ï¼‰
    
    Parameters:
    -----------
    pee_stages : list
        PEEéšæ®µçµæœåˆ—è¡¨
    method : str
        æ–¹æ³•åç¨± ("split")
    imgName : str
        åœ–åƒåç¨±
    output_dir : str
        è¼¸å‡ºç›®éŒ„
    is_color_image : bool
        æ˜¯å¦ç‚ºå½©è‰²åœ–åƒ
    """
    if method != "split":
        return
    
    # å‰µå»ºSplitå°ˆç”¨çš„è¼¸å‡ºç›®éŒ„
    split_effect_dir = os.path.join(output_dir, "image", imgName, "split", "rotation_effects")
    os.makedirs(split_effect_dir, exist_ok=True)
    
    for i, stage in enumerate(pee_stages):
        if 'rotated_sub_images' in stage or 'channel_rotated_sub_images' in stage:
            stage_dir = os.path.join(split_effect_dir, f"stage_{i}")
            os.makedirs(stage_dir, exist_ok=True)
            
            # ç²å–æ—‹è½‰è§’åº¦è³‡è¨Š
            rotations = stage.get('rotations', [0] * (stage.get('split_size', 2) ** 2))
            split_size = stage.get('split_size', 2)
            block_base = stage.get('block_base', True)
            
            if is_color_image:
                # å½©è‰²åœ–åƒè™•ç†
                if 'channel_rotated_sub_images' in stage:
                    color_results = create_split_rotation_effect_color(
                        stage['channel_rotated_sub_images'],
                        rotations, split_size, block_base,
                        stage_dir, i
                    )
                    print(f"Created color rotation effects for stage {i}")
            else:
                # ç°éšåœ–åƒè™•ç†
                if 'rotated_sub_images' in stage:
                    grayscale_save_path = os.path.join(stage_dir, "grayscale_rotation_effect.png")
                    merged_img, tiled_img = create_split_rotation_effect_grayscale(
                        stage['rotated_sub_images'],
                        rotations, split_size, block_base,
                        grayscale_save_path, i
                    )
                    print(f"Created grayscale rotation effects for stage {i}")

# æ–°å¢: å‰µå»ºç°¡æ½”çš„æ¯”è¼ƒåœ–åƒå‡½æ•¸
def create_split_comparison_simple(original_img, merged_img, tiled_img, save_path, split_type):
    """
    å‰µå»ºç°¡æ½”çš„Splitæ–¹æ³•æ¯”è¼ƒåœ–åƒï¼ˆç„¡æ–‡å­—ï¼‰
    
    Parameters:
    -----------
    original_img : numpy.ndarray
        åŸå§‹åœ–åƒ
    merged_img : numpy.ndarray
        åˆæˆçš„æ—‹è½‰æ•ˆæœåœ–åƒ
    tiled_img : numpy.ndarray
        æ‹¼è²¼çš„æ—‹è½‰æ•ˆæœåœ–åƒ
    save_path : str
        ä¿å­˜è·¯å¾‘
    split_type : str
        åˆ†å‰²é¡å‹ ('block' æˆ– 'quarter')
    """
    # ç¢ºä¿æ‰€æœ‰åœ–åƒå°ºå¯¸ä¸€è‡´ï¼ˆèª¿æ•´tiled_imgä»¥åŒ¹é…åŸå§‹åœ–åƒï¼‰
    h, w = original_img.shape[:2]
    
    # èª¿æ•´æ‹¼è²¼åœ–åƒå¤§å°ä»¥åŒ¹é…åŸå§‹åœ–åƒ
    tiled_resized = cv2.resize(tiled_img, (w, h))
    
    # æ°´å¹³æ‹¼æ¥ä¸‰å¼µåœ–åƒ
    if len(original_img.shape) == 3:  # å½©è‰²åœ–åƒ
        combined = np.hstack([original_img, merged_img, tiled_resized])
    else:  # ç°åº¦åœ–åƒ
        combined = np.hstack([original_img, merged_img, tiled_resized])
    
    cv2.imwrite(save_path, combined)
    print(f"Split comparison ({split_type}) saved: {save_path}")
    
def convert_single_channel_to_color(single_channel_img, channel_name):
    """
    å°‡å–®é€šé“åœ–åƒè½‰æ›ç‚ºå°æ‡‰é¡è‰²çš„å½©è‰²åœ–åƒ
    
    Parameters:
    -----------
    single_channel_img : numpy.ndarray
        å–®é€šé“ç°åº¦åœ–åƒ
    channel_name : str
        é€šé“åç¨± ('blue', 'green', 'red')
        
    Returns:
    --------
    numpy.ndarray
        å°æ‡‰é¡è‰²çš„å½©è‰²åœ–åƒ (BGRæ ¼å¼)
    """
    
    # ç¢ºä¿è¼¸å…¥æ˜¯2Dæ•¸çµ„
    if len(single_channel_img.shape) != 2:
        raise ValueError(f"Expected 2D array, got shape: {single_channel_img.shape}")
    
    height, width = single_channel_img.shape
    colored_img = np.zeros((height, width, 3), dtype=np.uint8)
    
    if channel_name == 'blue':
        # è—è‰²é€šé“ï¼š(B, G, R) = (blue_value, 0, 0)
        colored_img[:, :, 0] = single_channel_img  # Bé€šé“
        colored_img[:, :, 1] = 0                   # Gé€šé“
        colored_img[:, :, 2] = 0                   # Ré€šé“
    elif channel_name == 'green':
        # ç¶ è‰²é€šé“ï¼š(B, G, R) = (0, green_value, 0)
        colored_img[:, :, 0] = 0                   # Bé€šé“
        colored_img[:, :, 1] = single_channel_img  # Gé€šé“
        colored_img[:, :, 2] = 0                   # Ré€šé“
    elif channel_name == 'red':
        # ç´…è‰²é€šé“ï¼š(B, G, R) = (0, 0, red_value)
        colored_img[:, :, 0] = 0                   # Bé€šé“
        colored_img[:, :, 1] = 0                   # Gé€šé“
        colored_img[:, :, 2] = single_channel_img  # Ré€šé“
    else:
        raise ValueError(f"Unknown channel name: {channel_name}")
    
    return colored_img

def enhance_with_grid_visualization(combined_stage, b_img, g_img, r_img, image_dir, stage_num):
    """
    ğŸ¨ å¢å¼· with_grid è¦–è¦ºåŒ–ï¼šç”Ÿæˆä¸‰é€šé“å½©è‰²ç‰ˆæœ¬å’Œçµ„åˆç‰ˆæœ¬ï¼ˆåƒ…å½©è‰²ï¼‰
    """
    from visualization import convert_single_channel_to_color
    from image_processing import add_grid_lines
    
    # å‰µå»ºç›®éŒ„
    with_grid_dir = f"{image_dir}/with_grid"
    colored_grid_dir = f"{with_grid_dir}/colored"
    combined_grid_dir = f"{with_grid_dir}/combined"
    os.makedirs(colored_grid_dir, exist_ok=True)
    os.makedirs(combined_grid_dir, exist_ok=True)
    
    channel_names = ['blue', 'green', 'red']
    channel_imgs = [b_img, g_img, r_img]
    colored_grids = []
    
    # è™•ç†æ¯å€‹é€šé“
    for ch_name, ch_img in zip(channel_names, channel_imgs):
        if ch_name in combined_stage['channel_block_info']:
            block_info = combined_stage['channel_block_info'][ch_name]
            
            # ç”Ÿæˆå¸¶ç¶²æ ¼çš„ç°éšåœ–åƒ
            grid_img_gray = add_grid_lines(ch_img.copy(), block_info)
            
            # ğŸ¨ è½‰æ›ç‚ºå°æ‡‰é¡è‰²ä¸¦ä¿å­˜
            grid_img_colored = convert_single_channel_to_color(grid_img_gray, ch_name)
            colored_grids.append(grid_img_colored)
            
            # ğŸ¨ åƒ…ä¿å­˜å½©è‰²ç¶²æ ¼åœ–åƒ
            cv2.imwrite(f"{with_grid_dir}/stage_{stage_num}_{ch_name}_grid.png", grid_img_colored)
    
    # ğŸ¨ ç”Ÿæˆä¸‰é€šé“çµ„åˆçš„å½©è‰²ç¶²æ ¼åœ–åƒ
    if len(colored_grids) == 3:
        # æ–¹æ³•1ï¼šç›´æ¥ç–ŠåŠ ä¸‰å€‹å½©è‰²é€šé“ï¼ˆå‰µé€ æ··åˆæ•ˆæœï¼‰
        combined_overlay = np.zeros_like(colored_grids[0], dtype=np.float32)
        for colored_grid in colored_grids:
            combined_overlay += colored_grid.astype(np.float32)
        combined_overlay = np.clip(combined_overlay / 3, 0, 255).astype(np.uint8)
        
        cv2.imwrite(f"{combined_grid_dir}/stage_{stage_num}_overlay_grid.png", combined_overlay)
        
        # æ–¹æ³•2ï¼šä½¿ç”¨åŸå§‹é€šé“çµ„åˆå¾Œå†æ·»åŠ çµ±ä¸€ç¶²æ ¼
        from color import combine_color_channels
        combined_img = combine_color_channels(b_img, g_img, r_img)
        
        # ä½¿ç”¨è—è‰²é€šé“çš„block_infoä½œç‚ºä»£è¡¨ï¼ˆå› ç‚ºä¸‰é€šé“é€šå¸¸æœ‰ç›¸ä¼¼çš„åˆ†å‰²ï¼‰
        if 'blue' in combined_stage['channel_block_info']:
            combined_grid = add_grid_lines_color(combined_img.copy(), combined_stage['channel_block_info']['blue'])
            cv2.imwrite(f"{combined_grid_dir}/stage_{stage_num}_unified_grid.png", combined_grid)

def enhance_block_visualizations(combined_stage, original_img, image_dir, stage_num):
    """
    ğŸ¨ å¢å¼· block_size_visualizationsï¼šç”Ÿæˆä¸‰é€šé“å½©è‰²ç‰ˆæœ¬å’Œçµ„åˆç‰ˆæœ¬
    """
    from visualization import (convert_single_channel_to_color, 
                             visualize_specific_quadtree_blocks)
    from color import split_color_channels, combine_color_channels
    
    # å‰µå»ºç›®éŒ„çµæ§‹
    blocks_viz_dir = f"{image_dir}/block_size_visualizations"
    colored_blocks_dir = f"{blocks_viz_dir}/colored"
    combined_blocks_dir = f"{blocks_viz_dir}/combined"
    
    for ch_name in ['blue', 'green', 'red']:
        ch_colored_dir = f"{colored_blocks_dir}/{ch_name}"
        os.makedirs(ch_colored_dir, exist_ok=True)
    os.makedirs(combined_blocks_dir, exist_ok=True)
    
    # åˆ†é›¢åŸå§‹åœ–åƒé€šé“
    b_orig, g_orig, r_orig = split_color_channels(original_img)
    channel_origs = {'blue': b_orig, 'green': g_orig, 'red': r_orig}
    
    # æ¨™æº–å€å¡Šå¤§å°åˆ—è¡¨
    block_sizes = [16, 32, 64, 128, 256, 512, 1024]
    
    # ç‚ºæ¯å€‹å€å¡Šå¤§å°å‰µå»ºè¦–è¦ºåŒ–
    for size in block_sizes:
        size_str = str(size)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰é€™å€‹å¤§å°çš„å€å¡Š
        has_blocks = any(
            size_str in combined_stage['channel_block_info'][ch] and 
            len(combined_stage['channel_block_info'][ch][size_str]['blocks']) > 0
            for ch in ['blue', 'green', 'red']
            if ch in combined_stage['channel_block_info']
        )
        
        if has_blocks:
            colored_channel_imgs = []
            
            # è™•ç†æ¯å€‹é€šé“
            for ch_name, ch_orig in channel_origs.items():
                if (ch_name in combined_stage['channel_block_info'] and 
                    size_str in combined_stage['channel_block_info'][ch_name] and
                    len(combined_stage['channel_block_info'][ch_name][size_str]['blocks']) > 0):
                    
                    # ç”Ÿæˆç°éšçš„å€å¡Šè¦–è¦ºåŒ–
                    block_viz_gray = visualize_specific_quadtree_blocks(
                        combined_stage['channel_block_info'][ch_name], 
                        ch_orig, size, 
                        f"{blocks_viz_dir}/{ch_name}/stage_{stage_num}_blocks_{size}x{size}.png"
                    )
                    
                    # ğŸ¨ è½‰æ›ç‚ºå°æ‡‰é¡è‰²
                    block_viz_colored = convert_single_channel_to_color(block_viz_gray, ch_name)
                    colored_channel_imgs.append(block_viz_colored)
                    
                    # ä¿å­˜å–®é€šé“å½©è‰²ç‰ˆæœ¬
                    colored_save_path = f"{colored_blocks_dir}/{ch_name}/stage_{stage_num}_blocks_{size}x{size}_colored.png"
                    cv2.imwrite(colored_save_path, block_viz_colored)
                    
                else:
                    # å¦‚æœè©²é€šé“æ²’æœ‰é€™å€‹å¤§å°çš„å€å¡Šï¼Œå‰µå»ºç©ºçš„ä½”ä½ç¬¦
                    empty_colored = np.zeros((ch_orig.shape[0], ch_orig.shape[1], 3), dtype=np.uint8)
                    colored_channel_imgs.append(empty_colored)
            
            # ğŸ¨ ç”Ÿæˆä¸‰é€šé“çµ„åˆçš„å½©è‰²è¦–è¦ºåŒ–
            if len(colored_channel_imgs) == 3:
                # æ–¹æ³•1ï¼šç–ŠåŠ ä¸‰å€‹å½©è‰²é€šé“
                combined_overlay = np.zeros_like(colored_channel_imgs[0], dtype=np.float32)
                for colored_img in colored_channel_imgs:
                    combined_overlay += colored_img.astype(np.float32)
                combined_overlay = np.clip(combined_overlay, 0, 255).astype(np.uint8)
                
                overlay_path = f"{combined_blocks_dir}/stage_{stage_num}_blocks_{size}x{size}_overlay.png"
                cv2.imwrite(overlay_path, combined_overlay)
                
                # æ–¹æ³•2ï¼šä½¿ç”¨å¯¦éš›çš„å½©è‰²çµ„åˆï¼ˆåŸºæ–¼åŸå§‹åœ–åƒçš„å€å¡Šåˆ†å‰²ï¼‰
                # é€™éœ€è¦æ›´è¤‡é›œçš„é‚è¼¯ï¼Œæš«æ™‚ä½¿ç”¨è—è‰²é€šé“çš„åˆ†å‰²è³‡è¨Šä½œç‚ºä»£è¡¨
                if ('blue' in combined_stage['channel_block_info'] and 
                    size_str in combined_stage['channel_block_info']['blue']):
                    
                    color_blocks_viz = visualize_specific_quadtree_blocks_color(
                        combined_stage['channel_block_info']['blue'], 
                        original_img, size
                    )
                    
                    unified_path = f"{combined_blocks_dir}/stage_{stage_num}_blocks_{size}x{size}_unified.png"
                    cv2.imwrite(unified_path, color_blocks_viz)

def enhance_final_visualizations(pee_stages, final_b_img, final_g_img, final_r_img, image_dir):
    """
    ğŸ¨ å¢å¼·æœ€çµ‚çµæœçš„è¦–è¦ºåŒ–
    """
    from visualization import convert_single_channel_to_color
    from image_processing import add_grid_lines
    from color import combine_color_channels
    
    if not pee_stages:
        return
    
    final_stage = pee_stages[-1]
    
    # ğŸ¨ æœ€çµ‚ with_grid è¦–è¦ºåŒ–
    if 'channel_block_info' in final_stage:
        with_grid_dir = f"{image_dir}/with_grid"
        colored_grid_dir = f"{with_grid_dir}/colored"
        combined_grid_dir = f"{with_grid_dir}/combined"
        os.makedirs(colored_grid_dir, exist_ok=True)
        os.makedirs(combined_grid_dir, exist_ok=True)
        
        channel_names = ['blue', 'green', 'red']
        channel_imgs = [final_b_img, final_g_img, final_r_img]
        colored_final_grids = []
        
        for ch_name, ch_img in zip(channel_names, channel_imgs):
            if ch_name in final_stage['channel_block_info']:
                # ç”Ÿæˆå¸¶ç¶²æ ¼çš„ç°éšåœ–åƒ
                final_grid_gray = add_grid_lines(ch_img.copy(), final_stage['channel_block_info'][ch_name])
                
                # ğŸ¨ è½‰æ›ç‚ºå°æ‡‰é¡è‰²
                final_grid_colored = convert_single_channel_to_color(final_grid_gray, ch_name)
                colored_final_grids.append(final_grid_colored)
                
                # ä¿å­˜æœ€çµ‚å–®é€šé“å½©è‰²ç¶²æ ¼
                cv2.imwrite(f"{colored_grid_dir}/final_{ch_name}_grid_colored.png", final_grid_colored)
                
                # ä¿å­˜åŸå§‹ç°éšç‰ˆæœ¬ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
                cv2.imwrite(f"{with_grid_dir}/final_{ch_name}_channel_grid.png", final_grid_gray)
        
        # ğŸ¨ ç”Ÿæˆæœ€çµ‚çµ„åˆå½©è‰²ç¶²æ ¼
        if len(colored_final_grids) == 3:
            # ç–ŠåŠ ç‰ˆæœ¬
            final_overlay = np.zeros_like(colored_final_grids[0], dtype=np.float32)
            for colored_grid in colored_final_grids:
                final_overlay += colored_grid.astype(np.float32)
            final_overlay = np.clip(final_overlay / 3, 0, 255).astype(np.uint8)
            cv2.imwrite(f"{combined_grid_dir}/final_overlay_grid.png", final_overlay)
            
            # çµ±ä¸€ç‰ˆæœ¬
            final_combined_img = combine_color_channels(final_b_img, final_g_img, final_r_img)
            if 'blue' in final_stage['channel_block_info']:
                final_unified_grid = add_grid_lines_color(final_combined_img.copy(), 
                                                        final_stage['channel_block_info']['blue'])
                cv2.imwrite(f"{combined_grid_dir}/final_unified_grid.png", final_unified_grid)

def add_grid_lines_color(img, block_info):
    """
    ç‚ºå½©è‰²åœ–åƒæ·»åŠ ç¶²æ ¼ç·šçš„è¼”åŠ©å‡½æ•¸
    """
    grid_img = img.copy()
    grid_color = [128, 128, 128]  # ç°è‰²æ ¼ç·š
    
    # ç·šå¯¬è¨­å®š
    line_widths = {
        1024: 4,
        512: 3,
        256: 3,
        128: 2,
        64: 2,
        32: 1,
        16: 1
    }
    
    # å¾å¤§åˆ°å°è™•ç†å„å€‹å€å¡Š
    for size_str in sorted(block_info.keys(), key=lambda x: int(x), reverse=True):
        size = int(size_str)
        line_width = line_widths.get(size, 1)
        blocks = block_info[size_str]['blocks']
        
        for block in blocks:
            y, x = block['position']
            block_size = block['size']
            
            # ç¹ªè£½é‚Šæ¡†
            for i in range(line_width):
                # ä¸Šä¸‹é‚Šæ¡†
                grid_img[y+i:y+i+1, x:x+block_size] = grid_color
                grid_img[y+block_size-i-1:y+block_size-i, x:x+block_size] = grid_color
                # å·¦å³é‚Šæ¡†
                grid_img[y:y+block_size, x+i:x+i+1] = grid_color
                grid_img[y:y+block_size, x+block_size-i-1:x+block_size-i] = grid_color
    
    return grid_img

def visualize_specific_quadtree_blocks_color(block_info, original_color_img, specific_size):
    """
    ç‚ºå½©è‰²åœ–åƒå‰µå»ºç‰¹å®šå¤§å°å€å¡Šçš„è¦–è¦ºåŒ–
    """
    height, width = original_color_img.shape[:2]
    visualization = np.zeros((height, width, 3), dtype=np.uint8)  # é»‘è‰²èƒŒæ™¯
    
    size_str = str(specific_size)
    if size_str in block_info:
        blocks = block_info[size_str]['blocks']
        
        for block in blocks:
            y, x = block['position']
            
            # è¤‡è£½åŸåœ–é€™å€‹å€å¡Šçš„å…§å®¹
            visualization[y:y+specific_size, x:x+specific_size] = original_color_img[y:y+specific_size, x:x+specific_size]
            
            # æ·»åŠ å½©è‰²é‚Šæ¡†
            border_width = max(1, specific_size // 64)
            border_color = [255, 255, 0]  # é»ƒè‰²é‚Šæ¡†
            
            # ç¹ªè£½é‚Šæ¡†
            visualization[y:y+border_width, x:x+specific_size] = border_color
            visualization[y+specific_size-border_width:y+specific_size, x:x+specific_size] = border_color
            visualization[y:y+specific_size, x:x+border_width] = border_color
            visualization[y:y+specific_size, x+specific_size-border_width:x+specific_size] = border_color
    
    return visualization